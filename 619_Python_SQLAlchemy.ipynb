{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Databases in Python\n",
    "\n",
    "In this notebook, you'll learn the basics of using SQL with Python. This will be useful because databases are ubiquitous and data scientists, analysts, and engineers must interact with them constantly. The Python SQL toolkit **SQLAlchemy** provides an accessible and intuitive way to query, build, and write to essential databases, including `SQLite`, `MySQL`, and `PostgreSQL`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQL Alchemy\n",
    "\n",
    "An **engine** is a common interface to the database from SQLAlchemy. A **connection string** consists of all information required to connect to the database (and login, if necessary). A **reflection** process reads the database and creates SQLAlchemy table objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import create_engine, MetaData, and Table\n",
    "from sqlalchemy import create_engine, Table, MetaData\n",
    "\n",
    "path='data/dc25/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Engines and connection strings\n",
    "\n",
    "Alright, it's time to create your first engine! An **engine** is just a common interface to a database, and the information it requires to connect to one is contained in a **connection string**, for example `sqlite:///example.sqlite`. Here, `sqlite` in `sqlite:///` is the **database driver**, while `example.sqlite` is a SQLite file contained in the local directory.\n",
    "\n",
    "You can learn a lot more about connection strings in the [SQLAlchemy documentation](https://docs.sqlalchemy.org/en/13/core/engines.html#database-urls).\n",
    "\n",
    "Your job in this exercise is to create an engine that connects to a local SQLite file named `census.sqlite`. Then, print the names of the tables the engine contains using the `.table_names()` method. Note that when you just want to print the table names, you do not need to use `engine.connect()` after creating the engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import create_engine\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Create an engine that connects to the census.sqlite file: engine\n",
    "#cs = 'sqlite:///'+path+'census_nyc.sqlite'\n",
    "#print(cs)\n",
    "\n",
    "engine = create_engine('sqlite:///'+path+'census.sqlite')\n",
    "\n",
    "# Print table names\n",
    "print(engine.table_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoloading Tables from a database\n",
    "\n",
    "**SQLAlchemy** can be used to automatically load tables from a database using something called **reflection**. **Reflection** is the process of reading the database and building the metadata based on that information. It's the opposite of creating a Table by hand and is very useful for working with existing databases.\n",
    "\n",
    "To perform **reflection**, you will first need to import and initialize a `MetaData` object. MetaData objects contain information about tables stored in a database. During reflection, the MetaData object will be populated with information about the reflected table automatically, so we only need to initialize it before reflecting by calling `MetaData()`.\n",
    "\n",
    "You will also need to import the `Table` object from the SQLAlchemy package. Then, you use this Table object to read your table from the engine, autoload the columns, and populate the metadata. This can be done with a single call to `Table()`: using the Table object in this manner is a lot like passing arguments to a function. For example, to autoload the columns with the engine, you have to specify the keyword arguments `autoload=True` and `autoload_with=engine` to `Table()`.\n",
    "\n",
    "Finally, to view information about the object you just created, you will use the `repr()` function. For any Python object, `repr()` returns a text representation of that object. For SQLAlchemy Table objects, it will return the information about that table contained in the metadata.\n",
    "\n",
    "In this exercise, your job is to reflect the \"census\" table available on your engine into a variable called `census`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import create_engine, MetaData, and Table\n",
    "from sqlalchemy import create_engine, Table, MetaData\n",
    "\n",
    "# Create engine: engine\n",
    "engine = create_engine('sqlite:///'+path+'census.sqlite')\n",
    "\n",
    "# Create a metadata object: metadata\n",
    "metadata = MetaData()\n",
    "\n",
    "# Reflect census table from the engine: census\n",
    "census = Table('census', metadata, autoload=True, autoload_with=engine)\n",
    "\n",
    "# Print census table metadata\n",
    "print(repr(census))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viewing Table details\n",
    "\n",
    "Now you can begin to learn more about the columns and structure of your table. It is important to get an understanding of your database by examining the column names. This can be done by using the `.columns` attribute and accessing the `.keys()` method. For example, `census.columns.keys()` would return a list of column names of the census table.\n",
    "\n",
    "Following this, we can use the metadata container to find out more details about the reflected table such as the columns and their types. For example, information about the table objects are stored in the `metadata.tables` dictionary, so you can get the metadata of your census table with `metadata.tables['census']`. This is similar to your use of the `repr()` function on the census table from the previous exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reflect the census table from the engine: census\n",
    "census = Table('census', metadata, autoload=True, autoload_with=engine)\n",
    "\n",
    "# Print the column names\n",
    "print(census.columns.keys())\n",
    "\n",
    "# Print full metadata of census\n",
    "print(repr(metadata.tables['census']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting data from a Table: raw SQL\n",
    "\n",
    "To access and manipulate the data in the database, we will first need to establish a connection to it by using the `.connect()` method on the engine. This is because the `create_engine()` function that you have used before returns an instance of an engine, but it does not actually open a connection until an action is called that would require a connection, such as a query.\n",
    "\n",
    "Using what we just learned about SQL and applying the `.execute()` method on our connection, we can leverage a raw SQL query to query all the records in our census table. The object returned by the `.execute()` method is a `ResultProxy`. On this `ResultProxy`, we can then use the `.fetchall()` method to get our results - that is, the `ResultSet`.\n",
    "\n",
    "In this exercise, you'll use a traditional SQL query. Notice that when you execute a query using raw SQL, you will query the table in the database directly. In particular, no reflection step is needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "engine = create_engine('sqlite:///'+path+'census.sqlite')\n",
    "\n",
    "# Create a connection on engine\n",
    "connection = engine.connect()\n",
    "\n",
    "# Build select statement for census table: stmt\n",
    "stmt = 'SELECT * FROM census'\n",
    "\n",
    "# Execute the statement and fetch the results: results\n",
    "results = connection.execute(stmt).fetchall()\n",
    "\n",
    "# Print results\n",
    "print(results[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the stmt converts into a SQL statement listing all the records for all the columns in the table.This output is quite unwieldy though, and fetching all the records in the table might take a long time, so in the next exercises, you will learn how to fetch only the first few records of a ResultProxy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting data from a Table with SQLAlchemy\n",
    "\n",
    "It's now time to build your first select statement using SQLAlchemy. **SQLAlchemy** provides a nice \"Pythonic\" way of interacting with databases. When you used raw SQL in the last exercise, you queried the database directly. When using SQLAlchemy, you will go through a `Table` object instead, and SQLAlchemy will take case of translating your query to an appropriate SQL statement for you. So `rather than dealing with the differences between specific dialects of traditional SQL such as MySQL or PostgreSQL, you can leverage the Pythonic framework of SQLAlchemy to streamline your workflow and more efficiently query your data`. For this reason, it is worth learning even if you may already be familiar with traditional SQL.\n",
    "\n",
    "In this exercise, you'll once again build a statement to query all records from the census table. This time, however, you'll make use of the `select()` function of the sqlalchemy module. This function requires a list of tables or columns as the only required argument: for example, `select([my_table])`.\n",
    "\n",
    "You will also fetch only a few records of the `ResultProxy` by using `.fetchmany()` with a size argument specifying the number of records to fetch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import select\n",
    "from sqlalchemy import select\n",
    "\n",
    "# Reflect census table via engine: census\n",
    "census = Table('census', metadata, autoload=True, autoload_with=engine)\n",
    "\n",
    "# Build select statement for census table: stmt\n",
    "stmt = select([census])\n",
    "\n",
    "# Print the emitted statement to see the SQL string\n",
    "print(stmt)\n",
    "\n",
    "# Execute the statement on connection and fetch 10 records: result\n",
    "results = connection.execute(stmt).fetchmany(size=10)\n",
    "\n",
    "# Execute the statement and print the results\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling a ResultSet\n",
    "\n",
    "Recall the differences between a `ResultProxy` and a `ResultSet`:\n",
    "\n",
    "- `ResultProxy`: The object returned by the `.execute()` method. It can be used in a variety of ways to get the data returned by the query.\n",
    "- `ResultSet`: The actual data asked for in the query when using a fetch method such as `.fetchall()` on a `ResultProxy`.\n",
    "\n",
    "This separation between the `ResultSet` and `ResultProxy` allows us to fetch as much or as little data as we desire.\n",
    "\n",
    "Once we have a `ResultSet`, we can use Python to access all the data within it by column name and by list style indexes. For example, you can get the first row of the results by using `results[0]`. With that first row then assigned to a variable `first_row`, you can get data from the first column by either using `first_row[0]` or by column name such as `first_row['column_name']`. You'll now practice exactly this using the `ResultSet` you obtained from the census table in the previous exercise. It is stored in the variable `results`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the first row of the results by using an index: first_row\n",
    "first_row = results[0]\n",
    "\n",
    "# Print the first row of the results\n",
    "print(first_row)\n",
    "\n",
    "# Print the first column of the first row by accessing it by its index\n",
    "print(first_row[0])\n",
    "\n",
    "# Print the 'state' column of the first row by using its name\n",
    "print(first_row['state'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connecting to a PostgreSQL database\n",
    "\n",
    "In these exercises, you will be working with real databases hosted on the cloud via Amazon Web Services (AWS)!\n",
    "\n",
    "Let's begin by connecting to a **PostgreSQL** database. When connecting to a PostgreSQL database, many prefer to use the `psycopg2` database driver as it supports practically all of PostgreSQL's features efficiently and is the standard dialect for `PostgreSQL in SQLAlchemy`.\n",
    "\n",
    "We use the `create_engine()` function and a **connection string** to connect to a database. In general, connection strings have the form `\"dialect+driver://username:password@host:port/database\"`\n",
    "\n",
    "There are three components to the **connection string** in this exercise: the dialect and driver `('postgresql+psycopg2://')`, followed by the username and password `('student:datacamp')`, followed by the host and port `('@postgresql.csrrinzqubik.us-east-1.rds.amazonaws.com:5432/')`, and finally, the database name `('census')`. You will have to pass this string as an argument to `create_engine()` in order to connect to the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import create_engine function\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Create an engine to the census database\n",
    "engine = create_engine('postgresql+psycopg2://student:datacamp@postgresql.csrrinzqubik.us-east-1.rds.amazonaws.com:5432/census')\n",
    "\n",
    "# Use the .table_names() method on the engine to print the table names\n",
    "print(engine.table_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter data selected from a Table - Simple\n",
    "\n",
    "Having connected to the database, it's now time to practice filtering your queries!\n",
    "\n",
    "A `where()` clause is used to filter the data that a statement returns. For example, to select all the records from the census table where the sex is Female (or 'F') we would do the following: `select([census]).where(census.columns.sex == 'F')`\n",
    "\n",
    "In addition to `==` we can use basically any python comparison operator (such as `<=`, `!=`, etc) in the `where()` clause."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a select query: stmt\n",
    "stmt = select([census])\n",
    "\n",
    "# Add a where clause to filter the results to only those for New York : stmt_filtered\n",
    "stmt = stmt.where(census.columns.state == 'New York')\n",
    "\n",
    "# Execute the query to retrieve all the data returned: results\n",
    "results = connection.execute(stmt).fetchall()\n",
    "\n",
    "# Loop over the results and print the age, sex, and pop2000\n",
    "for result in results:\n",
    "    print(result.age, result.sex, result.pop2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter data selected from a Table - Expressions\n",
    "\n",
    "In addition to standard Python comparators, we can also use methods such as `in_()` to create more powerful `where()` clauses. You can see a full list of expressions in the [SQLAlchemy Documentation](https://docs.sqlalchemy.org/en/13/core/sqlelement.html#module-sqlalchemy.sql.expression).\n",
    "\n",
    "Method `in_()`, when used on a column, allows us to include records where the value of a column is among a list of possible values. For example, `where(census.columns.age.in_([20, 30, 40]))` will return only records for people who are exactly 20, 30, or 40 years old.\n",
    "\n",
    "In this exercise, you will continue working with the `census` table, and select the records for people from the three most densely populated states. The list of those states has already been created for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list of states for which we want results\n",
    "states = ['New York', 'California', 'Texas']\n",
    "\n",
    "# Create a query for the census table: stmt\n",
    "stmt = select([census])\n",
    "\n",
    "# Append a where clause to match all the states in_ the list states\n",
    "stmt = stmt.where(census.columns.state.in_(states))\n",
    "\n",
    "# Loop over the ResultProxy and print the state and its population in 2000\n",
    "for row in connection.execute(stmt):\n",
    "    print(row.state, row.pop2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Along with `in_`, you can also use methods like `and_`, `any_` to create more powerful `where()` clauses. You might have noticed that we did not use any of the fetch methods to retrieve a `ResultSet` like in the previous exercises. Indeed, if you are only interested in manipulating one record at a time, you can iterate over the `ResultProxy` directly!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter data selected from a Table - Advanced\n",
    "\n",
    "**SQLAlchemy** also allows users to use conjunctions such as `and_()`, `or_()`, and `not_()` to build more complex filtering. For example, we can get a set of records for people in New York who are 21 or 37 years old with the following code:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "select([census]).where(\n",
    "  and_(census.columns.state == 'New York',\n",
    "       or_(census.columns.age == 21,\n",
    "          census.columns.age == 37\n",
    "         )\n",
    "      )\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An equivalent SQL statement would be,for example, `SELECT * FROM census WHERE state = 'New York' AND (age = 21 OR age = 37)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import and_\n",
    "from sqlalchemy import and_\n",
    "\n",
    "# Build a query for the census table: stmt\n",
    "stmt = select([census])\n",
    "\n",
    "# Append a where clause to select only non-male records from California using and_\n",
    "stmt = stmt.where(\n",
    "    # The state of California with a non-male sex\n",
    "    and_(census.columns.state == 'California',\n",
    "         census.columns.sex != 'M'\n",
    "         )\n",
    ")\n",
    "\n",
    "# Loop over the ResultProxy printing the age and sex\n",
    "for result in connection.execute(stmt):\n",
    "    print(result.age, result.sex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ordering by a single column\n",
    "\n",
    "To sort the result output by a field, we use the `.order_by()` method. By default, the `.order_by()` method sorts from lowest to highest on the supplied column. You just have to pass in the name of the column you want sorted to `.order_by()`.\n",
    "\n",
    "For example, `stmt.order_by(census.columns.state)` can be used to sort the result output by the state column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a query to select the state column: stmt\n",
    "stmt = select([census.columns.state])\n",
    "\n",
    "# Order stmt by the state column\n",
    "stmt = stmt.order_by(census.columns.state)\n",
    "\n",
    "# Execute the query and store the results: results\n",
    "results = connection.execute(stmt).fetchall()\n",
    "\n",
    "# Print the first 10 results\n",
    "print(results[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ordering in descending order by a single column\n",
    "\n",
    "You can also use `.order_by()` to sort from highest to lowest by wrapping a column in the `desc()` function. Although you haven't seen this function in action, it generalizes what you have already learned.\n",
    "\n",
    "Pass `desc()` (for \"descending\") inside an `.order_by()` with the name of the column you want to sort by. For instance, `stmt.order_by(desc(table.columns.column_name))` sorts column_name in descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import desc\n",
    "from sqlalchemy import desc\n",
    "\n",
    "# Build a query to select the state column: stmt\n",
    "stmt = select([census.columns.state])\n",
    "\n",
    "# Order stmt by state in descending order: rev_stmt\n",
    "rev_stmt = stmt.order_by(desc(census.columns.state))\n",
    "\n",
    "# Execute the query and store the results: rev_results\n",
    "rev_results = connection.execute(rev_stmt).fetchall()\n",
    "\n",
    "# Print the first 10 rev_results\n",
    "print(rev_results[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ordering by multiple columns\n",
    "\n",
    "We can pass multiple arguments to the `.order_by()` method to order by multiple columns. In fact, we can also sort in ascending or descending order for each individual column. Each column in the `.order_by()` method is fully sorted from left to right. This means that the first column is completely sorted, and then within each matching group of values in the first column, it's sorted by the next column in the `.order_by()` method. This process is repeated until all the columns in the `.order_by()` are sorted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a query to select state and age: stmt\n",
    "stmt = select([census.columns.state, census.columns.age])\n",
    "\n",
    "# Append order by to ascend by state and descend by age\n",
    "stmt = stmt.order_by(census.columns.state, desc(census.columns.age))\n",
    "\n",
    "# Execute the statement and store all the records: results\n",
    "results = connection.execute(stmt).fetchall()\n",
    "\n",
    "# Print the first 20 results\n",
    "print(results[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Counting distinct data\n",
    "\n",
    "**SQLAlchemy's** `func` module provides access to built-in SQL functions that can make operations like counting and summing faster and more efficient.\n",
    "\n",
    "For example, you can use `func.sum()` to get a sum of the pop2008 column of census as shown below: `select([func.sum(census.columns.pop2008)])`. \n",
    "\n",
    "If instead you want to count the number of values in pop2008, you could use `func.count()` like this: `select([func.count(census.columns.pop2008)])`.\n",
    "\n",
    "Furthermore, if you only want to count the distinct values of pop2008, you can use the `.distinct()` method: `select([func.count(census.columns.pop2008.distinct())])`.\n",
    "\n",
    "In this exercise, you will practice using `func.count()` and `.distinct()` to get a count of the distinct number of states in census.\n",
    "\n",
    "So far, you've seen `.fetchall()`, `.fetchmany()`, and `.first()` used on a `ResultProxy` to get the results. The `ResultProxy` also has a method called `.scalar()` for getting just the value of a query that returns only one row and column.\n",
    "\n",
    "This can be very useful when you are querying for just a `count` or `sum`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import func\n",
    "\n",
    "# Build a query to count the distinct states values: stmt\n",
    "stmt = select([func.count(census.columns.state.distinct())])\n",
    "\n",
    "# Execute the query and store the scalar result: distinct_state_count\n",
    "distinct_state_count = connection.execute(stmt).scalar()\n",
    "\n",
    "# Print the distinct_state_count\n",
    "print(distinct_state_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count of records by state\n",
    "\n",
    "Often, we want to get a count for each record with a particular value in another column. The `.group_by()` method helps answer this type of query. You can pass a column to the `.group_by()` method and use in an aggregate function like `sum()` or `count()`. Much like the .order_by() method, `.group_by()` can take multiple columns as arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import func\n",
    "from sqlalchemy import func\n",
    "\n",
    "# Build a query to select the state and count of ages by state: stmt\n",
    "stmt = select([census.columns.state, func.count(census.columns.age)])\n",
    "\n",
    "# Group stmt by state\n",
    "stmt = stmt.group_by(census.columns.state)\n",
    "\n",
    "# Execute the statement and store all the records: results\n",
    "results = connection.execute(stmt).fetchall()\n",
    "\n",
    "# Print results\n",
    "print(results)\n",
    "\n",
    "# Print the keys/column names of the results returned\n",
    "print(results[0].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the key for the count method just came out as count_1. This can make it hard in complex queries to tell what column is being referred to: In the next exercise, you'll practice assigning more descriptive labels when performing such calculations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determining the population sum by state\n",
    "\n",
    "To avoid confusion with query result column names like `count_1`, we can use the `.label()` method to provide a name for the resulting column. This gets appended to the function method we are using, and its argument is the name we want to use.\n",
    "\n",
    "We can pair `func.sum()` with `.group_by()` to get a sum of the population by State and use the `label()` method to name the output.\n",
    "\n",
    "We can also create the `func.sum()` expression before using it in the select statement. We do it the same way we would inside the select statement and store it in a variable. Then we use that variable in the select statement where the `func.sum()` would normally be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import func\n",
    "from sqlalchemy import func\n",
    "\n",
    "# Build an expression to calculate the sum of pop2008 labeled as population\n",
    "pop2008_sum = func.sum(census.columns.pop2008).label('population')\n",
    "\n",
    "# Build a query to select the state and sum of pop2008: stmt\n",
    "stmt = select([census.columns.state, pop2008_sum])\n",
    "\n",
    "# Group stmt by state\n",
    "stmt = stmt.group_by(census.columns.state)\n",
    "\n",
    "# Execute the statement and store all the records: results\n",
    "results = connection.execute(stmt).fetchall()\n",
    "\n",
    "# Print results\n",
    "print(results)\n",
    "\n",
    "# Print the keys/column names of the results returned\n",
    "print(results[0].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResultsSets and pandas dataframes\n",
    "\n",
    "We can feed a `ResultSet` directly into a pandas `DataFrame`, which is the workhorse of many Data Scientists in PythonLand. In this exercise, you'll convert a ResultSet into a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Create a DataFrame from the results: df\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "# Set column names\n",
    "df.columns = results[0].keys()\n",
    "\n",
    "# Print the Dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From SQLAlchemy results to a plot\n",
    "\n",
    "We can also take advantage of pandas and `Matplotlib` to build figures of our data. Remember that data visualization is essential for both exploratory data analysis and communication of your data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pyplot as plt from matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Create a DataFrame from the results: df\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "# Set Column names\n",
    "df.columns = results[0].keys()\n",
    "\n",
    "# Print the DataFrame\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the DataFrame\n",
    "df.plot.bar()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connecting to a MySQL database\n",
    "\n",
    "Before you jump into the calculation exercises, let's begin by connecting to our database. Recall that before you connected to a PostgreSQL database. Now, you'll connect to a **MySQL** database, for which many prefer to use the `pymysql` database driver, which, like `psycopg2` for **PostgreSQL**, you have to install prior to use.\n",
    "\n",
    "This connection string is going to start with `'mysql+pymysql://'`, indicating which dialect and driver you're using to establish the connection. The dialect block is followed by the `'username:password'` combo. Next, you specify the host and port with the following `'@host:port/'`. Finally, you wrap up the connection string with the `'database_name'`.\n",
    "\n",
    "Now you'll practice connecting to a MySQL database: it will be the same census database that you have already been working with. One of the great things about **SQLAlchemy** is that, after connecting, it abstracts over the type of database it has connected to and you can write the same SQLAlchemy code, regardless!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['census', 'state_fact']\n"
     ]
    }
   ],
   "source": [
    "# ! conda install pymysql\n",
    "\n",
    "# Import create_engine function\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Create an engine to the census database\n",
    "engine = create_engine('mysql+pymysql://student:datacamp@courses.csrrinzqubik.us-east-1.rds.amazonaws.com:3306/census')\n",
    "\n",
    "# Print the table names\n",
    "print(engine.table_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating a difference between two columns\n",
    "\n",
    "Often, you'll need to perform math operations as part of a query, such as if you wanted to calculate the change in population from 2000 to 2008. For math operations on numbers, the operators in SQLAlchemy work the same way as they do in Python.\n",
    "\n",
    "You can use these operators to perform addition (`+`), subtraction (`-`), multiplication (`*`), division (`/`), and modulus (`%`) operations. Note: They behave differently when used with non-numeric column types.\n",
    "\n",
    "Let's now find the top 5 states by population growth between 2000 and 2008."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import select\n",
    "from sqlalchemy import select, MetaData, func, desc\n",
    "\n",
    "# Create a metadata object: metadata\n",
    "metadata = MetaData()\n",
    "\n",
    "census = Table('census', metadata, autoload=True, autoload_with=engine)\n",
    "state_fact = Table('state_fact', metadata, autoload=True, autoload_with=engine)\n",
    "\n",
    "# Create a connection on engine\n",
    "connection = engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texas:40137\n",
      "California:35406\n",
      "Florida:21954\n",
      "Arizona:14377\n",
      "Georgia:13357\n"
     ]
    }
   ],
   "source": [
    "# Build query to return state names by population difference from 2008 to 2000: stmt\n",
    "stmt = select([census.columns.state, (census.columns.pop2008 - census.columns.pop2000).label('pop_change')])\n",
    "\n",
    "# Append group by for the state: stmt_grouped\n",
    "stmt_grouped = stmt.group_by(census.columns.state)\n",
    "\n",
    "# Append order by for pop_change descendingly: stmt_ordered\n",
    "stmt_ordered = stmt_grouped.order_by(desc('pop_change'))\n",
    "\n",
    "# Return only 5 results: stmt_top5\n",
    "stmt_top5 = stmt_ordered.limit(5)\n",
    "\n",
    "# Use connection to execute stmt_top5 and fetch all results\n",
    "results = connection.execute(stmt_top5).fetchall()\n",
    "\n",
    "# Print the state and population change for each record\n",
    "for result in results:\n",
    "    print('{}:{}'.format(result.state, result.pop_change))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determining the overall percentage of women\n",
    "\n",
    "It's possible to combine functions and operators in a single select statement as well. These combinations can be exceptionally handy when we want to calculate percentages or averages, and we can also use the `case()` expression to operate on data that meets specific criteria while not affecting the query as a whole. The `case()` expression accepts a list of conditions to match and the column to return if the condition matches, followed by an `else_` if none of the conditions match. We can wrap this entire expression in any function or math operation we like.\n",
    "\n",
    "Often when performing integer division, we want to get a float back. While some databases will do this automatically, you can use the `cast()` function to convert an expression to a particular type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50.7455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ksatola/anaconda3/lib/python3.7/site-packages/sqlalchemy/dialects/mysql/base.py:1340: SAWarning: Datatype FLOAT does not support CAST on MySQL; the CAST will be skipped.\n",
      "  % self.dialect.type_compiler.process(cast.typeclause.type)\n"
     ]
    }
   ],
   "source": [
    "# import case, cast and Float from sqlalchemy\n",
    "from sqlalchemy import case, cast, Float\n",
    "\n",
    "# Build an expression to calculate female population in 2000\n",
    "female_pop2000 = func.sum(\n",
    "    case([\n",
    "        (census.columns.sex == 'F', census.columns.pop2000)\n",
    "    ], else_=0))\n",
    "\n",
    "# Cast an expression to calculate total population in 2000 to Float\n",
    "total_pop2000 = cast(func.sum(census.columns.pop2000), Float)\n",
    "\n",
    "# Build a query to calculate the percentage of women in 2000: stmt\n",
    "stmt = select([female_pop2000 / total_pop2000* 100])\n",
    "\n",
    "# Execute the query and store the scalar result: percent_female\n",
    "percent_female = connection.execute(stmt).scalar()\n",
    "\n",
    "# Print the percentage\n",
    "print(percent_female)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like there were slightly more women than men in the US population in 2000!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automatic joins with an established relationship\n",
    "\n",
    "If you have two tables that already have an established **relationship**, you can automatically use that relationship by just adding the columns we want from each table to the select statement: `stmt = select([census.columns.pop2008, state_fact.columns.abbreviation])` in order to **join** the census and state_fact tables and select the pop2008 column from the first and the abbreviation column from the second. In this case, the census and state_fact tables had a pre-defined relationship: the state column of the former corresponded to the name column of the latter.\n",
    "\n",
    "In this exercise, you'll use the same predefined relationship to select the pop2000 and abbreviation columns!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pop2000 89600\n",
      "abbreviation IL\n"
     ]
    }
   ],
   "source": [
    "# Reflect state_fact table from the engine: census\n",
    "#state_fact = Table('state_fact', metadata, autoload=True, autoload_with=engine)\n",
    "\n",
    "# Build a statement to join census and state_fact tables: stmt\n",
    "stmt = select([census.columns.pop2000, state_fact.columns.abbreviation])\n",
    "\n",
    "# Execute the statement and get the first result: result\n",
    "result = connection.execute(stmt).first()\n",
    "\n",
    "# Loop over the keys in the result object and print the key and value\n",
    "for key in result.keys():\n",
    "    print(key, getattr(result, key))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joins\n",
    "\n",
    "If you aren't selecting columns from both tables or the two tables don't have a defined **relationship**, you can still use the `.join()` method on a table to join it with another table and get extra data related to our query. The `join()` takes the table object you want to join in as the first argument and a condition that indicates how the tables are related to the second argument. Finally, you use the `.select_from()` method on the select statement to wrap the join clause. For example, the following code can be used to join the census table to the state_fact table such that the state column of the census table corresponded to the name column of the state_fact table."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "stmt = stmt.select_from(\n",
    "    census.join(\n",
    "        state_fact, census.columns.state == \n",
    "        state_fact.columns.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state Illinois\n",
      "sex M\n",
      "age 0\n",
      "pop2000 89600\n",
      "pop2008 95012\n",
      "id 13\n",
      "name Illinois\n",
      "abbreviation IL\n",
      "country USA\n",
      "type state\n",
      "sort 10\n",
      "status current\n",
      "occupied occupied\n",
      "notes \n",
      "fips_state 17\n",
      "assoc_press Ill.\n",
      "standard_federal_region V\n",
      "census_region 2\n",
      "census_region_name Midwest\n",
      "census_division 3\n",
      "census_division_name East North Central\n",
      "circuit_court 7\n"
     ]
    }
   ],
   "source": [
    "# Build a statement to select all the census and state_fact tables: stmt\n",
    "stmt = select([census, state_fact])\n",
    "\n",
    "# Add a select_from clause that wraps a join for the census and state_fact\n",
    "# tables where the census state column and state_fact name column match\n",
    "stmt_join = stmt.select_from(\n",
    "    census.join(state_fact, census.columns.state == state_fact.columns.name))\n",
    "\n",
    "# Execute the statement and get the first result: result\n",
    "result = connection.execute(stmt_join).first()\n",
    "\n",
    "# Loop over the keys in the result object and print the key and value\n",
    "for key in result.keys():\n",
    "    print(key, getattr(result, key))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More practice with joins\n",
    "\n",
    "You can use the same select statement you built in the last exercise, however, let's add a twist and only return a few columns and use the other table in a `group_by()` clause."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Alabama', Decimal('4681422'), 'East South Central')\n",
      "('Alaska', Decimal('664546'), 'Pacific')\n",
      "('Arizona', Decimal('10698743'), 'Mountain')\n",
      "('Arkansas', Decimal('4343608'), 'West South Central')\n",
      "('California', Decimal('56952946'), 'Pacific')\n",
      "('Colorado', Decimal('7474086'), 'Mountain')\n",
      "('Connecticut', Decimal('3727540'), 'New England')\n",
      "('Delaware', Decimal('869221'), 'South Atlantic')\n",
      "('Florida', Decimal('20339477'), 'South Atlantic')\n",
      "('Georgia', Decimal('9622508'), 'South Atlantic')\n",
      "('Hawaii', Decimal('1250676'), 'Pacific')\n",
      "('Idaho', Decimal('1518914'), 'Mountain')\n",
      "('Illinois', Decimal('16274391'), 'East North Central')\n",
      "('Indiana', Decimal('7378168'), 'East North Central')\n",
      "('Iowa', Decimal('3000490'), 'West North Central')\n",
      "('Kansas', Decimal('4045759'), 'West North Central')\n",
      "('Kentucky', Decimal('4525061'), 'East South Central')\n",
      "('Louisiana', Decimal('5183486'), 'West South Central')\n",
      "('Maine', Decimal('2018932'), 'New England')\n",
      "('Maryland', Decimal('7246747'), 'South Atlantic')\n",
      "('Massachusetts', Decimal('6492024'), 'New England')\n",
      "('Michigan', Decimal('14154883'), 'East North Central')\n",
      "('Minnesota', Decimal('6922744'), 'West North Central')\n",
      "('Mississippi', Decimal('4560123'), 'East South Central')\n",
      "('Missouri', Decimal('7836564'), 'West North Central')\n",
      "('Montana', Decimal('1172060'), 'Mountain')\n",
      "('Nebraska', Decimal('2348009'), 'West North Central')\n",
      "('Nevada', Decimal('3925294'), 'Mountain')\n",
      "('New Hampshire', Decimal('1949141'), 'New England')\n",
      "('New Jersey', Decimal('8670204'), 'Mid-Atlantic')\n",
      "('New Mexico', Decimal('3263613'), 'Mountain')\n",
      "('New York', Decimal('26837888'), 'Mid-Atlantic')\n",
      "('North Carolina', Decimal('9121606'), 'South Atlantic')\n",
      "('North Dakota', Decimal('634282'), 'West North Central')\n",
      "('Ohio', Decimal('16565266'), 'East North Central')\n",
      "('Oklahoma', Decimal('4736015'), 'West South Central')\n",
      "('Oregon', Decimal('4901890'), 'Pacific')\n",
      "('Pennsylvania', Decimal('17277878'), 'Mid-Atlantic')\n",
      "('Rhode Island', Decimal('1096276'), 'New England')\n",
      "('South Carolina', Decimal('4438870'), 'South Atlantic')\n",
      "('South Dakota', Decimal('800997'), 'West North Central')\n",
      "('Tennessee', Decimal('8524299'), 'East South Central')\n",
      "('Texas', Decimal('39829923'), 'West South Central')\n",
      "('Utah', Decimal('2730919'), 'Mountain')\n",
      "('Vermont', Decimal('820523'), 'New England')\n",
      "('Virginia', Decimal('9593860'), 'South Atlantic')\n",
      "('Washington', Decimal('8080837'), 'Pacific')\n",
      "('West Virginia', Decimal('1812879'), 'South Atlantic')\n",
      "('Wisconsin', Decimal('7518844'), 'East North Central')\n",
      "('Wyoming', Decimal('653500'), 'Mountain')\n"
     ]
    }
   ],
   "source": [
    "# Build a statement to select the state, sum of 2008 population and census\n",
    "# division name: stmt\n",
    "stmt = select([\n",
    "    census.columns.state,\n",
    "    func.sum(census.columns.pop2008),\n",
    "    state_fact.columns.census_division_name\n",
    "])\n",
    "\n",
    "# Append select_from to join the census and state_fact tables by the census state and state_fact name columns\n",
    "stmt_joined = stmt.select_from(\n",
    "    census.join(state_fact, census.columns.state == state_fact.columns.name)\n",
    ")\n",
    "\n",
    "# Append a group by for the state_fact name column\n",
    "stmt_grouped = stmt_joined.group_by(state_fact.columns.name)\n",
    "\n",
    "# Execute the statement and get the results: results\n",
    "results = connection.execute(stmt_grouped).fetchall()\n",
    "\n",
    "# Loop over the results object and print each record.\n",
    "for record in results:\n",
    "    print(record)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using alias to handle same table joined queries\n",
    "\n",
    "Often, you'll have tables that contain **hierarchical data**, such as employees and managers who are also employees. For this reason, you may wish to join a table to itself on different columns. The `.alias()` method, which creates a copy of a table, helps accomplish this task. Because it's the same table, you only need a where clause to specify the join condition.\n",
    "\n",
    "Here, you'll use the `.alias()` method to build a query to join the employees table against itself to determine to whom everyone reports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'employees' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-35d23de688ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Make an alias of the employees table: managers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmanagers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0memployees\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malias\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Build a query to select names of managers and their employees: stmt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m stmt = select(\n",
      "\u001b[0;31mNameError\u001b[0m: name 'employees' is not defined"
     ]
    }
   ],
   "source": [
    "# Make an alias of the employees table: managers\n",
    "managers = employees.alias()\n",
    "\n",
    "# Build a query to select names of managers and their employees: stmt\n",
    "stmt = select(\n",
    "    [managers.columns.name.label('manager'),\n",
    "     employees.columns.name.label('employee')]\n",
    ")\n",
    "\n",
    "# Match managers id with employees mgr: stmt_matched\n",
    "stmt_matched = stmt.where(managers.columns.id == employees.columns.mgr)\n",
    "\n",
    "# Order the statement by the managers name: stmt_ordered\n",
    "stmt_ordered = stmt_matched.order_by(managers.columns.name)\n",
    "\n",
    "# Execute statement: results\n",
    "results = connection.execute(stmt_ordered).fetchall()\n",
    "\n",
    "# Print records\n",
    "for record in results:\n",
    "    print(record)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<script.py> output:\n",
    "    ('FILLMORE', 'GRANT')\n",
    "    ('FILLMORE', 'ADAMS')\n",
    "    ('FILLMORE', 'MONROE')\n",
    "    ('GARFIELD', 'JOHNSON')\n",
    "    ('GARFIELD', 'LINCOLN')\n",
    "    ('GARFIELD', 'POLK')\n",
    "    ('GARFIELD', 'WASHINGTON')\n",
    "    ('HARDING', 'TAFT')\n",
    "    ('HARDING', 'HOOVER')\n",
    "    ('JACKSON', 'HARDING')\n",
    "    ('JACKSON', 'GARFIELD')\n",
    "    ('JACKSON', 'FILLMORE')\n",
    "    ('JACKSON', 'ROOSEVELT')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leveraging functions and group_bys with hierarchical data\n",
    "\n",
    "It's also common to want to roll up data which is in a **hierarchical table**. Rolling up data requires making sure you're careful which alias you use to perform the group_bys and which table you use for the function.\n",
    "\n",
    "Here, your job is to get a count of employees for each manager."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make an alias of the employees table: managers\n",
    "managers = employees.alias()\n",
    "\n",
    "# Build a query to select names of managers and counts of their employees: stmt\n",
    "stmt = select([managers.columns.name, func.count(employees.columns.id)])\n",
    "\n",
    "# Append a where clause that ensures the manager id and employee mgr are equal\n",
    "stmt_matched = stmt.where(managers.columns.id == employees.columns.mgr)\n",
    "\n",
    "# Group by Managers Name\n",
    "stmt_grouped = stmt_matched.group_by(managers.columns.name)\n",
    "\n",
    "# Execute statement: results\n",
    "results = connection.execute(stmt_grouped).fetchall()\n",
    "\n",
    "# print manager\n",
    "for record in results:\n",
    "    print(record)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working on blocks of records\n",
    "\n",
    "Sometimes you may have the need to work on a **large ResultProxy**, and `you may not have the memory to load all the results at once`. To work around that issue, you can get blocks of rows from the ResultProxy by using the `.fetchmany()` method inside a loop. With `.fetchmany()`, give it an argument of the number of records you want. When you reach an empty list, there are no more rows left to fetch, and you have processed all the results of the query. Then you need to use the `.close()` method to close out the connection to the database.\n",
    "\n",
    "You'll now have the chance to practice this on a large ResultProxy called results_proxy that has been pre-loaded for you to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'more_results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-1bc3868ff499>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Start a while loop checking for more results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mwhile\u001b[0m \u001b[0mmore_results\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;31m# Fetch the first 50 results from the ResultProxy: partial_results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mpartial_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults_proxy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetchmany\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'more_results' is not defined"
     ]
    }
   ],
   "source": [
    "# Start a while loop checking for more results\n",
    "while more_results:\n",
    "    # Fetch the first 50 results from the ResultProxy: partial_results\n",
    "    partial_results = results_proxy.fetchmany(50)\n",
    "\n",
    "    # if empty list, set more_results to False\n",
    "    if partial_results == []:\n",
    "        more_results = False\n",
    "\n",
    "    # Loop over the fetched records and increment the count for the state\n",
    "    for row in partial_results:\n",
    "        if row.state in state_count:\n",
    "            state_count[row.state] += 1\n",
    "        else:\n",
    "            state_count[row.state] = 1\n",
    "\n",
    "# Close the ResultProxy, and thus the connection\n",
    "results_proxy.close()\n",
    "\n",
    "# Print the count by state\n",
    "print(state_count)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<script.py> output:\n",
    "    {'Illinois': 172, 'New Jersey': 172, 'District of Columbia': 172, 'North Dakota': 75, 'Florida': 172, 'Maryland': 49, 'Idaho': 172, 'Massachusetts': 16}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating tables with SQLAlchemy\n",
    "\n",
    "Previously, you used the Table object to reflect a table from an existing database, but what if you wanted to create a new table? You'd still use the Table object; however, you'd need to replace the `autoload` and `autoload_with` parameters with `Column` objects.\n",
    "\n",
    "The `Column` object takes a name, a SQLAlchemy type with an optional format, and optional keyword arguments for different constraints.\n",
    "\n",
    "After defining the table, you can create the table in the database by using the `.create_all()` method on metadata and supplying the engine as the only parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table('data', MetaData(bind=None), Column('name', String(length=255), table=<data>), Column('count', Integer(), table=<data>), Column('amount', Float(), table=<data>), Column('valid', Boolean(), table=<data>), schema=None)\n"
     ]
    }
   ],
   "source": [
    "# Import Table, Column, String, Integer, Float, Boolean from sqlalchemy\n",
    "from sqlalchemy import Table, Column, String, Integer, Float, Boolean, create_engine\n",
    "\n",
    "engine = create_engine('sqlite:///'+path+'kstest.sqlite')\n",
    "metadata = MetaData()\n",
    "\n",
    "# Define a new table with a name, count, amount, and valid column: data\n",
    "data = Table('data', metadata,\n",
    "             Column('name', String(255)),\n",
    "             Column('count', Integer()),\n",
    "             Column('amount', Float()),\n",
    "             Column('valid', Boolean())\n",
    ")\n",
    "\n",
    "# Use the metadata to create the table\n",
    "metadata.create_all(engine)\n",
    "\n",
    "# Print table details\n",
    "print(repr(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constraints and data defaults\n",
    "\n",
    "You're now going to practice creating a table with some **constraints**! Often, you'll need to make sure that a column is unique, nullable, a positive value, or related to a column in another table. This is where constraints come in.\n",
    "\n",
    "In addition to constraints, you can also set a **default value** for the column if no data is passed to it via the `default` keyword on the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table('data', MetaData(bind=None), Column('name', String(length=255), table=<data>), Column('count', Integer(), table=<data>, default=ColumnDefault(1)), Column('amount', Float(), table=<data>), Column('valid', Boolean(), table=<data>, default=ColumnDefault(False)), schema=None)\n"
     ]
    }
   ],
   "source": [
    "# Import Table, Column, String, Integer, Float, Boolean from sqlalchemy\n",
    "from sqlalchemy import Table, Column, String, Integer, Float, Boolean\n",
    "\n",
    "engine = create_engine('sqlite:///'+path+'kstest.sqlite')\n",
    "metadata = MetaData()\n",
    "connection = engine.connect()\n",
    "\n",
    "# Define a new table with a name, count, amount, and valid column: data\n",
    "data = Table('data', metadata,\n",
    "             Column('name', String(255), unique=True),\n",
    "             Column('count', Integer(), default=1),\n",
    "             Column('amount', Float()),\n",
    "             Column('valid', Boolean(), default=False)\n",
    ")\n",
    "\n",
    "# Use the metadata to create the table\n",
    "metadata.create_all(engine)\n",
    "\n",
    "# Print the table details\n",
    "print(repr(metadata.tables['data']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inserting a single row\n",
    "\n",
    "There are several ways to perform an `insert` with SQLAlchemy; however, we are going to focus on the one that follows the same pattern as the select statement.\n",
    "\n",
    "It uses an `insert` statement where you specify the table as an argument, and supply the data you wish to insert into the value via the `.values()` method as keyword arguments. For example, if `my_table` contains columns `my_col_1` and `my_col_2`, then `insert(my_table).values(my_col_1=5, my_col_2=\"Example\")` will create a row in my_table with the value in my_col_1 equal to 5 and value in my_col_2 equal to \"Example\".\n",
    "\n",
    "Notice the difference in syntax: when appending a `where` statement to an existing statement, we include the name of the table as well as the name of the column, for example `new_stmt = old_stmt.where(my_tbl.columns.my_col == 15)`. This is necessary because the existing statement might involve several tables.\n",
    "\n",
    "On the other hand, you can only insert a record into a single table, so you do not need to include the name of the table when using `values()` to insert, e.g. `stmt = insert(my_table).values(my_col = 10)`.\n",
    "\n",
    "Here, the name of the table is `data`. You can run `repr(data)` in the console to examine the structure of the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "('Anna', 1, 1000.0, True)\n"
     ]
    }
   ],
   "source": [
    "# Import insert and select from sqlalchemy\n",
    "from sqlalchemy import insert, select\n",
    "\n",
    "# Build an insert statement to insert a record into the data table: insert_stmt\n",
    "insert_stmt = insert(data).values(name='Anna', count=1, amount=1000.00, valid=True)\n",
    "\n",
    "# Execute the insert statement via the connection: results\n",
    "results = connection.execute(insert_stmt)\n",
    "\n",
    "# Print result rowcount\n",
    "print(results.rowcount)\n",
    "\n",
    "# Build a select statement to validate the insert: select_stmt\n",
    "select_stmt = select([data]).where(data.columns.name == 'Anna')\n",
    "\n",
    "# Print the result of executing the query.\n",
    "print(connection.execute(select_stmt).first())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inserting multiple records at once\n",
    "\n",
    "When inserting multiple records at once, you do not use the `.values()` method. Instead, you'll want to first build a list of dictionaries that represents the data you want to insert, with keys being the names of the columns. in the `.execute()` method, you can pair this list of dictionaries with an insert statement, which will insert all the records in your list of dictionaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "# Build a list of dictionaries: values_list\n",
    "values_list = [\n",
    "    {'name': 'Anna', 'count': 1, 'amount': 1000.00, 'valid': True},\n",
    "    {'name': 'Taylor', 'count': 1, 'amount': 750.00, 'valid': False}\n",
    "]\n",
    "\n",
    "# Build an insert statement for the data table: stmt\n",
    "stmt = insert(data)\n",
    "\n",
    "# Execute stmt with the values_list: results\n",
    "results = connection.execute(stmt, values_list)\n",
    "\n",
    "# Print rowcount\n",
    "print(results.rowcount)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading a CSV into a table\n",
    "\n",
    "You're now going to learn how to load the contents of a CSV file into a table. One way to do that would be to read a CSV file line by line, create a dictionary from each line, and then use insert(), like you did in the previous exercise.\n",
    "\n",
    "But there is a faster way using `pandas`. You can read a CSV file into a `DataFrame` using the `read_csv()` function. Then, you can call the `.to_sql()` method on the DataFrame to load it into a SQL table in a database. **The columns of the DataFrame should match the columns of the SQL table**.\n",
    "\n",
    "`.to_sql()` has many parameters, but in this exercise we will use the following:\n",
    "\n",
    "- `name` is the name of the SQL table (as a string).\n",
    "- `con` is the connection to the database that you will use to upload the data.\n",
    "- `if_exists` specifies how to behave if the table already exists in the database; possible values are \"fail\", \"replace\", and \"append\".\n",
    "- `index` (True or False) specifies whether to write the DataFrame's index as a column.\n",
    "\n",
    "In this exercise, you will upload the data contained in the `census.csv` file into an existing table \"census\". The connection to the database has already been created for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table('census', MetaData(bind=None), Column('state', String(length=255), table=<census>), Column('sex', String(length=1), table=<census>), Column('age', Integer(), table=<census>), Column('pop2000', Integer(), table=<census>), Column('pop2008', Integer(), table=<census>), schema=None)\n"
     ]
    }
   ],
   "source": [
    "# Import Table, Column, String, Integer, Float, Boolean from sqlalchemy\n",
    "from sqlalchemy import Table, Column, String, Integer, Float, Boolean\n",
    "\n",
    "engine = create_engine('sqlite:///'+path+'census2.sqlite')\n",
    "metadata = MetaData()\n",
    "connection = engine.connect()\n",
    "\n",
    "# Define a new table with a name, count, amount, and valid column: data\n",
    "census = Table('census', metadata,\n",
    "             Column('state', String(255)),\n",
    "             Column('sex', String(1)),\n",
    "             Column('age', Integer()),\n",
    "             Column('pop2000', Integer()),\n",
    "             Column('pop2008', Integer())\n",
    ")\n",
    "\n",
    "# Use the metadata to create the table\n",
    "metadata.create_all(engine)\n",
    "\n",
    "# Print the table details\n",
    "print(repr(metadata.tables['census']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# read census.csv into a dataframe : census_df\n",
    "census_df = pd.read_csv(path+'census.csv', header=None)\n",
    "\n",
    "# rename the columns of the census dataframe\n",
    "census_df.columns = ['state', 'sex', 'age', 'pop2000', 'pop2008']\n",
    "\n",
    "# append the data from census_df to the \"census\" table via connection\n",
    "census_df.to_sql(name='census', con=connection, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Illinois', 'M', 0, 89600, 95012),\n",
       " ('Illinois', 'M', 1, 88445, 91829),\n",
       " ('Illinois', 'M', 2, 88729, 89547),\n",
       " ('Illinois', 'M', 3, 88868, 90037),\n",
       " ('Illinois', 'M', 4, 91947, 91111),\n",
       " ('Illinois', 'M', 5, 93894, 89802),\n",
       " ('Illinois', 'M', 6, 93676, 88931),\n",
       " ('Illinois', 'M', 7, 94818, 90940),\n",
       " ('Illinois', 'M', 8, 95035, 86943),\n",
       " ('Illinois', 'M', 9, 96436, 86055)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stmt = select([census])\n",
    "results = connection.execute(stmt).fetchall()\n",
    "results[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pandas package provides us with an efficient way to load a DataFrames into a SQL table. If you would create and execute a statement to select all records from census, you would see that there are 8772 rows in the table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Updating individual records\n",
    "\n",
    "The update statement is very similar to an insert statement. For example, you can update all wages in the employees table as follows: `stmt = update(employees).values(wage=100.00)`.\n",
    "\n",
    "The update statement also typically uses a `where` clause to help us determine what data to update. For example, to only update the record for the employee with ID 15, you would append the previous statement as follows: `stmt = stmt.where(employees.id == 15)`.\n",
    "\n",
    "You'll be using the FIPS state code here, which is appropriated by the U.S. government to identify U.S. states and certain other associated areas.\n",
    "\n",
    "For your convenience, the names of the tables and columns of interest in this exercise are: state_fact (Table), name (Column), and fips_state (Column)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a select statement: select_stmt\n",
    "select_stmt = select([state_fact]).where(state_fact.columns.name == 'New York')\n",
    "\n",
    "# Execute select_stmt and fetch the results\n",
    "results = connection.execute(select_stmt).fetchall()\n",
    "\n",
    "# Print the results of executing the select_stmt\n",
    "print(results)\n",
    "\n",
    "# Print the FIPS code for the first row of the result\n",
    "print(results[0]['fips_state'])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<script.py> output:\n",
    "    [('32', 'New York', 'NY', 'USA', 'state', '10', 'current', 'occupied', '', '0', 'N.Y.', 'II', '1', 'Northeast', '2', 'Mid-Atlantic', '2')]\n",
    "    0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a statement to update the fips_state to 36: update_stmt\n",
    "update_stmt = update(state_fact).values(fips_state = 36)\n",
    "\n",
    "# Append a where clause to limit it to records for New York state\n",
    "update_stmt = update_stmt.where(state_fact.columns.name == 'New York')\n",
    "\n",
    "# Execute the statement: update_results\n",
    "update_results = connection.execute(update_stmt)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<script.py> output:\n",
    "    [('32', 'New York', 'NY', 'USA', 'state', '10', 'current', 'occupied', '', '0', 'N.Y.', 'II', '1', 'Northeast', '2', 'Mid-Atlantic', '2')]\n",
    "    0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute select_stmt again and fetch the new results\n",
    "new_results = connection.execute(select_stmt).fetchall()\n",
    "\n",
    "# Print the new_results\n",
    "print(new_results)\n",
    "\n",
    "# Print the FIPS code for the first row of the new_results\n",
    "print(results[0]['fips_state'])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<script.py> output:\n",
    "    [('32', 'New York', 'NY', 'USA', 'state', '10', 'current', 'occupied', '', '0', 'N.Y.', 'II', '1', 'Northeast', '2', 'Mid-Atlantic', '2')]\n",
    "    0\n",
    "    [('32', 'New York', 'NY', 'USA', 'state', '10', 'current', 'occupied', '', '36', 'N.Y.', 'II', '1', 'Northeast', '2', 'Mid-Atlantic', '2')]\n",
    "    0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Updating multiple records\n",
    "\n",
    "By using a where clause that selects more records, you can update multiple records at once. Unlike inserting, updating multiple records works exactly the same way as updating a single record (as long as you are updating them with the same value). It's time now to practice this!\n",
    "\n",
    "For your convenience, the names of the tables and columns of interest in this exercise are: state_fact (Table), notes (Column), and census_region_name (Column)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a statement to update the notes to 'The Wild West': stmt\n",
    "stmt = update(state_fact).values(notes='The Wild West')\n",
    "\n",
    "# Append a where clause to match the West census region records: stmt_west\n",
    "stmt_west = stmt.where(state_fact.columns.census_region_name == 'West')\n",
    "\n",
    "# Execute the statement: results\n",
    "results = connection.execute(stmt_west)\n",
    "\n",
    "# Print rowcount\n",
    "print(results.rowcount)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlated updates\n",
    "\n",
    "You can also update records with data from a select statement. This is called a **correlated update**. It works by defining a select statement that returns the value you want to update the record with and assigning that select statement as the value in update.\n",
    "\n",
    "You'll be using a flat_census in this exercise as the target of your correlated update. The flat_census table is a summarized copy of your census table, and contains, in particular, the fips_state columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a statement to select name from state_fact: stmt\n",
    "fips_stmt = select([state_fact.columns.name])\n",
    "\n",
    "# Append a where clause to Match the fips_state to flat_census fips_code\n",
    "fips_stmt = fips_stmt.where(\n",
    "    state_fact.columns.fips_state == flat_census.columns.fips_code)\n",
    "\n",
    "# Build an update statement to set the name to fips_stmt: update_stmt\n",
    "update_stmt = update(flat_census).values(state_name=fips_stmt)\n",
    "\n",
    "# Execute update_stmt: results\n",
    "results = connection.execute(update_stmt)\n",
    "\n",
    "# Print rowcount\n",
    "print(results.rowcount)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deleting all the records from a table\n",
    "\n",
    "Often, you'll need to empty a table of all of its records so you can reload the data. You can do this with a delete statement with just the table as an argument. For example:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "delete_stmt = delete(extra_employees)\n",
    "result_proxy = connection.execute(delete_stmt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do be careful, though, as deleting cannot be undone!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import delete, select\n",
    "from sqlalchemy import delete, select\n",
    "\n",
    "# Build a statement to empty the census table: stmt\n",
    "delete_stmt = delete(census)\n",
    "\n",
    "# Execute the statement: results\n",
    "results = connection.execute(delete_stmt)\n",
    "\n",
    "# Print affected rowcount\n",
    "print(results.rowcount)\n",
    "\n",
    "# Build a statement to select all records from the census table : select_stmt\n",
    "select_stmt = select([census])\n",
    "\n",
    "# Print the results of executing the statement to verify there are no rows\n",
    "print(connection.execute(select_stmt).fetchall())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
