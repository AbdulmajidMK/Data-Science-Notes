{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation and Hyperparameter Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validation\n",
    "\n",
    "Cross validation is simply splitting a dataset into two components: a train dataset, which the model is trained on, and a test dataset, which the model is tested on. For example, a default split between these two parts of the dataset is 80-20. A model will be trained on a random 80% of the dataset; then we will evaluate how well it did using the remaining 20%.\n",
    "\n",
    "Since that 20% was never seen by the model during training, it is not optimized for, and we can except model performance \"in the wild\" to be closely approximated by model performance on our training data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5-fold cross-validation\n",
    "\n",
    "**Cross-validation** is a vital step in evaluating a model. It maximizes the amount of data that is used to train the model, as during the course of training, the model is not only trained, but also tested on all of the available data. It also solves the problem of arbitrary split of data to train and test datasets.\n",
    "\n",
    "In this exercise, you will practice 5-fold cross validation on the Gapminder data. By default, scikit-learn's `cross_val_score()` function uses `R2` as the metric of choice for **regression**. Since you are performing 5-fold cross-validation, the function will return 5 scores. Your job is to compute these 5 scores and then take their average.\n",
    "\n",
    "<img src=\"images/cross-validation.png\" alt=\"\" style=\"width: 600px;\"/>\n",
    "\n",
    "**Cross validation** is essential but do not forget that the more folds you use, the more computationally expensive cross-validation becomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "path = 'data/dc18/'\n",
    "\n",
    "# Read the CSV file into a DataFrame: df\n",
    "df = pd.read_csv(path+'gapminder.csv')\n",
    "X = np.array(df.drop('life', axis=1).values)\n",
    "y = np.array(df.life.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.81720569 0.82917058 0.90214134 0.80633989 0.94495637]\n",
      "Average 5-Fold CV Score: 0.8599627722793232 <- R2 mean value\n"
     ]
    }
   ],
   "source": [
    "# Import the necessary modules\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Create a linear regression object: reg\n",
    "reg = LinearRegression()\n",
    "\n",
    "# Compute 5-fold cross-validation scores: cv_scores\n",
    "cv_scores = cross_val_score(reg, X, y, cv=5)\n",
    "\n",
    "# Print the 5-fold cross-validation scores\n",
    "print(cv_scores)\n",
    "\n",
    "print(\"Average 5-Fold CV Score: {} <- R2 mean value\".format(np.mean(cv_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.97 ms ± 89 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit cross_val_score(reg, X, y, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.75 ms ± 199 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit cross_val_score(reg, X, y, cv=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter search\n",
    "\n",
    "Which cross validation now in our toolbelt, we can approach the problem again: what polynomial model performs best when applied to our problem?\n",
    "\n",
    "We expect cross validation to be a good estimator on model performance against never-before-seen data. Hence we can use cross validation—that is, checking the mean squared error of the classifier applied to the test dataset—for, say, every degree polynomial regression function between 1 and 10. Clearly our best-performing model will be somewhere in there!\n",
    "\n",
    "This is known as a hyperparameter search. Hyperparameter searches are important because they are, effectively, how we go about finding the most useful and effective model in a series of possible models controlled by some magic number (the so-named \"hyperparameter\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources\n",
    "\n",
    "- [Gaming Cross Validation and Hyperparameter Search](https://www.kaggle.com/residentmario/gaming-cross-validation-and-hyperparameter-search/notebook)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
