{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "From: https://github.com/ksatola\n",
    "Version: 1.0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Recommendation Engines with PySpark\n",
    "\n",
    "This course will show you how to build recommendation engines using `Alternating Least Squares` in PySpark. Using the popular MovieLens dataset and the Million Songs dataset, this course will take you step by step through the intuition of the Alternating Least Squares algorithm as well as the code to train, test and implement ALS models on various types of customer data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "- [Introduction](#intro)\n",
    "- [How does ALS work?](#als)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "path = \"data/dc36/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "sc = SparkContext(\"local\", \"First App\")\n",
    "print(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('First App').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return spark version\n",
    "print(spark.version)\n",
    "\n",
    "# Return python version\n",
    "import sys\n",
    "print(sys.version_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='intro'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why learn how to build recommendation engines?\n",
    "\n",
    "<img src=\"images/spark6_001.png\" alt=\"\" style=\"width: 800px;\"/>\n",
    "\n",
    "<img src=\"images/spark6_002.png\" alt=\"\" style=\"width: 800px;\"/>\n",
    "\n",
    "<img src=\"images/spark6_003.png\" alt=\"\" style=\"width: 800px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## See the power of a recommendation engine\n",
    "\n",
    "Taylor and Jane both like watching movies. Taylor only likes dramas, comedies, and romances. Jane likes only action, adventure, and otherwise exciting films. One of the greatest benefits of `ALS-based recommendation engines` is that they can identify movies or items that users will like, even if they themselves think that they might not like them. Take a look at the movie ratings that Taylor and Jane have provided below. It would stand to reason that their different preferences would generate different recommendations.\n",
    "\n",
    "- Take a look at TJ_ratings using the .show() method and any other methods you prefer to see how each of them rated the various movies they've seen.\n",
    "- Input user names into the get_ALS_recs() function provided to see what movies ALS recommends for Jane and Taylor based on the ratings provided. Do the ratings make sense to you?\n",
    "\n",
    "```\n",
    "In [1]: TJ_ratings.show()\n",
    "+---------+--------------------+------+\n",
    "|user_name|          movie_name|rating|\n",
    "+---------+--------------------+------+\n",
    "|   Taylor|            Twilight|   4.9|\n",
    "|   Taylor|  A Walk to Remember|   4.5|\n",
    "|   Taylor|        The Notebook|   5.0|\n",
    "|   Taylor|Raiders of the Lo...|   1.2|\n",
    "|   Taylor|      The Terminator|   1.0|\n",
    "|   Taylor|      Mrs. Doubtfire|   1.0|\n",
    "|     Jane|            Iron Man|   4.8|\n",
    "|     Jane|Raiders of the Lo...|   4.9|\n",
    "|     Jane|      The Terminator|   4.6|\n",
    "|     Jane|           Anchorman|   1.2|\n",
    "|     Jane|        Pretty Woman|   1.0|\n",
    "|     Jane|           Toy Story|   1.2|\n",
    "+---------+--------------------+------+\n",
    "\n",
    "In [2]: get_ALS_recs([\"Taylor\",\"Jane\"])\n",
    "    userId  pred_rating                 title          genres\n",
    "0   Taylor         3.89   Seven Pounds (2008)           Drama\n",
    "1   Taylor         3.61      Cure, The (1995)           Drama\n",
    "2   Taylor         3.55  Kiss Me, Guido (1997          Comedy\n",
    "3   Taylor         3.29  You've Got Mail (199  Comedy|Romance\n",
    "4   Taylor         3.27  10 Things I Hate Abo  Comedy|Romance\n",
    "5   Taylor         3.26  Corrina, Corrina (19  Comedy|Drama|R\n",
    "6     Jane         4.96           Fear (1996)        Thriller\n",
    "7     Jane         4.85  Lord of the Rings: T  Adventure|Fant\n",
    "8     Jane         4.70  Lord of the Rings: T  Adventure|Fant\n",
    "9     Jane         4.55  No Holds Barred (198          Action\n",
    "10    Jane         4.54  Lord of the Rings: T  Action|Adventu\n",
    "11    Jane         4.30  Band of Brothers (20  Action|Drama|W\n",
    "12    Jane         4.26   Transformers (2007)  Action|Sci-Fi|\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommendation Engine Types and Data Types\n",
    "\n",
    "<img src=\"images/spark6_004.png\" alt=\"\" style=\"width: 800px;\"/>\n",
    "\n",
    "<img src=\"images/spark6_005.png\" alt=\"\" style=\"width: 800px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collaborative vs Content-Based Filtering Part II\n",
    "\n",
    "Look at the df dataframe using the .show() method and/or the .columns method, and determine whether it is best suited for \"collaborative filtering\", \"content-based filtering\", or \"both\".\n",
    "\n",
    "```\n",
    "In [1]: df.show()\n",
    "+------+-------+-----------------+--------+--------+-------------+------+\n",
    "|UserId|MovieId|      Movie_Title|   Genre|Language|Year_Produced|rating|\n",
    "+------+-------+-----------------+--------+--------+-------------+------+\n",
    "| User1|   2112|     Finding Nemo|Animated| English|         2003|     3|\n",
    "| User1|   2113|   The Terminator|  Action| English|         1984|     0|\n",
    "| User1|   2114|       Spinal Tap|  Satire| English|         1984|     4|\n",
    "| User1|   2115|Life Is Beautiful|   Drama| Italian|         1998|     4|\n",
    "| User2|   2112|     Finding Nemo|Animated| English|         2003|     4|\n",
    "| User2|   2113|   The Terminator|  Action| English|         1984|     0|\n",
    "| User2|   2114|       Spinal Tap|  Satire| English|         1984|     0|\n",
    "| User2|   2115|Life Is Beautiful|   Drama| Italian|         1998|     4|\n",
    "| User3|   2112|     Finding Nemo|Animated| English|         2003|     1|\n",
    "| User3|   2113|   The Terminator|  Action| English|         1984|     2|\n",
    "| User3|   2114|       Spinal Tap|  Satire| English|         1984|     1|\n",
    "| User3|   2115|Life Is Beautiful|   Drama| Italian|         1998|     0|\n",
    "| User4|   2112|     Finding Nemo|Animated| English|         2003|     3|\n",
    "| User4|   2113|   The Terminator|  Action| English|         1984|     1|\n",
    "| User4|   2114|       Spinal Tap|  Satire| English|         1984|     0|\n",
    "| User4|   2115|Life Is Beautiful|   Drama| Italian|         1998|     0|\n",
    "+------+-------+-----------------+--------+--------+-------------+------+\n",
    "```\n",
    "\n",
    "Possible Answers\n",
    "- Collaborative filtering\n",
    "- Content-based filtering\n",
    "- Both collaborative and content-based filtering (correct)\n",
    "\n",
    "Because this dataset includes descriptive tags like genre and language, as well as user ratings, it is suited for both collaborative and content-based filtering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implicit vs Explicit Data\n",
    "\n",
    "Recall the differences between implicit and explicit ratings. Take a look at the df1 dataframe to understand whether the data includes implicit or explicit ratings data.\n",
    "\n",
    "- Use the .columns and .show() methods to get an idea of the data provided, and see if the data includes implicit or explicit ratings.\n",
    "- Type \"implicit\" or \"explicit\" based on whether you think this data contains \"implicit\" ratings or \"explicit\" ratings. Name your response answer.\n",
    "\n",
    "```\n",
    "In [1]: df1.columns\n",
    "Out[1]: ['Movie_Title', 'Genre', 'Num_Views']\n",
    "\n",
    "In [2]: df1.show()\n",
    "+--------------------+------------------+---------+\n",
    "|         Movie_Title|             Genre|Num_Views|\n",
    "+--------------------+------------------+---------+\n",
    "|        Finding Nemo|Animated Childrens|       12|\n",
    "|           Toy Story|Animated Childrens|        6|\n",
    "|            Iron Man|            Action|        1|\n",
    "|     Captain America|            Action|        1|\n",
    "|     The Incredibles|Animated Childrens|        9|\n",
    "|              Frozen|Animated Childrens|       22|\n",
    "|The Shawshank Red...|             Drama|        2|\n",
    "|  Rabbit Proof Fence|             Drama|        2|\n",
    "|Searching for Sug...|       Documentary|        3|\n",
    "|              Powder|             Drama|        1|\n",
    "|        The Fugitive|            Action|        2|\n",
    "+--------------------+------------------+---------+\n",
    "```\n",
    "This dataset includes user behavior counts which are used as implicit ratings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ratings data types\n",
    "\n",
    "Markus watches a lot of movies, including documentaries, superhero movies, classics, and dramas. Drawing on your previous experience with Spark, use the markus_ratings dataframe, which contains data on the number of times Markus has seen movies in various genres, and think about whether these are implicit or explicit ratings. Use the groupBy() method to determine which genre has the highest rating, which could likely influence what recommendations ALS would generate for Markus.\n",
    "\n",
    "- Use the groupBy() method to group the markus_ratings dataframe by \"Genre\".\n",
    "- Apply the .sum() method to get the total number of movies watched for each genre.\n",
    "- Be sure to add the .show() method at the end to view the counts.\n",
    "\n",
    "```\n",
    "In [1]: markus_ratings.show()\n",
    "+--------------------+------------------+---------+\n",
    "|         Movie_Title|             Genre|Num_Views|\n",
    "+--------------------+------------------+---------+\n",
    "|        Finding Nemo|Animated Childrens|       12|\n",
    "|           Toy Story|Animated Childrens|        6|\n",
    "|            Iron Man|            Action|        1|\n",
    "|     Captain America|            Action|        1|\n",
    "|     The Incredibles|Animated Childrens|        9|\n",
    "|              Frozen|Animated Childrens|       22|\n",
    "|The Shawshank Red...|             Drama|        2|\n",
    "|  Rabbit Proof Fence|             Drama|        2|\n",
    "|Searching for Sug...|       Documentary|        3|\n",
    "|              Powder|             Drama|        1|\n",
    "|        The Fugitive|            Action|        2|\n",
    "+--------------------+------------------+---------+\n",
    "\n",
    "In [2]: # Group the data by \"Genre\"\n",
    "        markus_ratings.groupBy(\"Genre\").sum().show()\n",
    "+------------------+--------------+\n",
    "|             Genre|sum(Num_Views)|\n",
    "+------------------+--------------+\n",
    "|             Drama|             5|\n",
    "|       Documentary|             3|\n",
    "|            Action|             4|\n",
    "|Animated Childrens|            49|\n",
    "+------------------+--------------+\n",
    "```\n",
    "Markus seems to like animated children's movies. Or perhaps his 3 kids use his movie streaming account more than he does."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uses for Recommendation Engines\n",
    "\n",
    "<img src=\"images/spark6_006.png\" alt=\"\" style=\"width: 800px;\"/>\n",
    "\n",
    "<img src=\"images/spark6_007.png\" alt=\"\" style=\"width: 800px;\"/>\n",
    "\n",
    "<img src=\"images/spark6_008.png\" alt=\"\" style=\"width: 800px;\"/>\n",
    "\n",
    "<img src=\"images/spark6_009.png\" alt=\"\" style=\"width: 800px;\"/>\n",
    "\n",
    "`Latent features` aren't directly observable by humans, and need mathematical operations to uncover them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confirm understanding of latent features\n",
    "\n",
    "Matrix P is provided here. Its columns represent movies and its rows represent several latent features. Use your understanding of Spark commands to view matrix P and see if you can determine what some of the latent features might represent. After examining the matrix, look at the dataframe Pi, which contains a rough approximation of what these latent features could represent. See if you weren't far off.\n",
    "\n",
    "- Examine matrix P using the .show() method.\n",
    "- Examine matrix Pi using the .show() method.\n",
    "\n",
    "```\n",
    "<script.py> output:\n",
    "    +--------+------------+--------+---------+------------+------+----------+\n",
    "    |Iron Man|Finding Nemo|Avengers|Toy Story|Forrest Gump|Wall-E|Green Mile|\n",
    "    +--------+------------+--------+---------+------------+------+----------+\n",
    "    |     0.2|         2.4|     0.1|      2.4|           0|   2.5|         0|\n",
    "    |     1.5|         1.4|     1.4|      1.3|         1.8|   1.8|       2.5|\n",
    "    |     2.5|         1.1|     2.4|      0.9|         0.2|   0.9|      0.09|\n",
    "    |     1.9|           2|     1.5|      2.2|         1.2|   0.3|      0.01|\n",
    "    |       0|           0|       0|      2.3|         2.2|     0|       2.5|\n",
    "    +--------+------------+--------+---------+------------+------+----------+\n",
    "    \n",
    "    +---------+--------+------------+--------+---------+------------+------+----------+\n",
    "    | Lat Feat|Iron Man|Finding Nemo|Avengers|Toy Story|Forrest Gump|Wall-E|Green Mile|\n",
    "    +---------+--------+------------+--------+---------+------------+------+----------+\n",
    "    | Animated|     0.2|         2.4|     0.1|      2.4|           0|   2.5|         0|\n",
    "    |    Drama|     1.5|         1.4|     1.4|      1.3|         1.8|   1.8|       2.5|\n",
    "    |Superhero|     2.5|         1.1|     2.4|      0.9|         0.2|   0.9|      0.09|\n",
    "    |   Comedy|     1.9|           2|     1.5|      2.2|         1.2|   0.3|      0.01|\n",
    "    |Tom Hanks|       0|           0|       0|      1.8|         2.2|     0|       2.5|\n",
    "    +---------+--------+------------+--------+---------+------------+------+----------+\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='als'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How does ALS work?\n",
    "\n",
    "<img src=\"images/spark6_010.png\" alt=\"\" style=\"width: 800px;\"/>\n",
    "\n",
    "<img src=\"images/spark6_011.png\" alt=\"\" style=\"width: 800px;\"/>\n",
    "\n",
    "<img src=\"images/spark6_012.png\" alt=\"\" style=\"width: 800px;\"/>\n",
    "\n",
    "<img src=\"images/spark6_013.png\" alt=\"\" style=\"width: 800px;\"/>\n",
    "\n",
    "<img src=\"images/spark6_014.png\" alt=\"\" style=\"width: 800px;\"/>\n",
    "\n",
    "<img src=\"images/spark6_015.png\" alt=\"\" style=\"width: 800px;\"/>\n",
    "\n",
    "<img src=\"images/spark6_016.png\" alt=\"\" style=\"width: 800px;\"/>\n",
    "\n",
    "<img src=\"images/spark6_017.png\" alt=\"\" style=\"width: 800px;\"/>\n",
    "\n",
    "<img src=\"images/spark6_018.png\" alt=\"\" style=\"width: 800px;\"/>\n",
    "\n",
    "<img src=\"images/spark6_019.png\" alt=\"\" style=\"width: 800px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix Multiplication\n",
    "\n",
    "To understand matrix multiplication more directly, let's do some matrix operations manually.\n",
    "\n",
    "- Matrices a and b are Pandas dataframes. Use the .head() method on each of them to view them.\n",
    "- Work out the product of these two matrices on your own.\n",
    "- Enter the values of the product of the a and b matrices into the product array, created using np.array().\n",
    "- Use the validation on the last line of code to evaluate your estimate. The .dot() method multiplies two matrices together.\n",
    "\n",
    "```\n",
    "In [1]: print(\"Matrix A: \")\n",
    "        print (a.head())\n",
    "        \n",
    "        print(\"Matrix B: \")\n",
    "        print (b.head())\n",
    "Matrix A: \n",
    "     0  1\n",
    "One  2  2\n",
    "Two  3  3\n",
    "Matrix B: \n",
    "     0  1\n",
    "One  1  2\n",
    "Two  4  4\n",
    "\n",
    "In [2]: product = np.array([[10,12], [15,18]])\n",
    "\n",
    "In [3]: product == np.dot(a,b)\n",
    "Out[3]: \n",
    "array([[ True,  True],\n",
    "       [ True,  True]])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix Multiplication Part II\n",
    "\n",
    "Let's put your matrix multiplication skills to the test.\n",
    "\n",
    "- Use the .shape attribute to understand the dimensions of matrices C and D, and determine whether these two matrices can be multiplied together or not.\n",
    "- If they can be multiplied, use the np.matmul() method to multiply them. If not, set C_times_D to None.\n",
    "\n",
    "```\n",
    "In [1]: print(C.shape)\n",
    "        \n",
    "        # Print the dimensions of D\n",
    "        print(D.shape)\n",
    "(4, 5)\n",
    "(3, 2)\n",
    "\n",
    "In [2]: C_times_D = np.matmul()\n",
    "Traceback (most recent call last):\n",
    "  File \"<stdin>\", line 1, in <module>\n",
    "    C_times_D = np.matmul()\n",
    "ValueError: invalid number of arguments\n",
    "\n",
    "In [3]: C_times_D = None\n",
    "```\n",
    "The number of columns in C is different than the number of rows in D. C and D cannot be multiplied."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview of Matrix Factorization\n",
    "\n",
    "<img src=\"images/spark6_020.png\" alt=\"\" style=\"width: 800px;\"/>\n",
    "\n",
    "<img src=\"images/spark6_021.png\" alt=\"\" style=\"width: 800px;\"/>\n",
    "\n",
    "<img src=\"images/spark6_022.png\" alt=\"\" style=\"width: 800px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix Factorization\n",
    "\n",
    "Matrix G is provided here as a Pandas dataframe. View it to understand what it looks like. Look at the possible factor matrices H, I, and J (also Pandas dataframes), and determine which two matrices will produce the matrix G when multiplied together.\n",
    "\n",
    "- Take a look at matrix G using the print command\n",
    "- Take a look at the matrices H, I, and J and determine which pair of those matrices will produce G when multiplied together.\n",
    "- Input your answer into the np.matmul() code provided.\n",
    "\n",
    "```\n",
    "# Take a look at Matrix G using the following print function\n",
    "print(\"Matrix G:\")\n",
    "print(G)\n",
    "\n",
    "# Take a look at the matrices H, I, and J and determine which pair of those matrices will produce G when multiplied together. \n",
    "print(\"Matrix H:\")\n",
    "print(H)\n",
    "print(\"Matrix I:\")\n",
    "print(I)\n",
    "print(\"Matrix J:\")\n",
    "print(J)\n",
    "\n",
    "# Multiply the two matrices that are factors of the matrix G\n",
    "prod = np.matmul(H, J)\n",
    "print(G == prod)\n",
    "\n",
    "<script.py> output:\n",
    "    Matrix G:\n",
    "       0  1\n",
    "    0  6  6\n",
    "    1  3  3\n",
    "    Matrix H:\n",
    "       0  1\n",
    "    0  2  2\n",
    "    1  1  1\n",
    "    Matrix I:\n",
    "       0  1\n",
    "    0  3  3\n",
    "    1  3  3\n",
    "    Matrix J:\n",
    "       0  1\n",
    "    0  1  1\n",
    "    1  2  2\n",
    "          0     1\n",
    "    0  True  True\n",
    "    1  True  True\n",
    "```\n",
    "Matrices H and J are factors of G."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-Negative Matrix Factorization\n",
    "\n",
    "It's possible for one matrix to have two equally close factorizations where one has all positive values and the other has some negative values.\n",
    "\n",
    "The matrix M has been factored twice using two different factorizations. Take a look at each pair of factor matrices L and U, and W and H to see the differences. Then use their products to see that they produce essentially the same product.\n",
    "\n",
    "- Use print() to view the L and U matrices. Notice that some values in matrices L and U are negative.\n",
    "- Use print() to view the W and H matrices. Notice that all values in these two matrices are positive.\n",
    "- The L and U matrices and W and H matrices have been multiplied together to produce the LU and WH matrices respectively. Use getRMSE(product_matrix, original_matrix) to see how close LU is to M compared to how close WH is to M. Are they similar?\n",
    "\n",
    "```\n",
    "# View the L, U, W, and H matrices.\n",
    "print(\"Matrices L and U:\") \n",
    "print(L)\n",
    "print(U)\n",
    "\n",
    "print(\"Matrices W and H:\")\n",
    "print(W)\n",
    "print(H)\n",
    "\n",
    "# Calculate RMSE between LU and M\n",
    "print(\"RMSE of LU: \", getRMSE(LU, M))\n",
    "\n",
    "# Calculate RMSE between WH and M\n",
    "print(\"RMSE of WH: \", getRMSE(WH, M))\n",
    "\n",
    "<script.py> output:\n",
    "    Matrices L and U:\n",
    "          0         1         2  3\n",
    "    0  1.00  0.000000  0.000000  0\n",
    "    1  0.01 -0.421053  0.098316  1\n",
    "    2  1.00  0.000000  1.000000  0\n",
    "    3  0.10  1.000000  0.000000  0\n",
    "       0     1      2         3\n",
    "    0  1  2.00  1.000  2.000000\n",
    "    1  0 -0.19 -0.099 -0.198000\n",
    "    2  0  0.00  1.000 -1.000000\n",
    "    3  0  0.00  0.000  0.194947\n",
    "    Matrices W and H:\n",
    "          0     1     2     3\n",
    "    0  2.61  0.24  0.00  0.12\n",
    "    1  0.00  0.05  0.02  0.17\n",
    "    2  1.97  0.00  0.58  0.83\n",
    "    3  0.05  0.00  0.00  0.00\n",
    "          0     1     2     3\n",
    "    0  0.38  0.65  0.34  0.41\n",
    "    1  0.00  1.20  0.15  3.72\n",
    "    2  0.42  1.09  1.38  0.07\n",
    "    3  0.00  0.11  0.65  0.17\n",
    "    RMSE of LU:  0.072\n",
    "    RMSE of WH:  0.072\n",
    "```\n",
    "Did you notice that LU and WH essentailly created the same product despite LU having some negative values and WH having all positive values?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How ALS Alternates to Generate Predictions\n",
    "\n",
    "<img src=\"images/spark6_023.png\" alt=\"\" style=\"width: 800px;\"/>\n",
    "\n",
    "<img src=\"images/spark6_024.png\" alt=\"\" style=\"width: 800px;\"/>\n",
    "\n",
    "<img src=\"images/spark6_025.png\" alt=\"\" style=\"width: 800px;\"/>\n",
    "\n",
    "<img src=\"images/spark6_026.png\" alt=\"\" style=\"width: 800px;\"/>\n",
    "\n",
    "<img src=\"images/spark6_027.png\" alt=\"\" style=\"width: 800px;\"/>\n",
    "\n",
    "<img src=\"images/spark6_028.png\" alt=\"\" style=\"width: 800px;\"/>\n",
    "\n",
    "<img src=\"images/spark6_029.png\" alt=\"\" style=\"width: 800px;\"/>\n",
    "\n",
    "<img src=\"images/spark6_030.png\" alt=\"\" style=\"width: 800px;\"/>\n",
    "\n",
    "<img src=\"images/spark6_031.png\" alt=\"\" style=\"width: 800px;\"/>\n",
    "\n",
    "<img src=\"images/spark6_032.png\" alt=\"\" style=\"width: 800px;\"/>\n",
    "\n",
    "<img src=\"images/spark6_033.png\" alt=\"\" style=\"width: 800px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimating Recommendations\n",
    "\n",
    "Use your knowledge of matrix multiplication to determine which movie will have the highest recommendation for User_3. The ratings matrix has been factorized into U and P with ALS.\n",
    "\n",
    "- View the left factor matrix, U, using the print function.\n",
    "- Did you see anything interesting about User_3? Now inspect the right factor matrix, P. Use the print function.\n",
    "\n",
    "```\n",
    "# View left factor matrix\n",
    "print(U)\n",
    "\n",
    "<script.py> output:\n",
    "            U_LF_1  U_LF_2  U_LF_3  U_LF_4\n",
    "    User_1    0.80    0.01    0.30     0.8\n",
    "    User_2    0.40    0.01    0.06     0.2\n",
    "    User_3    0.05    2.10    0.01     2.2\n",
    "    User_4    0.30    0.01    0.20     0.2\n",
    "    User_5    0.10    1.50    0.90     0.0\n",
    "    User_6    0.00    0.03    0.40     0.5\n",
    "    User_7    0.01    0.02    0.66     0.4\n",
    "    User_8    0.90    0.70    0.00     1.0\n",
    "    User_9    1.00    2.00    0.04     0.2\n",
    "    \n",
    "# View right factor matrix\n",
    "print(P)\n",
    "\n",
    "<script.py> output:\n",
    "            Movie_1  Movie_2  Movie_3  Movie_4\n",
    "    P_LF_1      0.5      0.1      0.4     1.10\n",
    "    P_LF_2      0.2      2.0      0.0     0.01\n",
    "    P_LF_3      0.3      1.9      0.6     0.90\n",
    "    P_LF_4      1.0      0.2      1.0     0.89\n",
    "```\n",
    "\n",
    "- Looking at U and P, which movie do you think will have the highest recommendation for User_3.\n",
    "- Multiply U and P using numpy's matmul to obtain recommendations. Call thisUP.\n",
    "- Complete the code to print UP.\n",
    "\n",
    "```\n",
    "# Multiply factor matrices\n",
    "UP = np.matmul(U,P)\n",
    "\n",
    "# Convert to pandas DataFrame\n",
    "print(pd.DataFrame(UP, columns = P.columns, index = U.index))\n",
    "\n",
    "<script.py> output:\n",
    "            Movie_1  Movie_2  Movie_3  Movie_4\n",
    "    User_1      NaN      NaN      NaN      NaN\n",
    "    User_2      NaN      NaN      NaN      NaN\n",
    "    User_3      NaN      NaN      NaN      NaN\n",
    "    User_4      NaN      NaN      NaN      NaN\n",
    "    User_5      NaN      NaN      NaN      NaN\n",
    "    User_6      NaN      NaN      NaN      NaN\n",
    "    User_7      NaN      NaN      NaN      NaN\n",
    "    User_8      NaN      NaN      NaN      NaN\n",
    "    User_9      NaN      NaN      NaN      NaN\n",
    "```\n",
    "\n",
    "Did you guess Movie 2? It has the highest predicted rating at 4.664 out of 5.\n",
    "\n",
    "???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RMSE As ALS Alternates\n",
    "\n",
    "As you know, ALS will alternate between the two factor matrices, adjusting their values each time to iteratively come closer and closer to approximating the original ratings matrix. This exercise is intended to illustrate this to you.\n",
    "\n",
    "Matrix T is a ratings matrix, and matrices F1, F2, F3, F4, F5, and F6 are the respective products of ALS after iterating 2, 3, 4, 5, and 6 times respectively. Follow the instructions below to see how the RMSE changes as ALS iterates.\n",
    "\n",
    "- Use getRMSE(pred_matrix, actual_matrix) to calculate the RMSE of F1.\n",
    "- Put F2, F3, F4, F5, and F6 into one list called Fs.\n",
    "- Complete the getRMSEs(listOfPredMatrices, actualValues) function to calculate the RMSE of each matrix in the Fs list.\n",
    "\n",
    "```\n",
    "# Use getRMSE(preds, actuals) to calculate the RMSE of matrices T and F1.\n",
    "getRMSE(F1, T)\n",
    "\n",
    "# Create list of F2, F3, F4, F5, and F6\n",
    "Fs = [F2, F3, F4, F5, F6]\n",
    "\n",
    "# Calculate RMSEs for F2 - F6\n",
    "getRMSEs(Fs, T)\n",
    "\n",
    "<script.py> output:\n",
    "    F1:  2.4791263858912522\n",
    "    F2: 0.4389326310548279\n",
    "    F3: 0.17555006757053257\n",
    "    F4: 0.15154042416388636\n",
    "    F5: 0.13191130368008455\n",
    "    F6: 0.04533823201006271\n",
    "\n",
    "```\n",
    "Do you see how the RMSE gets smaller and smaller as ALS continues to iterate?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation for Spark ALS\n",
    "\n",
    "<img src=\"images/spark6_034.png\" alt=\"\" style=\"width: 800px;\"/>\n",
    "\n",
    "<img src=\"images/spark6_035.png\" alt=\"\" style=\"width: 800px;\"/>\n",
    "\n",
    "<img src=\"images/spark6_036.png\" alt=\"\" style=\"width: 800px;\"/>\n",
    "\n",
    "<img src=\"images/spark6_037.png\" alt=\"\" style=\"width: 800px;\"/>\n",
    "\n",
    "<img src=\"images/spark6_038.png\" alt=\"\" style=\"width: 800px;\"/>\n",
    "\n",
    "<img src=\"images/spark6_039.png\" alt=\"\" style=\"width: 800px;\"/>\n",
    "\n",
    "<img src=\"images/spark6_040.png\" alt=\"\" style=\"width: 800px;\"/>\n",
    "\n",
    "<img src=\"images/spark6_041.png\" alt=\"\" style=\"width: 800px;\"/>\n",
    "\n",
    "<img src=\"images/spark6_042.png\" alt=\"\" style=\"width: 800px;\"/>\n",
    "\n",
    "<img src=\"images/spark6_043.png\" alt=\"\" style=\"width: 800px;\"/>\n",
    "\n",
    "<img src=\"images/spark6_044.png\" alt=\"\" style=\"width: 800px;\"/>\n",
    "\n",
    "<img src=\"images/spark6_045.png\" alt=\"\" style=\"width: 800px;\"/>\n",
    "\n",
    "<img src=\"images/spark6_046.png\" alt=\"\" style=\"width: 800px;\"/>\n",
    "\n",
    "<img src=\"images/spark6_047.png\" alt=\"\" style=\"width: 800px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correct format and distinct users\n",
    "\n",
    "Take a look at the R dataframe. Notice that it is in conventional or `\"wide\"` format with a different movie in each column. Also notice that the User's and movie names are not in integer format. Follow the steps to properly prepare this data for ALS.\n",
    "\n",
    "- Import the monotonically_increasing_id package from pyspark.sql.functions and view the R dataframe using the .show() method.\n",
    "- Use the to_long() function to convert the R dataframe into a `\"long\"` data frame. Call the new dataframe ratings.\n",
    "- Create a dataframe called users that contains all the .distinct() users from the dataframe and repartition the dataframe into one partition using the .coalesce(1) method.\n",
    "- Use the monotonically_increasing_id() method inside of withColumn() to create a new column in the users dataframe that contains a unique integer for each user. Call this column userId. Be sure to call the .persist() method on the final dataframe to ensure the new integer IDs persist.\n",
    "\n",
    "```\n",
    "# Import monotonically_increasing_id and show R\n",
    "from pyspark.sql.functions import monotonically_increasing_id\n",
    "R.show()\n",
    "\n",
    "# Use the to_long() function to convert the dataframe to the \"long\" format.\n",
    "ratings = to_long(R)\n",
    "ratings.show()\n",
    "\n",
    "# Get unique users and repartition to 1 partition\n",
    "users = ratings.select(\"User\").distinct().coalesce(1)\n",
    "\n",
    "# Create a new column of unique integers called \"userId\" in the users dataframe.\n",
    "users = users.withColumn(\"userId\", monotonically_increasing_id()).persist()\n",
    "users.show()\n",
    "\n",
    "<script.py> output:\n",
    "    +----------------+-----+----+----------+--------+\n",
    "    |            User|Shrek|Coco|Swing Kids|Sneakers|\n",
    "    +----------------+-----+----+----------+--------+\n",
    "    |    James Alking|    3|   4|         4|       3|\n",
    "    |Elvira Marroquin|    4|   5|      null|       2|\n",
    "    |      Jack Bauer| null|   2|         2|       5|\n",
    "    |     Julia James|    5|null|         2|       2|\n",
    "    +----------------+-----+----+----------+--------+\n",
    "    \n",
    "    +----------------+----------+------+\n",
    "    |            User|     Movie|Rating|\n",
    "    +----------------+----------+------+\n",
    "    |    James Alking|     Shrek|     3|\n",
    "    |    James Alking|      Coco|     4|\n",
    "    |    James Alking|Swing Kids|     4|\n",
    "    |    James Alking|  Sneakers|     3|\n",
    "    |Elvira Marroquin|     Shrek|     4|\n",
    "    |Elvira Marroquin|      Coco|     5|\n",
    "    |Elvira Marroquin|  Sneakers|     2|\n",
    "    |      Jack Bauer|      Coco|     2|\n",
    "    |      Jack Bauer|Swing Kids|     2|\n",
    "    |      Jack Bauer|  Sneakers|     5|\n",
    "    |     Julia James|     Shrek|     5|\n",
    "    |     Julia James|Swing Kids|     2|\n",
    "    |     Julia James|  Sneakers|     2|\n",
    "    +----------------+----------+------+\n",
    "    \n",
    "    +----------------+------+\n",
    "    |            User|userId|\n",
    "    +----------------+------+\n",
    "    |Elvira Marroquin|     0|\n",
    "    |      Jack Bauer|     1|\n",
    "    |    James Alking|     2|\n",
    "    |     Julia James|     3|\n",
    "    +----------------+------+\n",
    "```\n",
    "Each user now has a unique integer assigned to it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assigning integer id's to movies\n",
    "\n",
    "Let's do the same thing to the movies. Then let's join the new user IDs and movie IDs into one dataframe.\n",
    "\n",
    "- Use the .select() and the .distinct() methods to extract all unique Movies from the ratings dataframe.\n",
    "- Repartition the movies dataframe to one partition using coalesce().\n",
    "- Complete the partial code provided to assign unique integer IDs to each movie. Name the new column movieId and call the .persist() method on the resulting dataframe.\n",
    "- Join the ratings dataframe to the users dataframe and subsequently to the movies dataframe. Call the result movie_ratings.\n",
    "\n",
    "```\n",
    "# Extract the distinct movie id's\n",
    "movies = ratings.select(\"Movie\").distinct() \n",
    "\n",
    "# Repartition the data to have only one partition.\n",
    "movies = movies.coalesce(1) \n",
    "\n",
    "# Create a new column of movieId integers. \n",
    "movies = movies.withColumn(\"movieId\", monotonically_increasing_id()).persist() \n",
    "\n",
    "# Join the ratings, users and movies dataframes\n",
    "movie_ratings = ratings.join(users, \"User\", \"left\").join(movies, \"Movie\", \"left\")\n",
    "movie_ratings.show()\n",
    "\n",
    "<script.py> output:\n",
    "    +----------+----------------+------+------+-------+\n",
    "    |     Movie|            User|Rating|userId|movieId|\n",
    "    +----------+----------------+------+------+-------+\n",
    "    |     Shrek|    James Alking|     3|     2|      3|\n",
    "    |      Coco|    James Alking|     4|     2|      1|\n",
    "    |Swing Kids|    James Alking|     4|     2|      2|\n",
    "    |  Sneakers|    James Alking|     3|     2|      0|\n",
    "    |     Shrek|Elvira Marroquin|     4|     0|      3|\n",
    "    |      Coco|Elvira Marroquin|     5|     0|      1|\n",
    "    |  Sneakers|Elvira Marroquin|     2|     0|      0|\n",
    "    |      Coco|      Jack Bauer|     2|     1|      1|\n",
    "    |Swing Kids|      Jack Bauer|     2|     1|      2|\n",
    "    |  Sneakers|      Jack Bauer|     5|     1|      0|\n",
    "    |     Shrek|     Julia James|     5|     3|      3|\n",
    "    |Swing Kids|     Julia James|     2|     3|      2|\n",
    "    |  Sneakers|     Julia James|     2|     3|      0|\n",
    "    +----------+----------------+------+------+-------+\n",
    "```\n",
    "You now have distinct userId's and movieId's that are integer data types."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ALS Parameters and Hyperparameters\n",
    "\n",
    "<img src=\"images/spark6_048.png\" alt=\"\" style=\"width: 800px;\"/>\n",
    "\n",
    "<img src=\"images/spark6_049.png\" alt=\"\" style=\"width: 800px;\"/>\n",
    "\n",
    "<img src=\"images/spark6_050.png\" alt=\"\" style=\"width: 800px;\"/>\n",
    "\n",
    "<img src=\"images/spark6_051.png\" alt=\"\" style=\"width: 800px;\"/>\n",
    "\n",
    "<img src=\"images/spark6_052.png\" alt=\"\" style=\"width: 800px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Out An ALS Model\n",
    "\n",
    "Let's specify your first ALS model. Complete the code below to build your first ALS model.\n",
    "\n",
    "Recall that you can use the .columns method on the ratings data frame to see what the names of the columns are that contain user, movie, and ratings data. Spark needs to know the names of these columns in order to perform ALS correctly.\n",
    "\n",
    "- Before building our ALS model, we need to split the data into training data and test data. Use the randomSplit() method to split the ratings dataframe into training_data and test_data using an 0.8/0.2 split respectively and a seed for the random number generator of 42.\n",
    "- Tell Spark which columns contain the userCol, itemCol and ratingCol. Use the .columns method if needed. Complete the hyperparameters. Set the rank to 10, the maxIter to 15, the regParam or lambda to .1, the coldStartStrategy to \"drop\", the nonnegative argument should be set to True, and since our data contains explicit ratings, set the implicitPrefs argument to False.\n",
    "- Now fit the als model to the training_data portion of the ratings data by calling the als.fit() method on the training_data provided. Call the fitted model model.\n",
    "- Generate predictions on the test_data portion of the ratings data by calling the model.transform() method on the test_data provided. Call the predictions test_predictions. Feel free to view the predictions by calling the .show() method on the test_predictions\n",
    "\n",
    "```\n",
    "In [1]: ratings.show(5)\n",
    "+------+-------+------+\n",
    "|userId|movieId|rating|\n",
    "+------+-------+------+\n",
    "|     2|      3|   3.0|\n",
    "|     2|      1|   4.0|\n",
    "|     2|      2|   4.0|\n",
    "|     2|      0|   3.0|\n",
    "|     0|      3|   4.0|\n",
    "+------+-------+------+\n",
    "only showing top 5 rows\n",
    "\n",
    "# Split the ratings dataframe into training and test data\n",
    "(training_data, test_data) = ratings.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "# Set the ALS hyperparameters\n",
    "from pyspark.ml.recommendation import ALS\n",
    "als = ALS(userCol=\"userId\", itemCol=\"movieId\", ratingCol=\"rating\", rank = 10, maxIter = 15, regParam = .1,\n",
    "          coldStartStrategy=\"drop\", nonnegative = True, implicitPrefs = False)\n",
    "\n",
    "# Fit the mdoel to the training_data\n",
    "model = als.fit(training_data)\n",
    "\n",
    "# Generate predictions on the test_data\n",
    "test_predictions = model.transform(test_data)\n",
    "test_predictions.show()\n",
    "\n",
    "<script.py> output:\n",
    "    +------+-------+------+----------+\n",
    "    |userId|movieId|rating|prediction|\n",
    "    +------+-------+------+----------+\n",
    "    |     0|      1|   5.0| 2.4220588|\n",
    "    |     0|      3|   4.0| 2.5182998|\n",
    "    |     1|      0|   5.0| 1.4837145|\n",
    "    +------+-------+------+----------+\n",
    "```\n",
    "You just built our your first ALS model and generated some test predictions. It's a toy dataset, so the results aren't particularly meaningful, but you now know how to do this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build RMSE Evaluator\n",
    "\n",
    "Now that you know how to fit a model to training data and generate test predictions, you need a way to evaluate how well your model performs. For this we'll build an evaluator. Evaluators in Spark can be built out in various ways. For our purposes, we want a regressionEvaluator that calculates the RMSE. After we build our regressionEvaluator, we can fit the model to our data and generate predictions.\n",
    "\n",
    "- Import the required RegressionEvaluator package from the pyspark.ml.evaluation class.\n",
    "- Complete the evaluator code, specifying the metric name to be \"rmse\". Set the labelCol to the name of the column in our ratings data that contains our ratings (use the ratings.columns method to see column names) and set the prediction column name to \"prediction\".\n",
    "- Confirm that the evaluator was properly created by extracting each of the three parameters from it. Do this by running the following 3 lines of code, each within a print statement:\n",
    "    - evaluator.getMetricName()\n",
    "    - evaluator.getLabelCol()\n",
    "    - evaluator.getPredictionCol()\n",
    "\n",
    "```\n",
    "# Import RegressionEvaluator\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# Complete the evaluator code\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\", predictionCol=\"prediction\")\n",
    "\n",
    "# Extract the 3 parameters\n",
    "print(evaluator.getMetricName())\n",
    "print(evaluator.getLabelCol())\n",
    "print(evaluator.getPredictionCol())\n",
    "\n",
    "<script.py> output:\n",
    "    rmse\n",
    "    rating\n",
    "    prediction\n",
    "```\n",
    "You now know how to build a model, generate predictions, and build an evaluator to tell you how well the model predicted the test values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get RMSE\n",
    "\n",
    "Now that you know how to build a model and generate predictions, and have an evaluator to tell us how well it predicts ratings, we can calculate the RMSE to see how well an ALS model performed. We'll use the evaluator that we built in the previous exercise to calculate and print the rmse.\n",
    "\n",
    "- Call the .evaluate() method on our evaluator to calculate our RMSE on the test_predictions dataframe. Call the result RMSE.\n",
    "- Print the RMSE\n",
    "\n",
    "```\n",
    "In [1]: test_predictions.show(5)\n",
    "+------+-------+------+----------+\n",
    "|userId|movieId|rating|prediction|\n",
    "+------+-------+------+----------+\n",
    "|     1|      1|   2.0| 2.0127134|\n",
    "|     2|      1|   4.0| 4.0069914|\n",
    "|     0|      1|   5.0| 4.7319183|\n",
    "|     3|      3|   5.0|  4.730774|\n",
    "|     2|      3|   3.0| 2.9880555|\n",
    "+------+-------+------+----------+\n",
    "only showing top 5 rows\n",
    "\n",
    "# Evaluate the \"test_predictions\" dataframe\n",
    "RMSE = evaluator.evaluate(test_predictions)\n",
    "\n",
    "# Print the RMSE\n",
    "print (RMSE)\n",
    "\n",
    "<script.py> output:\n",
    "    0.16853197489754093\n",
    "```\n",
    "This RMSE means that on average, the model's test predictions are about .16 off from the true values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Terminate the cluster\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<img src=\"images/spark6_053.png\" alt=\"\" style=\"width: 800px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "---\n",
    "<a id='intro'></a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
