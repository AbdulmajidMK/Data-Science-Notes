{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "From: https://github.com/ksatola\n",
    "Version: 0.0.1\n",
    "\n",
    "TODOs\n",
    "1. OLS Assumptions class for Linear Regression\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Algorithms\n",
    "Regression is a supervised machine learning process. It is similar to classification, but rather than predicting a label, we try to predict a continuous value. If you are trying to predict a number, then use regression.\n",
    "\n",
    "Sklearn supports many of the same classification models for regression problems. In fact, the API is the same, calling `.fit`, `.score`, and `.predict`. This is also true for the next-generation boosting libraries, XGBoost and LightGBM.\n",
    "\n",
    "Though there are similarities with the classification models and hyperparameters, the evaluation metrics are different for regression. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect with underlying Python code\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.insert(0, '../src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import (\n",
    "    get_dataset,\n",
    "    add_prefix_to_list_items\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# To eliminate Yellowbrick warming: findfont: Font family ['sans-serif'] not found. Falling back to DejaVu Sans.\n",
    "import matplotlib.font_manager\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crim</th>\n",
       "      <th>zn</th>\n",
       "      <th>indus</th>\n",
       "      <th>chas</th>\n",
       "      <th>nox</th>\n",
       "      <th>rm</th>\n",
       "      <th>age</th>\n",
       "      <th>dis</th>\n",
       "      <th>rad</th>\n",
       "      <th>tax</th>\n",
       "      <th>ptratio</th>\n",
       "      <th>b</th>\n",
       "      <th>lstat</th>\n",
       "      <th>medv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      crim    zn  indus  chas    nox     rm   age     dis  rad  tax  ptratio  \\\n",
       "0  0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296     15.3   \n",
       "1  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242     17.8   \n",
       "2  0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242     17.8   \n",
       "3  0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222     18.7   \n",
       "4  0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222     18.7   \n",
       "\n",
       "        b  lstat  medv  \n",
       "0  396.90   4.98  24.0  \n",
       "1  396.90   9.14  21.6  \n",
       "2  392.83   4.03  34.7  \n",
       "3  394.63   2.94  33.4  \n",
       "4  396.90   5.33  36.2  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This dataset contains information collected by the U.S Census Service concerning housing in the area of Boston Mass. \n",
    "# It was obtained from the StatLib archive (http://lib.stat.cmu.edu/datasets/boston), \n",
    "# and has been used extensively throughout the literature to benchmark algorithms. \n",
    "\n",
    "df = get_dataset('boston_housing')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import (\n",
    "    model_selection,\n",
    "    preprocessing,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    14\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Missing values?\n",
    "df.isnull().mean().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[['medv']]\n",
    "X = df.drop(columns=['medv'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>medv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>22.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>20.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>23.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>11.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     medv\n",
       "0    24.0\n",
       "1    21.6\n",
       "2    34.7\n",
       "3    33.4\n",
       "4    36.2\n",
       "..    ...\n",
       "501  22.4\n",
       "502  20.6\n",
       "503  23.9\n",
       "504  22.0\n",
       "505  11.9\n",
       "\n",
       "[506 rows x 1 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.41978194,  0.28482986, -1.2879095 , ..., -1.45900038,\n",
       "         0.44105193, -1.0755623 ],\n",
       "       [-0.41733926, -0.48772236, -0.59338101, ..., -0.30309415,\n",
       "         0.44105193, -0.49243937],\n",
       "       [-0.41734159, -0.48772236, -0.59338101, ..., -0.30309415,\n",
       "         0.39642699, -1.2087274 ],\n",
       "       ...,\n",
       "       [-0.41344658, -0.48772236,  0.11573841, ...,  1.17646583,\n",
       "         0.44105193, -0.98304761],\n",
       "       [-0.40776407, -0.48772236,  0.11573841, ...,  1.17646583,\n",
       "         0.4032249 , -0.86530163],\n",
       "       [-0.41500016, -0.48772236,  0.11573841, ...,  1.17646583,\n",
       "         0.44105193, -0.66905833]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standardize data\n",
    "cols = X.columns\n",
    "Xs = preprocessing.StandardScaler().fit_transform(X.values)\n",
    "Xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crim</th>\n",
       "      <th>zn</th>\n",
       "      <th>indus</th>\n",
       "      <th>chas</th>\n",
       "      <th>nox</th>\n",
       "      <th>rm</th>\n",
       "      <th>age</th>\n",
       "      <th>dis</th>\n",
       "      <th>rad</th>\n",
       "      <th>tax</th>\n",
       "      <th>ptratio</th>\n",
       "      <th>b</th>\n",
       "      <th>lstat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.419782</td>\n",
       "      <td>0.284830</td>\n",
       "      <td>-1.287909</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.144217</td>\n",
       "      <td>0.413672</td>\n",
       "      <td>-0.120013</td>\n",
       "      <td>0.140214</td>\n",
       "      <td>-0.982843</td>\n",
       "      <td>-0.666608</td>\n",
       "      <td>-1.459000</td>\n",
       "      <td>0.441052</td>\n",
       "      <td>-1.075562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.417339</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-0.593381</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.740262</td>\n",
       "      <td>0.194274</td>\n",
       "      <td>0.367166</td>\n",
       "      <td>0.557160</td>\n",
       "      <td>-0.867883</td>\n",
       "      <td>-0.987329</td>\n",
       "      <td>-0.303094</td>\n",
       "      <td>0.441052</td>\n",
       "      <td>-0.492439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.417342</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-0.593381</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.740262</td>\n",
       "      <td>1.282714</td>\n",
       "      <td>-0.265812</td>\n",
       "      <td>0.557160</td>\n",
       "      <td>-0.867883</td>\n",
       "      <td>-0.987329</td>\n",
       "      <td>-0.303094</td>\n",
       "      <td>0.396427</td>\n",
       "      <td>-1.208727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.416750</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-1.306878</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.835284</td>\n",
       "      <td>1.016303</td>\n",
       "      <td>-0.809889</td>\n",
       "      <td>1.077737</td>\n",
       "      <td>-0.752922</td>\n",
       "      <td>-1.106115</td>\n",
       "      <td>0.113032</td>\n",
       "      <td>0.416163</td>\n",
       "      <td>-1.361517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.412482</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-1.306878</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.835284</td>\n",
       "      <td>1.228577</td>\n",
       "      <td>-0.511180</td>\n",
       "      <td>1.077737</td>\n",
       "      <td>-0.752922</td>\n",
       "      <td>-1.106115</td>\n",
       "      <td>0.113032</td>\n",
       "      <td>0.441052</td>\n",
       "      <td>-1.026501</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       crim        zn     indus      chas       nox        rm       age  \\\n",
       "0 -0.419782  0.284830 -1.287909 -0.272599 -0.144217  0.413672 -0.120013   \n",
       "1 -0.417339 -0.487722 -0.593381 -0.272599 -0.740262  0.194274  0.367166   \n",
       "2 -0.417342 -0.487722 -0.593381 -0.272599 -0.740262  1.282714 -0.265812   \n",
       "3 -0.416750 -0.487722 -1.306878 -0.272599 -0.835284  1.016303 -0.809889   \n",
       "4 -0.412482 -0.487722 -1.306878 -0.272599 -0.835284  1.228577 -0.511180   \n",
       "\n",
       "        dis       rad       tax   ptratio         b     lstat  \n",
       "0  0.140214 -0.982843 -0.666608 -1.459000  0.441052 -1.075562  \n",
       "1  0.557160 -0.867883 -0.987329 -0.303094  0.441052 -0.492439  \n",
       "2  0.557160 -0.867883 -0.987329 -0.303094  0.396427 -1.208727  \n",
       "3  1.077737 -0.752922 -1.106115  0.113032  0.416163 -1.361517  \n",
       "4  1.077737 -0.752922 -1.106115  0.113032  0.441052 -1.026501  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xs_df = pd.DataFrame(Xs, index=X.index, columns=X.columns)\n",
    "Xs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs_train, Xs_test, ys_train, ys_test = train_test_split(Xs_df, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crim</th>\n",
       "      <th>zn</th>\n",
       "      <th>indus</th>\n",
       "      <th>chas</th>\n",
       "      <th>nox</th>\n",
       "      <th>rm</th>\n",
       "      <th>age</th>\n",
       "      <th>dis</th>\n",
       "      <th>rad</th>\n",
       "      <th>tax</th>\n",
       "      <th>ptratio</th>\n",
       "      <th>b</th>\n",
       "      <th>lstat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.417044</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-1.306878</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.835284</td>\n",
       "      <td>0.207096</td>\n",
       "      <td>-0.351157</td>\n",
       "      <td>1.077737</td>\n",
       "      <td>-0.752922</td>\n",
       "      <td>-1.106115</td>\n",
       "      <td>0.113032</td>\n",
       "      <td>0.410571</td>\n",
       "      <td>-1.043322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>-0.405205</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-0.164408</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.066472</td>\n",
       "      <td>-0.154767</td>\n",
       "      <td>0.139579</td>\n",
       "      <td>-0.506241</td>\n",
       "      <td>-0.408041</td>\n",
       "      <td>0.141134</td>\n",
       "      <td>-0.303094</td>\n",
       "      <td>0.401580</td>\n",
       "      <td>-0.085935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>-0.400569</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-0.616727</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.921667</td>\n",
       "      <td>-0.858548</td>\n",
       "      <td>-1.236615</td>\n",
       "      <td>0.620527</td>\n",
       "      <td>-0.752922</td>\n",
       "      <td>-1.040783</td>\n",
       "      <td>-0.256858</td>\n",
       "      <td>0.441052</td>\n",
       "      <td>-0.342453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.297868</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-0.437258</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.144217</td>\n",
       "      <td>-0.498110</td>\n",
       "      <td>-1.396638</td>\n",
       "      <td>0.334449</td>\n",
       "      <td>-0.637962</td>\n",
       "      <td>-0.601276</td>\n",
       "      <td>1.176466</td>\n",
       "      <td>0.330860</td>\n",
       "      <td>-0.851284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>1.392077</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>1.015999</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>0.218592</td>\n",
       "      <td>-0.510932</td>\n",
       "      <td>0.086238</td>\n",
       "      <td>-0.421483</td>\n",
       "      <td>1.661245</td>\n",
       "      <td>1.530926</td>\n",
       "      <td>0.806576</td>\n",
       "      <td>0.132296</td>\n",
       "      <td>0.767723</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         crim        zn     indus      chas       nox        rm       age  \\\n",
       "5   -0.417044 -0.487722 -1.306878 -0.272599 -0.835284  0.207096 -0.351157   \n",
       "116 -0.405205 -0.487722 -0.164408 -0.272599 -0.066472 -0.154767  0.139579   \n",
       "45  -0.400569 -0.487722 -0.616727 -0.272599 -0.921667 -0.858548 -1.236615   \n",
       "16  -0.297868 -0.487722 -0.437258 -0.272599 -0.144217 -0.498110 -1.396638   \n",
       "468  1.392077 -0.487722  1.015999 -0.272599  0.218592 -0.510932  0.086238   \n",
       "\n",
       "          dis       rad       tax   ptratio         b     lstat  \n",
       "5    1.077737 -0.752922 -1.106115  0.113032  0.410571 -1.043322  \n",
       "116 -0.506241 -0.408041  0.141134 -0.303094  0.401580 -0.085935  \n",
       "45   0.620527 -0.752922 -1.040783 -0.256858  0.441052 -0.342453  \n",
       "16   0.334449 -0.637962 -0.601276  1.176466  0.330860 -0.851284  \n",
       "468 -0.421483  1.661245  1.530926  0.806576  0.132296  0.767723  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xs_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Model\n",
    "A baseline regression model will give us something to compare our other models to. In sklearn, the default result of the `.score` method is the `coefficient of determination (r² or R²)`. This number explains the percent of variation of the input data that the prediction captures. The value is typically between 0 and 1, but it can be negative in the case of particulary bad models.\n",
    "\n",
    "The default strategy of the `DummyRegressor` is to predict the mean value of the training set. We can see that this model does not perform very well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.03469753992352409"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.dummy import DummyRegressor\n",
    "\n",
    "dr = DummyRegressor()\n",
    "dr.fit(Xs_train, ys_train)\n",
    "dr.score(Xs_test, ys_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression\n",
    "[Simple linear regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html) is taught in math and beginning statistics courses. It tries to fit a form of the formula `y = mx + b` while minimizing the square of the errors. When solved, we have an intercept and coefficient. The `intercept` gives a base value for a prediction modified by adding the product of the `coefficient` and the input.\n",
    "\n",
    "This form can be generalized to higher dimensions. In that case each feature has a `coefficient`. The larger the absolute value of the coefficient, the more impact the feature has on the target.\n",
    "\n",
    "This model assumes that the prediction is a linear combination of the inputs. For some datasets, this is not flexible enough. Complexity can be added by transforming the features (the sklearn `preprocessing.PolynomialFeatures` transformer can create polynomial combinations of the features). If this leads to overfitting, `ridge` and `lasso` regression may be used to regularize the estimator.\n",
    "\n",
    "This model is also susceptible to `heteroscedasticity`. This is the idea that as the input values change in size, the error of the prediction (or the residuals) often changes as well. If you plot the input against the residuals, you will see a fan or cone shape. We will see examples of that later.\n",
    "\n",
    "Another issue to be aware of is `multicollinearity`. If columns have high correlation, it can hinder interpretation of the coefficients. This usually does not impact the model, only coefficient meaning.\n",
    "\n",
    "A linear regression model has the following properties:\n",
    "- **Runtime efficiency:** Use n_jobs to speed up performance.\n",
    "- **Preprocess data:** Standardize data before training the model.\n",
    "- **Prevent overfitting:** You can simplify the model by not using or adding polynomial features.\n",
    "- **Interpret results:** Can interpret results as weights for feature contribution, but assumes normality and independence of features. You might want to remove colinear features to improve interpretability. R² will tell you how much of the total variance of the outcome is explained by the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(n_jobs=-1)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Non-standardized data\n",
    "lr = LinearRegression(n_jobs=-1)\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7112260057484903"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.33470103e-01,  3.58089136e-02,  4.95226452e-02,\n",
       "         3.11983512e+00, -1.54170609e+01,  4.05719923e+00,\n",
       "        -1.08208352e-02, -1.38599824e+00,  2.42727340e-01,\n",
       "        -8.70223437e-03, -9.10685208e-01,  1.17941159e-02,\n",
       "        -5.47113313e-01]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([31.63108404])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `.intercept_` value is the `expected mean value`. You can see how scaling the data affects the coefficients. `The sign of the coefficients` explains the direction of the relation between the feature and the target. A positive sign indicates that as the feature increases, the label increases. A negative sign indicates that as the feature increases, the label decreases. The larger the absolute value of the coefficient, the more impact it has."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(n_jobs=-1)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standardized data\n",
    "lrs = LinearRegression(n_jobs=-1)\n",
    "lrs.fit(Xs_train, ys_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7112260057484925"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrs.score(Xs_test, ys_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.14691411,  0.83432605,  0.33940694,  0.79163612, -1.784727  ,\n",
       "         2.84783949, -0.30429306, -2.91562521,  2.11140045, -1.46519951,\n",
       "        -1.9696347 ,  1.07567771, -3.90310727]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrs.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([22.50945471])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrs.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use Yellowbrick to visualize coefficients. Because the scaled Boston data is a numpy array rather than a pandas DataFrame, we need to pass the `labels` parameter if we want to use the column names."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "CRIM - per capita crime rate by town\n",
    "ZN - proportion of residential land zoned for lots over 25,000 sq.ft.\n",
    "INDUS - proportion of non-retail business acres per town.\n",
    "CHAS - Charles River dummy variable (1 if tract bounds river; 0 otherwise)\n",
    "NOX - nitric oxides concentration (parts per 10 million)\n",
    "RM - average number of rooms per dwelling\n",
    "AGE - proportion of owner-occupied units built prior to 1940\n",
    "DIS - weighted distances to five Boston employment centres\n",
    "RAD - index of accessibility to radial highways\n",
    "TAX - full-value property-tax rate per $10,000\n",
    "PTRATIO - pupil-teacher ratio by town\n",
    "B - 1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
    "LSTAT - % lower status of the population\n",
    "MEDV - Median value of owner-occupied homes in $1000's\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/base.py:209: FutureWarning: From version 0.24, get_params will raise an AttributeError if a parameter cannot be retrieved as an instance attribute. Previously it would return None.\n",
      "  warnings.warn('From version 0.24, get_params will raise an '\n",
      "/usr/local/lib/python3.8/dist-packages/yellowbrick/model_selection/importances.py:190: YellowbrickWarning: detected multi-dimensional feature importances but stack=False, using mean to aggregate them.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from yellowbrick.features import FeatureImportances\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "fi_viz = FeatureImportances(lrs, labels=X.columns)\n",
    "fi_viz.fit(Xs_train, ys_train.values.ravel())\n",
    "fi_viz.poof()\n",
    "fig.savefig(\"images/regression_linear_regression.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVMs\n",
    "Support vector machines can perform regression as well.\n",
    "\n",
    "SVMs have the following properties:\n",
    "- **Runtime efficiency:** The scikit-learn implementation is O(n⁴), so it can be hard to scale to large sizes. Using a linear kernel or the LinearSVR model can improve the runtime performance at perhaps the cost of accuracy. Upping the cache_size parameter can bring that down to O(n³).\n",
    "- **Preprocess data:** The algorithm is not scale invariant, so standardizing the data is highly recommended.\n",
    "- **Prevent overfitting:** \n",
    "- **Interpret results:** \n",
    "\n",
    "Runtime efficiency\n",
    "\n",
    "\n",
    "Preprocess data\n",
    "\n",
    "\n",
    "Prevent overfitting\n",
    "The C (penalty parameter) controls regularization. A smaller value allows for a smaller margin in the hyperplane. A higher value for gamma will tend to overfit the training data. The LinearSVR model supports a loss and penalty parameter for regularization. The epsilon parameter can be raised (with 0 you should expect overfitting).\n",
    "\n",
    "Interpret results\n",
    "Inspect .support_vectors_, though these are hard to interpret. With linear kernels, you can inspect .coef_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "- **Runtime efficiency:** \n",
    "- **Preprocess data:** \n",
    "- **Prevent overfitting:** \n",
    "- **Interpret results:** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
