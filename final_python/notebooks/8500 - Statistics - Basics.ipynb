{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "From: https://github.com/ksatola\n",
    "Version: 0.0.1\n",
    "\n",
    "TODOs\n",
    "1. Distributions: \n",
    "    - https://mathworld.wolfram.com/PoissonDistribution.html\n",
    "    - https://mathworld.wolfram.com/BinomialDistribution.html\n",
    "    - https://mathworld.wolfram.com/UniformDistribution.html\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistics - Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation vs. Regression\n",
    "Correlation and regression are far from the same concept. So, let’s see what the relationship is between correlation analysis and regression analysis.\n",
    "\n",
    "There is a single expression that sums it up nicely: **correlation does not imply causation**!\n",
    "\n",
    "### The Relationship between Variables\n",
    "**Correlation** measures the degree of relationship between two variables. **Regression analysis** is about how one variable affects another or what changes it triggers in the other.\n",
    "\n",
    "### Causality\n",
    "**Correlation** doesn’t capture causality but the degree of interrelation between the two variables. **Regression** is based on causality. It shows no degree of connection, but cause and effect.\n",
    "\n",
    "### Are X and Y Interchangeable?\n",
    "A property of **correlation** is that the correlation between x and y is the same as between y and x. You can easily spot that from the formula, which is symmetrical. **Regressions** of y on x and x on y yield different results. Think about income and education. Predicting income, based on education makes sense, but the opposite does not.\n",
    "\n",
    "### Graphical Representation of Correlation and Regression Analysis\n",
    "The two methods have a very different graphical representation. **Linear regression analysis** is known for the best fitting line that goes through the data points and minimizes the distance between them. Whereas, **correlation** is a single point.\n",
    "\n",
    "<img src=\"images/stats_correlation_and_regression.jpg\" alt=\"\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probability Distribution\n",
    "\n",
    "When we use the term normal distribution in statistics, we usually mean a `probability distribution`. Good examples are the Normal distribution, the Binomial distribution, and the Uniform distribution. **A distribution in statistics is a function that shows the possible values for a variable and how often they occur**.\n",
    "\n",
    "<img src=\"images/stats_probability_distributions.png\" alt=\"\" style=\"width: 600px;\"/>\n",
    "\n",
    "The distribution of an event consists not only of the input values that can be observed, but is made up of all possible values.\n",
    "\n",
    "<img src=\"images/stats_probability_rolling_a_die.png\" alt=\"\" style=\"width: 600px;\"/>\n",
    "\n",
    "So, the distribution of the event – rolling a die – will be given by the following table. The probability of getting one is 0.17, the probability of getting 2 is 0.17, and so on… you are sure that you have exhausted all possible values when the sum of probabilities is equal to 1 or 100%. For all other values, the probability of occurrence is 0.\n",
    "\n",
    "<img src=\"images/stats_probability_rolling_a_die2.png\" alt=\"\" style=\"width: 600px;\"/>\n",
    "\n",
    "Each probability distribution is associated with a graph describing the likelihood of occurrence of every event. Here’s the graph for our example. This type of distribution is called a `uniform distribution`.\n",
    "\n",
    "<img src=\"images/stats_probability_rolling_a_die3.png\" alt=\"\" style=\"width: 600px;\"/>\n",
    "\n",
    "It is crucial to understand that the distribution in statistics is defined by the underlying probabilities and not the graph. The graph is just a visual representation. \n",
    "\n",
    "Now think about rolling two dice. What are the possibilities? One and one, two and one, one and two, and so on. \n",
    "\n",
    "<img src=\"images/stats_probability_rolling_a_die4.png\" alt=\"\" style=\"width: 600px;\"/>\n",
    "\n",
    "Here’s a table with all the possible combinations. \n",
    "\n",
    "<img src=\"images/stats_probability_rolling_a_die5.png\" alt=\"\" style=\"width: 600px;\"/>\n",
    "\n",
    "We are interested in the sum of the two dice. So, what’s the probability of getting a sum of 1? It’s 0, as this event is impossible. What’s the probability of getting a sum of 2? There is only one combination that would give us a sum of 2 – when both dice are equal to 1. So, 1 out of 36 total outcomes, or 0.03. Similarly, the probability of getting a sum of 3 is given by the number of combinations that give a sum of three divided by 36. Therefore, 2 divided by 36, or 0.06. We continue this way until we have the full probability distribution.\n",
    "\n",
    "Let’s see the graph associated with it. So, looking at it we understand that when rolling two dice, the probability of getting a 7 is the highest. We can also compare different outcomes such as: the probability of getting a 10 and the probability of getting a 5. It’s evident that it’s less likely that we’ll get a 10.\n",
    "\n",
    "<img src=\"images/stats_probability_rolling_a_die6.png\" alt=\"\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Normal Distribution\n",
    "The normal distribution is essential when it comes to statistics. Not only does it approximate a wide variety of variables, but decisions based on its insights have a great track record. Also, distributions of sample means with large enough sample sizes could be approximated to normal (even the original distributions from which the samples were drawn are not normal).\n",
    "\n",
    "The statistical term for it is **Gaussian distribution**. Though, many people call it the **Bell Curve**, as it is shaped like a bell. It is symmetrical and its mean, median and mode are equal. It has no skew. It is perfectly centred around its mean.\n",
    "\n",
    "<img src=\"images/stats_normal_distribution.jpg\" alt=\"\" style=\"width: 600px;\"/>\n",
    "\n",
    "On the plane, you can notice that the highest point is located at the mean. This is because it coincides with the mode. The spread of the graph is determined by the standard deviation, as it is shown below.\n",
    "\n",
    "<img src=\"images/stats_normal_distribution2.jpg\" alt=\"\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis Testing\n",
    "\n",
    "There are four hypothesis testing steps in data-driven decision-making:\n",
    "1. Formulate a hypothesis.\n",
    "2. Find the right test for your hypothesis.\n",
    "3. Execute the test.\n",
    "4. Make a decision based on the result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Hypothesis\n",
    "A hypothesis is an idea that can be tested (compared with something else).\n",
    "\n",
    "So, if I tell you that apples in New York are expensive, this is an idea, or a statement, but is not testable, until I have something to compare it with. For instance, if I define expensive as: any price higher than $1.75 dollars per pound, then it immediately becomes a hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An Example\n",
    "\n",
    "#### Two-sided or а two-tailed test\n",
    "\n",
    "Here’s a simple topic that can be tested.\n",
    "\n",
    "According to Glassdoor (the popular salary information website), the mean data scientist salary in the US is 113,000 dollars. So, we want to test if their estimate is correct.\n",
    "\n",
    "There are two hypotheses that are made: the null hypothesis, denoted H zero, and the alternative hypothesis, denoted H one or H A. The null hypothesis is the one to be tested and the alternative is everything else. In our example,\n",
    "\n",
    "The null hypothesis would be: The mean data scientist salary is 113,000 dollars,\n",
    "\n",
    "While the alternative: The mean data scientist salary is not 113,000 dollars.\n",
    "\n",
    "Now, you would want to check if 113,000 is close enough to the true mean, predicted by our sample. In case it is, you would accept the null hypothesis. Otherwise, you would reject the null hypothesis.\n",
    "\n",
    "The concept of the null hypothesis is similar to: innocent until proven guilty. We assume that the mean salary is 113,000 dollars and we try to prove otherwise.\n",
    "\n",
    "#### One sided or one-tailed test\n",
    "\n",
    "This was an example of a two-sided or а two-tailed test. You can also form one sided or one-tailed tests. Say your friend, Paul, told you that he thinks data scientists earn more than 125,000 dollars per year. You doubt him so you design a test to see who’s right.\n",
    "\n",
    "The null hypothesis of this test would be: The mean data scientist salary is more than 125,000 dollars.\n",
    "\n",
    "The alternative will cover everything else, thus: The mean data scientist salary is less than or equal to 125,000 dollars.\n",
    "\n",
    "It is important to note that outcomes of tests refer to the population parameter rather than the sample statistic! As such, the result that we get is for the population.\n",
    "\n",
    "Another crucial consideration is that, generally, the researcher is trying to reject the null hypothesis. Think about the null hypothesis as the status quo and the alternative as the change or innovation that challenges that status quo. In our example, Paul was representing the status quo, which we were challenging.\n",
    "\n",
    "Alright. We showed you the four hypothesis testing steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Type I and Type II Errors\n",
    "In general, we can have two types of errors – `type I error` and `ype II error`.\n",
    "\n",
    "**Type I error** is when you reject a true null hypothesis and is the more serious error. It is also called `a false positive`. The probability of making this error is `alpha` – the `level of significance`. Since you, the researcher, choose the alpha, the responsibility for making this error lies solely on you.\n",
    "\n",
    "**Type II error** is when you accept a false null hypothesis. The probability of making this error is denoted by `beta`. Beta depends mainly on sample size and population variance. So, if your topic is difficult to test due to hard sampling or has high variability, it is more likely to make this type of error. As you can imagine, if the data set is hard to test, it is not your fault, so Type II error is considered a smaller problem.\n",
    "\n",
    "We should also mention that the `probability of rejecting a false null hypothesis` is equal to 1 minus beta. This is the researcher’s goal – to reject a false null hypothesis. Therefore, 1 minus beta is called `the power of the test`. Generally, researchers increase the power of a test by increasing the sample size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An Example\n",
    "\n",
    "You are in love with this girl from the other class, but are unsure if she likes you.\n",
    "\n",
    "There are two errors you can make.\n",
    "First, if she likes you back and you don’t invite her out, you are making the type I error.\n",
    "\n",
    "The null hypothesis in this situation is: she likes you back. It turns out that she really did like you back. Unfortunately, you did not invite her out, because after testing the situation, you wrongly thought the null hypothesis was false. In other words, you made a type I error – you rejected a true null hypothesis and lost your chance. It is a very serious problem, because you could have been made for each other, but you didn’t even try.\n",
    "\n",
    "Now imagine another situation. She doesn’t like you back, but you go and invite her out. The null hypothesis is still: she likes you back, but this time it is false. In reality she doesn’t really like you back, that is. However, after testing, you accept the null hypothesis and wrongly go and invite her out. She tells you she has a boyfriend that is much older, smarter and better at statistics than you and turns her back.\n",
    "\n",
    "You made a type II error – accepted a false null hypothesis. However, it is no big deal, as you go back to your normal life without her and soon forget about this awkward situation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
