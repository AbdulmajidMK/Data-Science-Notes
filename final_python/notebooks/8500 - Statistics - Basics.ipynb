{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "From: https://github.com/ksatola\n",
    "Version: 0.0.1\n",
    "\n",
    "TODOs\n",
    "1. Distributions: \n",
    "    - https://mathworld.wolfram.com/PoissonDistribution.html\n",
    "    - https://mathworld.wolfram.com/BinomialDistribution.html\n",
    "    - https://mathworld.wolfram.com/UniformDistribution.html\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistics - Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation vs. Regression\n",
    "Correlation and regression are far from the same concept. So, let’s see what the relationship is between correlation analysis and regression analysis.\n",
    "\n",
    "There is a single expression that sums it up nicely: **correlation does not imply causation**!\n",
    "\n",
    "### The Relationship between Variables\n",
    "**Correlation** measures the degree of relationship between two variables. **Regression analysis** is about how one variable affects another or what changes it triggers in the other.\n",
    "\n",
    "### Causality\n",
    "**Correlation** doesn’t capture causality but the degree of interrelation between the two variables. **Regression** is based on causality. It shows no degree of connection, but cause and effect.\n",
    "\n",
    "### Are X and Y Interchangeable?\n",
    "A property of **correlation** is that the correlation between x and y is the same as between y and x. You can easily spot that from the formula, which is symmetrical. **Regressions** of y on x and x on y yield different results. Think about income and education. Predicting income, based on education makes sense, but the opposite does not.\n",
    "\n",
    "### Graphical Representation of Correlation and Regression Analysis\n",
    "The two methods have a very different graphical representation. **Linear regression analysis** is known for the best fitting line that goes through the data points and minimizes the distance between them. Whereas, **correlation** is a single point.\n",
    "\n",
    "<img src=\"images/stats_correlation_and_regression.jpg\" alt=\"\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probability Distribution\n",
    "\n",
    "When we use the term normal distribution in statistics, we usually mean a `probability distribution`. Good examples are the Normal distribution, the Binomial distribution, and the Uniform distribution. **A distribution in statistics is a function that shows the possible values for a variable and how often they occur**.\n",
    "\n",
    "<img src=\"images/stats_probability_distributions.png\" alt=\"\" style=\"width: 600px;\"/>\n",
    "\n",
    "The distribution of an event consists not only of the input values that can be observed, but is made up of all possible values.\n",
    "\n",
    "<img src=\"images/stats_probability_rolling_a_die.png\" alt=\"\" style=\"width: 600px;\"/>\n",
    "\n",
    "So, the distribution of the event – rolling a die – will be given by the following table. The probability of getting one is 0.17, the probability of getting 2 is 0.17, and so on… you are sure that you have exhausted all possible values when the sum of probabilities is equal to 1 or 100%. For all other values, the probability of occurrence is 0.\n",
    "\n",
    "<img src=\"images/stats_probability_rolling_a_die2.png\" alt=\"\" style=\"width: 600px;\"/>\n",
    "\n",
    "Each probability distribution is associated with a graph describing the likelihood of occurrence of every event. Here’s the graph for our example. This type of distribution is called a `uniform distribution`.\n",
    "\n",
    "<img src=\"images/stats_probability_rolling_a_die3.png\" alt=\"\" style=\"width: 600px;\"/>\n",
    "\n",
    "It is crucial to understand that the distribution in statistics is defined by the underlying probabilities and not the graph. The graph is just a visual representation. \n",
    "\n",
    "Now think about rolling two dice. What are the possibilities? One and one, two and one, one and two, and so on. \n",
    "\n",
    "<img src=\"images/stats_probability_rolling_a_die4.png\" alt=\"\" style=\"width: 600px;\"/>\n",
    "\n",
    "Here’s a table with all the possible combinations. \n",
    "\n",
    "<img src=\"images/stats_probability_rolling_a_die5.png\" alt=\"\" style=\"width: 600px;\"/>\n",
    "\n",
    "We are interested in the sum of the two dice. So, what’s the probability of getting a sum of 1? It’s 0, as this event is impossible. What’s the probability of getting a sum of 2? There is only one combination that would give us a sum of 2 – when both dice are equal to 1. So, 1 out of 36 total outcomes, or 0.03. Similarly, the probability of getting a sum of 3 is given by the number of combinations that give a sum of three divided by 36. Therefore, 2 divided by 36, or 0.06. We continue this way until we have the full probability distribution.\n",
    "\n",
    "Let’s see the graph associated with it. So, looking at it we understand that when rolling two dice, the probability of getting a 7 is the highest. We can also compare different outcomes such as: the probability of getting a 10 and the probability of getting a 5. It’s evident that it’s less likely that we’ll get a 10.\n",
    "\n",
    "<img src=\"images/stats_probability_rolling_a_die6.png\" alt=\"\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Normal Distribution\n",
    "The normal distribution is essential when it comes to statistics. Not only does it approximate a wide variety of variables, but decisions based on its insights have a great track record. Also, distributions of sample means with large enough sample sizes could be approximated to normal (even the original distributions from which the samples were drawn are not normal).\n",
    "\n",
    "The statistical term for it is **Gaussian distribution**. Though, many people call it the **Bell Curve**, as it is shaped like a bell. It is symmetrical and its mean, median and mode are equal. It has no skew. It is perfectly centred around its mean.\n",
    "\n",
    "<img src=\"images/stats_normal_distribution.jpg\" alt=\"\" style=\"width: 600px;\"/>\n",
    "\n",
    "On the plane, you can notice that the highest point is located at the mean. This is because it coincides with the mode. The spread of the graph is determined by the standard deviation, as it is shown below.\n",
    "\n",
    "<img src=\"images/stats_normal_distribution2.jpg\" alt=\"\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis Testing\n",
    "\n",
    "There are four hypothesis testing steps in data-driven decision-making:\n",
    "1. Formulate a hypothesis.\n",
    "2. Find the right test for your hypothesis.\n",
    "3. Execute the test.\n",
    "4. Make a decision based on the result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Hypothesis\n",
    "A hypothesis is an idea that can be tested (compared with something else).\n",
    "\n",
    "So, if I tell you that apples in New York are expensive, this is an idea, or a statement, but is not testable, until I have something to compare it with. For instance, if I define expensive as: any price higher than $1.75 dollars per pound, then it immediately becomes a hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An Example\n",
    "\n",
    "#### Two-sided or а two-tailed test\n",
    "\n",
    "Here’s a simple topic that can be tested.\n",
    "\n",
    "According to Glassdoor (the popular salary information website), the mean data scientist salary in the US is 113,000 dollars. So, we want to test if their estimate is correct.\n",
    "\n",
    "There are two hypotheses that are made: the null hypothesis, denoted H zero, and the alternative hypothesis, denoted H one or H A. The null hypothesis is the one to be tested and the alternative is everything else. In our example,\n",
    "\n",
    "The null hypothesis would be: The mean data scientist salary is 113,000 dollars,\n",
    "\n",
    "While the alternative: The mean data scientist salary is not 113,000 dollars.\n",
    "\n",
    "Now, you would want to check if 113,000 is close enough to the true mean, predicted by our sample. In case it is, you would accept the null hypothesis. Otherwise, you would reject the null hypothesis.\n",
    "\n",
    "The concept of the null hypothesis is similar to: innocent until proven guilty. We assume that the mean salary is 113,000 dollars and we try to prove otherwise.\n",
    "\n",
    "#### One sided or one-tailed test\n",
    "\n",
    "This was an example of a two-sided or а two-tailed test. You can also form one sided or one-tailed tests. Say your friend, Paul, told you that he thinks data scientists earn more than 125,000 dollars per year. You doubt him so you design a test to see who’s right.\n",
    "\n",
    "The null hypothesis of this test would be: The mean data scientist salary is more than 125,000 dollars.\n",
    "\n",
    "The alternative will cover everything else, thus: The mean data scientist salary is less than or equal to 125,000 dollars.\n",
    "\n",
    "It is important to note that outcomes of tests refer to the population parameter rather than the sample statistic! As such, the result that we get is for the population.\n",
    "\n",
    "Another crucial consideration is that, generally, the researcher is trying to reject the null hypothesis. Think about the null hypothesis as the status quo and the alternative as the change or innovation that challenges that status quo. In our example, Paul was representing the status quo, which we were challenging.\n",
    "\n",
    "Alright. We showed you the four hypothesis testing steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Type I and Type II Errors\n",
    "In general, we can have two types of errors – `type I error` and `ype II error`.\n",
    "\n",
    "**Type I error** is when you reject a true null hypothesis and is the more serious error. It is also called `a false positive`. The probability of making this error is `alpha` – the `level of significance`. Since you, the researcher, choose the alpha, the responsibility for making this error lies solely on you.\n",
    "\n",
    "**Type II error** is when you accept a false null hypothesis. The probability of making this error is denoted by `beta`. Beta depends mainly on sample size and population variance. So, if your topic is difficult to test due to hard sampling or has high variability, it is more likely to make this type of error. As you can imagine, if the data set is hard to test, it is not your fault, so Type II error is considered a smaller problem.\n",
    "\n",
    "We should also mention that the `probability of rejecting a false null hypothesis` is equal to 1 minus beta. This is the researcher’s goal – to reject a false null hypothesis. Therefore, 1 minus beta is called `the power of the test`. Generally, researchers increase the power of a test by increasing the sample size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An Example\n",
    "\n",
    "You are in love with this girl from the other class, but are unsure if she likes you.\n",
    "\n",
    "There are two errors you can make.\n",
    "First, if she likes you back and you don’t invite her out, you are making the type I error.\n",
    "\n",
    "The null hypothesis in this situation is: she likes you back. It turns out that she really did like you back. Unfortunately, you did not invite her out, because after testing the situation, you wrongly thought the null hypothesis was false. In other words, you made a type I error – you rejected a true null hypothesis and lost your chance. It is a very serious problem, because you could have been made for each other, but you didn’t even try.\n",
    "\n",
    "Now imagine another situation. She doesn’t like you back, but you go and invite her out. The null hypothesis is still: she likes you back, but this time it is false. In reality she doesn’t really like you back, that is. However, after testing, you accept the null hypothesis and wrongly go and invite her out. She tells you she has a boyfriend that is much older, smarter and better at statistics than you and turns her back.\n",
    "\n",
    "You made a type II error – accepted a false null hypothesis. However, it is no big deal, as you go back to your normal life without her and soon forget about this awkward situation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistics 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean, Median, Mode, Weighted Mean, Harmonic Mean\n",
    "\n",
    "### Example 1\n",
    "```\n",
    "Provide the mean and median for this data set: 4, 6, 8, 10, 17\n",
    "mean = 45/5 = 9\n",
    "median = 8\n",
    "```\n",
    "### Example 2\n",
    "```\n",
    "Provide the mode for the dataset: 3,5,7,10,3,3,9,2,5,10,9.\n",
    "3\n",
    "```\n",
    "\n",
    "\n",
    "## Min, Max, Range, Variance, Standard Deviation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## z-score\n",
    "How many standard deviations our data point lies from the mean?\n",
    "\n",
    "<img src=\"images/z-score.png\" alt=\"\" style=\"width: 200px;\"/>\n",
    "\n",
    "Simply put, a `z-score` (also called a `standard score`) gives you an idea of how far from the mean a data point is. But more technically it’s a measure of how many standard deviations below or above the population mean a raw score is.\n",
    "\n",
    "A z-score can be placed on a normal distribution curve. Z-scores range from -3 standard deviations (which would fall to the far left of the normal distribution curve) up to +3 standard deviations (which would fall to the far right of the normal distribution curve). In order to use a z-score, you need to know the mean μ and also the population standard deviation σ.\n",
    "\n",
    "Z-scores are a way to compare results to a “normal” population. Results from tests or surveys have thousands of possible results and units; those results can often seem meaningless. For example, knowing that someone’s weight is 150 pounds might be good information, but if you want to compare it to the “average” person’s weight, looking at a vast table of data can be overwhelming (especially if some weights are recorded in kilograms). A z-score can tell you where that person’s weight is compared to the average population’s mean weight.\n",
    "\n",
    "see: https://www.statisticshowto.com/probability-and-statistics/z-score/\n",
    "\n",
    "z-score, standard score example:\n",
    "\n",
    "<img src=\"images/z-score-iq-example.png\" alt=\"\" style=\"width: 400px;\"/>\n",
    "\n",
    "\n",
    "<img src=\"images/z-score-empirical-rule.png\" alt=\"\" style=\"width: 400px;\"/>\n",
    "\n",
    "### Example 1\n",
    "```\n",
    "For a certain data set we have a mean of 100, a median of 95, and a standard deviation of 25. What is the z-score for the data point 138?\n",
    "Answer: z-score = (138-100)/25 = 1.52\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Empirical Rule ( 68-95-99.7) - Three Sigma Rule\n",
    "When you use a standard normal distribution (aka Gaussian Distribution):\n",
    "\n",
    "- About 68% of values fall within one standard deviation of the mean.\n",
    "- About 95% of the values fall within two standard deviations from the mean.\n",
    "- Almost all of the values—about 99.7%—fall within three standard deviations from the mean.\n",
    "\n",
    "These facts are the `68 95 99.7 rule`. It is sometimes called the `Empirical Rul`e because the rule originally came from observations (empirical means “based on observation”).\n",
    "\n",
    "The Normal/Gaussian distribution is the most common type of data distribution. All of the measurements are computed as distances from the mean and are reported in standard deviations.\n",
    "\n",
    "The Gaussian curve is a symmetric distribution, so the middle 68.2% can be divided in two. Zero to 1 standard deviations from the mean has 34.1% of the data. The opposite side is the same (0 to -1 standard deviations). Together, this area adds up to about 68% of the data.\n",
    "\n",
    "<img src=\"images/Empirical-rule-FINAL.jpg\" alt=\"\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Percentile Rank\n",
    "\n",
    "<img src=\"images/percentile_rank.png\" alt=\"\" style=\"width: 600px;\"/>\n",
    "\n",
    "Example of PR calculation for score of 85\n",
    "\n",
    "<img src=\"images/percentile_rank_85.png\" alt=\"\" style=\"width: 600px;\"/>\n",
    "\n",
    "<img src=\"images/PR_and_NCE.gif\" alt=\"\" style=\"width: 600px;\"/>\n",
    "\n",
    "\n",
    "\n",
    "See: https://en.wikipedia.org/wiki/Percentile_rank\n",
    "\n",
    "### Example 1\n",
    "```\n",
    "Six students earn the following test scores: 60, 70, 80, 90, 95, 100. The student that scored 95 is in the _____ percentile.\n",
    "Answer: (4 + 0.5) / 6 * 100 = 75\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probability\n",
    "Always consider a type of probability you encounter and ask how it was calculated/infered to assess how reliable it might be\n",
    "- **Objective** probabilities (based on calculations)\n",
    "    - **Classical** (coin flip, roll a die) - we know all possible outcomes and they are equally likely to occur\n",
    "        - How: `number of wins / all possible outcomes = % of probability`\n",
    "    - **Empirical** (number of successful shots by a footbal player) \n",
    "        - possible outcomes are not equally likely to occur, each attempt is different and can be influenced by many factors. \n",
    "        - based on past data - we can only use historical data to infer, the more data we have, the more trust we can in the probability \n",
    "        - not perfect but can be done if we have some data in repeating situations\n",
    "        - gives a nice idea of what to expect\n",
    "        - How: `number of successful shots / all shots by the player = % of probability (ratio)`\n",
    "- **Subjective** (based on experience)\n",
    "    - Uses people's opinions and experience and perhaps some related data that influence the statement about probability\n",
    "    - A guess\n",
    "    \n",
    "### Example 1\n",
    "```\n",
    "When people attend a fundraiser, 40% of them donate money. If three people attend this month’s fundraiser -- Jane, Kate, and Liza -- what are the exact chances that just one of them will donate money?\n",
    "Answer:\n",
    "Probability of donating Amount = 40/100 = 0.4\n",
    "Probability of not donating Amount = 1 - 0.4 = 0.6\n",
    "Three possibilities\n",
    "- Jane Donates but Kate & liza do not donate\n",
    "- Kate donate but jane & liza do not donate\n",
    "- Liza donate but Jane & Kate do nt donate\n",
    "\n",
    "p = (0.4)(0.6)(0.6) + (0.4)(0.6)(0.6) + (0.4)(0.6)(0.6) = 0.432 = 43.2%\n",
    "```\n",
    "### Example 2\n",
    "```\n",
    "On an exam, 60 of 100 people got a passing score. 50 of 100 people studied for the exam. 45 of the people that studied got a passing score. Studying for the exam and passing the exam are _____.\n",
    "Answer: dependent events\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Permutations: the order of things\n",
    "The number of ways in which objects can be arranged (order matters)\n",
    "- `n!` (n factorial)\n",
    "- for 5 objects: 5! = 5x4x3x2x1 = 120\n",
    "\n",
    "How many permutation we have when selecting x objects out of n?\n",
    "- `n! / (n-x)!`\n",
    "- if we have 8 players, how many permutations we may have on the podium (3 places)?\n",
    "- 8! / (8-3)! = 8x7x6 = 336\n",
    "\n",
    "### Example 1\n",
    "```\n",
    "There are 5 total candidates available for 2 different jobs. How many permutations are there for those two jobs from the pool of 5 candidates?\n",
    "Answer: 5! / (5-2)! = 5x4 = 20\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combinations: permutations without regard for order\n",
    "The number of ways in which objects can be chosen (order not important)\n",
    "- `n! / [(n-x)! * x!]` where n is total number of objects and x is number of objects chosen at one time\n",
    "- if we have 10 students in a class, how many combinations of 4 person team we could randomly choose?\n",
    "- 10! / [(10-4)! * 4!] = 10x9x8x7 / 4x3x2x1 = 5040 / 24 = 210 possible teams of four\n",
    "\n",
    "- what is the probability that 2 specific students (Tom and Kate) end up in the same team?\n",
    "- how many other students can fill the last free spots (2 first sports are already taken by our 2 students, 10 were in total, so we have 8 other students left)\n",
    "- 8! / [(8-2)! * 2!] = 28\n",
    "\n",
    "- so, we have 210 outcomes and 28 desired outcomes\n",
    "- the probability that 2 specific students end up in the same team is 28/210 = 14%\n",
    "\n",
    "Eight adults are carpooling to an event. At random 2 will be chosen as the drivers for the rest of the group. How many combinations of 2 drivers are there among this group of 8?\n",
    "- To solve you divide 8! by the product of 6!*2! This would be (8*7*6*5*4*3*2*1) / [(6*5*4*3*2*1)*(2*1)] This reduces to (8*7)/2 which equals 28.\n",
    "- 8! / [(8-2)! * 2!] = 28\n",
    "\n",
    "You have 10 employees chosen at random to be placed in a team of 4 people. You want Li and Raoul to be on the team. What will the formula 8!/[(8-2)! 2!] provide you?\n",
    "- The number of combinations for the eight employees other than Li and Raoul to be on the team.\n",
    "- When you calculate this, you will also know the probability of Li and Raoul being on the team.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Experiment and Random Variable\n",
    "`Random experiments` are opportunities to observe the outcome of a chance event. If we were rolling dice, the `random experiment` is observing and recording the outcome, which brings us to a random variable. A `random variable` is the numerical outcome of a random experiment. If we rolled a two and a three, our `random variable` would be five. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Variables\n",
    "As the result of the outcome is unknown (random), we call the result from an experiment a random variable\n",
    "- Discrete experimental results often characterised by whole numbers (no decimals are allowed (always whole numbers) and there is a limited number of possible outcomes)\n",
    "- Continuous - there is infinite number of possible outcomes (there are endless of possibilities in terms of outcomes)\n",
    "\n",
    "The distinction between the two is important because you will calculate probabilities differently in each type of situation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discrete Probability Distribution\n",
    "\n",
    "Probability distribution of drinks orders during a party:\n",
    "\n",
    "<img src=\"images/probability_distribution_discrete.png\" alt=\"\" style=\"width: 400px;\"/>\n",
    "\n",
    "<img src=\"images/probability_distribution_discrete2.png\" alt=\"\" style=\"width: 400px;\"/>\n",
    "\n",
    "Relative frequency:\n",
    "\n",
    "<img src=\"images/probability_distribution_discrete_relative_frequency.png\" alt=\"\" style=\"width: 500px;\"/>\n",
    "\n",
    "Mean of discrete probability distribution:\n",
    "\n",
    "<img src=\"images/probability_distribution_discrete_relative_frequency_mean.png\" alt=\"\" style=\"width: 600px;\"/>\n",
    "\n",
    "An average consumer ordered 1.46 drinks during the party.\n",
    "\n",
    "Standard deviation of discrete probability distribution:\n",
    "\n",
    "<img src=\"images/probability_distribution_discrete_relative_frequency_std.png\" alt=\"\" style=\"width: 650px;\"/>\n",
    "\n",
    "3.02 (sum of squared weights) - 2.13 (mean squared) = 0.89 (variance) -> 0.94 (variance squared root -> standard deviation / sigma)\n",
    "\n",
    "#### Expected Value\n",
    "Total of the weighted payoffs associated with the decision. `Expected monetary value (EMV)` is a variation of the mean for a discrete probability distribution that includes subtracting the cost of the investment.\n",
    "```\n",
    "You hold a lottery ticket. There is a 10% chance you win $500, a 40% chance you win $25, and a 50% you win $0. What is the expected monetary value of your lottery ticket?\n",
    "Answer: For each outcome multiply the possible winnings times the percentage, then add up all three products. (0.1*500)+(0.4*25)+(0.5*0) = $60\n",
    "```\n",
    "\n",
    "#### Binomial random variable\n",
    "An experiment that has only two possible outcomes. With binomial random variables, you can use n, the number trial, and the chance of success represented as p to predict a result.\n",
    "\n",
    "Binomial vs. Normal distribution\n",
    "\n",
    "<img src=\"images/CompareBinomialAndNormalDistribution.png\" alt=\"\" style=\"width: 400px;\"/>\n",
    "\n",
    "### Example 1\n",
    "```\n",
    "10 customers ordered pizza. Five ordered 1 pizza, two ordered 2 pizzas, two ordered 3 pizzas, and one ordered 4 pizzas. What's the mean number of pizzas ordered for this discrete distribution?\n",
    "\n",
    "    pizzas ordered    frequences    relative freq.    weights\n",
    "        1                5                5/10=0.5        1*0.5=0.5\n",
    "        2                2                2/10=0.2        2*0.2=0.4\n",
    "        3                2                    0.2         3*0.2=0.6\n",
    "        4                1                    0.1         4x0.1=0.4\n",
    "        \n",
    "                                                        Mean (sum of weights) = 1.9\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continuous Probability Distribution\n",
    "\n",
    "<img src=\"images/probability_distribution_continuous.png\" alt=\"\" style=\"width: 400px;\"/>\n",
    "\n",
    "Probability density curves can be used to show the distribution of outcomes. The area under the curve represents the probability of outcomes. The probability of A is X, and the probability of B is Y. In reality, the probability in a single point is equal to 0, so we usually check the probability over a ranges of random variables. The all area under the curve is equal to 1 (or 100%).\n",
    "\n",
    "<img src=\"images/probability_distribution_continuous_density_distribution_curve.png\" alt=\"\" style=\"width: 400px;\"/>\n",
    "\n",
    "<img src=\"images/probability_distribution_continuous_density_distribution_curve2.png\" alt=\"\" style=\"width: 400px;\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normal distribution & Central Limit Theorem\n",
    "\n",
    "The `\"fuzzy\" central limit theorem` says that data which are influenced by many small and unrelated random effects are approximately normally distributed.\n",
    "\n",
    "<img src=\"images/probability_distribution_continuous_normal.png\" alt=\"\" style=\"width: 800px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Z-transformations\n",
    "\n",
    "### Example 1\n",
    "What percentage of men weight more than 211 pounds? The weight is normally distributed with mean of 150 pounds and std of 25.\n",
    "\n",
    "First, calculate the `z-score`\n",
    "\n",
    "<img src=\"images/z-score-example.png\" alt=\"\" style=\"width: 600px;\"/>\n",
    "\n",
    "It would appear here far to the right\n",
    "\n",
    "<img src=\"images/z-score-example1b.png\" alt=\"\" style=\"width: 600px;\"/>\n",
    "\n",
    "Then, find the percentage of men who would weight more than 211 pounds by using `standard normal distribution / z-score table` and find the probability value for z-score of 2.44\n",
    "\n",
    "<img src=\"images/z-score-example1c.png\" alt=\"\" style=\"width: 600px;\"/>\n",
    "\n",
    "According to our mean and std 99.27% of all men weight 211 pounds or less, which means that the percentage of men that weight more than 211 pounds is 1-0.9927 = 0,0073 or 0,73%.\n",
    "\n",
    "### Example 2\n",
    "What is the probability a man weight between 140 and 170 pounds?\n",
    "\n",
    "First, we need two z-scores: one for 140, another for 170. Next, check the standard normal distribution table (chart value) values for the scores. \n",
    "\n",
    "<img src=\"images/z-score-example2b.png\" alt=\"\" style=\"width: 600px;\"/>\n",
    "\n",
    "How to find a value for a negative z-score? Because the bell curve is symetrical, we can substract number found for the positive z-score from 1.0.\n",
    "\n",
    "<img src=\"images/z-score-example2d.png\" alt=\"\" style=\"width: 400px;\"/>\n",
    "\n",
    "<img src=\"images/z-score-example2e.png\" alt=\"\" style=\"width: 400px;\"/>\n",
    "\n",
    "So, the result is:\n",
    "\n",
    "<img src=\"images/z-score-example2f.png\" alt=\"\" style=\"width: 400px;\"/>\n",
    "\n",
    "\n",
    "### Example 3\n",
    "Comparing distributions\n",
    "\n",
    "<img src=\"images/example_ztransform.png\" alt=\"\" style=\"width: 600px;\"/>\n",
    "\n",
    "See: http://www.statistics4u.info/fundstat_eng/ee_ztransform.html\n",
    "\n",
    "### Example 4\n",
    "```\n",
    "A student scores 1510 on a standardized test, for a z-score of 2.17. The z-score table shows that the z-score for 2.17 is 0.9850. Therefore, the probability someone scored >1510 on this test is 0.015 or 1.5%.\n",
    "Answer: 0.9850 indicates that this student was equal to or greater than 98.50% of other student scores. Thus 1.5% are likely to score higher.\n",
    "```\n",
    "\n",
    "### Example 5\n",
    "```\n",
    "The average height for men is 5'9\". Michael's height is 6'7\". If the data is normally distributed and you calculated the Z-score, how can you find the percentage of men who are 6'7\" or taller?\n",
    "Answer: The Standard Distribution Table gives you the percentage of men shorter than 6'7\", thus giving you the probability of being taller. The table associates Z-scores to percentages at or below the Z-score, which leaves the percentage of men taller than the mean.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistics 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inferential Statistics\n",
    "Based on samples of data infer about whole population."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling\n",
    "The challenge is getting the right answers, especially when the world, even your small slice of it is very big. \n",
    "\n",
    "Measuring everything is just way \n",
    "- too expensive, \n",
    "- too time consuming and \n",
    "- in some cases, it's just impossible. \n",
    "\n",
    "Political operatives can't poll every voter. Cell phone companies can't measure the quality level of every single item the produce. A farmer can't measure the actual size of every tomato grown. Scientists, they can't track the health of every single person in the country. Instead of measuring everything, they just measure a small group or subset of the total population. That small subset of measurements is a `sample`. And under the right circumstances, this `sample can act as a representative of the entire population`. The best samples are chosen at random.\n",
    "\n",
    "### Random Sample\n",
    "The most dependable type of data comes from what we call a `simple random sample`. This means that \n",
    "- the sample is chosen such that each individual in the population has the same probability of being chosen at any stage during the sampling process. \n",
    "- And each subset of k individuals has the same probability of be chosen for the sample as any other subset of k individuals.\n",
    "\n",
    "The simple random sample can be rather elusive. Eliminating bias and maintaining data independence is quite challenging. As a result, `alternatives to the simple random sample` are sometimes utilized (but the simple random sample is still the only way to get dependable statistical outcomes). These alternative methods are simpler to organize, easier to carry out, and often, they seem both logical and sound:\n",
    "- **Systematic sample** - Choose one unit and then every k unit thereafter. So if we're measuring customer satisfaction at a store, perhaps you might ask the first person to come out of the store for their opinions, then you might ask every tenth customer after them, for their opinion.\n",
    "- **Sources of bias** - The sampling time and sampling location as well as the presence of a sampler, may introduce bias or inhibit independence.\n",
    "- **Opportunity sample** - the sampler simply takes the first n number of units that come along.\n",
    "- **Stratified sample** - Is one where the total population is broken up into homogeneous groups. Let's say, we're trying to figure out the average amount of sugar in a single cookie, regardless of the type of cookie. We could break up the population into so many different cookie types. Chocolate chip, peanut butter, oatmeal, sugar, ginger, snickerdoodle, oatmeal raisin. From there, we might take a sample of 30 cookies from each category. Perhaps chocolate chip cookies make up 50% of all cookies and ginger cookies make up only 3% of all the cookies. Our very fair-looking system might actually be biased against the most popular cookies.\n",
    "- **Cluster sample** - is similar to stratified samples in that we are breaking things up into groups. What's the difference? In stratified groups, all the members of each group were the same. In clusters, the groups are likely to have a mix of characteristics. They're heterogeneous. Suppose we are testing a new product. We might ask for samples of people in 20 major cities, what they think about the new product. While the people in a single sample might all be from the same city, each sample might contain men and women, people of different races, politics and socio-economic backgrounds.\n",
    "\n",
    "The `simple random sample` will always be the gold standard, but these `alternative sampling methods` should not be completely dismissed.\n",
    "\n",
    "### Sample Size\n",
    "A `sample` is a group of units drawn from a population, and the `sample size` is the number of units drawn and measured for that particular sample. The total population itself may be very large or, perhaps, immeasurable, so a `sample` is just looking at a slice of the population in the hopes of providing us a representative picture of the entire population. The larger the sample size, the more accurate our measurement or, at least, the more confidence we have that our sample is actually providing us a glimpse of the whole population. \n",
    "\n",
    "<img src=\"images/sample_size.png\" alt=\"\" style=\"width: 600px;\"/>\n",
    "\n",
    "And this is where sample size becomes important. Why? Well, let's take a look at the formula for standard deviation, where `n` is our sample size. `P` and the quantity `one minus p`, they won't change, but sample size will. So, `the bigger the sample size, the smaller our standard deviation`. \n",
    "\n",
    "<img src=\"images/sample_size4.png\" alt=\"\" style=\"width: 600px;\"/>\n",
    "\n",
    "For this sample, if n is equal to five, then one standard deviation would be 13.4% from 90% in either direction, which means that, with a sample size of five, we would expect 68% of all of our samples to have between 76.6% and 100% good forks, since we can't have more than 100% good forks in any sample. \n",
    "\n",
    "<img src=\"images/sample_size2.png\" alt=\"\" style=\"width: 600px;\"/>\n",
    "\n",
    "If n equals 25, one standard deviation would be 6%. At n equals 100, one standard deviation would be 3%. And at n equals 400, one standard deviation would be 1.5%, which means that, with a sample size of 400, we would expect at least 68% of all of our samples to have between 88.5% and 91.5% good forks. As you can see, a larger sample size can really make us feel so much more comfortable with our results. It gives us more confidence when we apply the sample results to our larger population.\n",
    "\n",
    "<img src=\"images/sample_size3.png\" alt=\"\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The central limit theorem\n",
    "The central limit theorem. Let's start simple. A distribution of discrete numbers. We start on the left, where we have five values of five. We move right along our distribution. Two units of 10. Four units of 15. Six units of 20. And on the right of our distribution, we have three values of 25. 20 different readings in our entire population. If we average out the values of our 20 different readings, we get an average of 15.0. \n",
    "\n",
    "<img src=\"images/central_limit_theorem.png\" alt=\"\" style=\"width: 600px;\"/>\n",
    "\n",
    "Now suppose we didn't want to tally up all 20 values, but we still wanted to find the average of the data set. Could we use samples to direct us to the population mean? Let's try it. Let's take samples of four units every day. Here's our first sample. Sample one, 10, 15, 20, 25. Our sample mean for this sample is 17.5. Sample two, five, 15, 20, and 20. Our sample mean for this sample is 15. Sample three, five, five, 15, and 20. Our sample mean here is 11.25. We have three samples, thus we have three sample means, 17.5, 15, and 11.25. If we average those, we get the mean of our means, 14.58. Not too far off from our actual population mean of 15.0. \n",
    "\n",
    "<img src=\"images/central_limit_theorem2.png\" alt=\"\" style=\"width: 600px;\"/>\n",
    "\n",
    "`The central limit theorem tells us the more samples we take, the closer the means of our sample means will get to the population mean`. Actually, it's even more interesting, because as we start to take many more samples, dozens of samples, hundreds of samples, even thousands of samples, the sample means, if plotted as a histogram, our sampling distribution of our sample means would start to look like a normal distribution. \n",
    "\n",
    "<img src=\"images/central_limit_theorem3.png\" alt=\"\" style=\"width: 600px;\"/>\n",
    "\n",
    "`Not only does the central limit theorem work with our example with a tiny population and discrete values, it works with massive populations and continuous values`. So no matter if you're interested in learning about the average test scores of a small school, the average weight of watermelons grown in North America, or the political preferences of voters in the United States, the central limit theorem is there to provide you the guidance to understand the overall population with the assistance of some simple random samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard Error (for proportions)\n",
    "We've already begun to see the impact of sample size. In general, `the larger the sample size, the more confidence we have in our results`. Now let's shift our attention to the standard error. In short, `the standard error` is the standard deviation of our proportion distribution. \n",
    "\n",
    "Through an example, let's take a look at how we calculate the standard error and also what that calculated number would mean to us. In the cell phone industry, companies struggle to keep their clients happy. Suppose a reputable, national poll finds that 60% of adults are satisfied with their cell phone provider. Let's take that as our population proportion `p`=0.60. We'd like to see if cell phone service in our city reflects what is being seen nationally. In an attempt to measure this, we'll take simple random samples of 100 cell phone users in our city. Now, we know that 100 people can't possibly reflect the satisfaction levels of everyone in our city, therefor we can assume that each sample will carry with it some level of `standard error`. \n",
    "\n",
    "So, how big is this standard error? Well the answer to that question really depends on you guessed it: sample size. `The standard error is ultimately related to the standard deviation`, our formula for standard deviation is seen here, `p` is the proportion population, in this case 0.60 and `n` is sample size. In this case, 100.\n",
    "\n",
    "<img src=\"images/standard_error_proportions.png\" alt=\"\" style=\"width: 600px;\"/>\n",
    "\n",
    "So we can see that for n=100, our standard deviation is approximately 0.05 or 5%. And remember, if we assume a normal distribution, 68% of all the samples taken should fall within one standard deviation of the population proportion. So in this situation, for simple random samples with 100 ratings, we would expect 68% of the samples to provide `sample proportions` or `p-hats` between 55% and 65%. 55% is our lower limit. 65% is our upper limit and 60% our population proportion that would be at the center. \n",
    "\n",
    "<img src=\"images/standard_error_proportions2.png\" alt=\"\" style=\"width: 600px;\"/>\n",
    "\n",
    "So if tomorrow we gathered a simple random sample of 100 cell phone customers and 57% of those customers were satisfied, we can say that our city was likely on par with the national proportion of 60% because we were within the 5% standard error. \n",
    "\n",
    "Then again, if we could afford to take simple random samples with sample sizes of 1000 cell phone customers. Notice what happens here, since n is now 1000. Our standard deviation drops to about 0.015 or 1.5%. So if n=1000, we would expect 68% of those larger samples to have p-hats between 58.5% and 61.5%. \n",
    "\n",
    "<img src=\"images/standard_error_proportions3.png\" alt=\"\" style=\"width: 600px;\"/>\n",
    "\n",
    "So let's recap, `the standard error in situations where we are looking at proportions is the standard deviation`. This is the formula for the standard deviation of a sample proportion, `p-hat`. The bigger our sample size, the smaller our standard deviation. This standard deviation is our standard error. `The standard error allows us to set up a range around the population proportion that extends the equivalent of one standard deviation in both the positive and negative direction`. The formula for our upper limit is p plus the standard deviation and for the lower the limit, p minus our standard deviation. Once the range is established, if we assume the probability distribution is nearly normal, then we would expect that 68% of the simple random samples gathered in the upcoming weeks, that they would fall within one standard deviation or the standard error. \n",
    "\n",
    "What happens when 68% of our samples are not falling within our calculated upper and lower limits? \n",
    "- Perhaps, it signals that something in our city is different form the overall nation. Customers, companies, or a combination of the two might create a unique environment in our city. \n",
    "- Perhaps there is a flaw in the reported national average of 60%, maybe their data gathering techniques were flawed. \n",
    "- Perhaps, the market has changed since that number was first reported or perhaps our sampling method was biased. \n",
    "\n",
    "Don't forget, while standard errors are there to help us judge and analyze future samples, samples that fall beyond the standard error, they should be analyzed not necessarily judged as failures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling distribution of the mean\n",
    "Suppose we know that the average player in a men's college basketball league weighs 180 pounds. Let's also say that the median player weighs about 190 pounds, so that means quite a few of the smaller players in the league are bringing down that average. This league has over 4,000 players. \n",
    "\n",
    "Would we have to weigh everyone of those 4,000 plus players to know the average weight of a player in the league? \n",
    "\n",
    "Well, if you remember, `the Central Limit Theorem tells us that by taking some simple random samples, we can get a very good approximation of the true population average`. \n",
    "\n",
    "If we take five random samples, with a sample size of only four, we might find that those five tiny samples will have sample means that average to perhaps 182 pounds. Now, if we take five random samples, but increase the sample size to 25, we would likely see the mean of the sample means closer to 180.5 pounds. \n",
    "\n",
    "<img src=\"images/sampling_distribution_of_the_mean.png\" alt=\"\" style=\"width: 600px;\"/>\n",
    "\n",
    "Only five simple random samples with sample sizes as low as four can get us very close to our true population mean of 180 pounds. Now, this basketball league has the capability of tracking all 4,000 plus players, so we knew that the average weight of the players in this league was actually 180 pounds, but hopefully the example has helped convince you that even when we have a massive population, the Central Limit Theorem tells us we can trust our simple random samples to point us in the direction of the true population mean. \n",
    "\n",
    "Let's say instead of 4,000 well-tracked male college basketball players, we wanted to know the average weight of 18 to 24 year old men in United States colleges. There are millions of young males in college, and these men are not tracked nearly as well as the basketball players, but that shouldn't be a concern. The Central Limit Theorem tells us that if we are diligent in collecting simple random samples, we should trust our sample means in this scenario, with a population of over three million students, to be as accurate as the example of five samples collected from the pool of 4,000 college basketball players. And it works the other way too. If you have a school of only 50 students, a very small population, you can approximate the population mean for those 50 students by simply taking a few simple random samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard Error (for means)\n",
    "Through the use of the central limit theorem, we've seen how taking just a few random samples can guide us in the direction of the population mean. Of course when we use only a few samples to try and figure out a population mean, we understand that `the average of our sample means comes with a standard error`. \n",
    "\n",
    "So how do we figure out the standard error for our simple random samples? Let's say we're trying to figure out how long it takes to get our coffee drinks from our local cafe between 7 a.m. and 8 a.m. on a Monday morning. We take samples on four different Mondays. Our sample size for each of these samples is five. Here is our data set for those days, times are in minutes. \n",
    "\n",
    "<img src=\"images/standard_error_means.png\" alt=\"\" style=\"width: 600px;\"/>\n",
    "\n",
    "So, for sample A you can see that the time it took our five customers to get coffee ranged from 0.6 minutes to 2.4 minutes. The average for sample A was 1.58 minutes. If we take the average of the sample means, we will find that the average time to get a coffee drink was about 1.52 minutes. And the standard deviation of those four sample means is 0.25 minutes. \n",
    "\n",
    "`The standard deviation of our sample means this is our estimated standard error`. What's interesting is that `there's a relationship between the standard error of our population means and the standard deviation of the population`. Take a look at this formula, Sigma Xbar is equal to Sigma over the square root of our sample size n. Sigma Xbar is our standard error. So it is the standard deviation of our four sample means. On the other side of the equation, we have another Signma, this Sigma is the standard deviation for the entire population.\n",
    "\n",
    "<img src=\"images/standard_error_means2.png\" alt=\"\" style=\"width: 600px;\"/>\n",
    "\n",
    "So by plugging in our calculated standard error from our cafe example which was 0.25 minutes, and then plugging in 5 for n, our sample size. We can then solve for Sigma, our populations standard deviation. We can see that based on these four samples with a sample size of five, we can estimate the population's standard deviation is 0.56 minutes. Again, we can see how sample size can have a huge impact on working with samples to find out information about the entire population. In essence, what the formula tells us is that `if we use larger sample sizes, our standard error gets smaller`. This is also important as we collect samples in the future, why, well, when we collect a sample of drink service times from our cafe tomorrow and the rest of the week, we will know that 68% of our samples should have sample means that fall within 0.25 minutes of 1.52 minutes, our average. Upper limit would then be 1.77 minutes and our lower limit, 1.23 minutes. The standard error formula is very simple, but still very informative, by understanding the simple relationship between sample size, the standard deviation of our population and the stand deviation of our sample means, we can better understand our population as well as the samples we take going forward."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1\n",
    "80% of customers pay with a debit or credit card. 25 customers are chosen at random each day. 68% of the samples would have p-hats between:\n",
    "```\n",
    "Sigma p-hat = sqrt((0.80*0.20)/25) = sqrt(0.0064). Next take the square root of 0.0064, this provides a standard dev. of 0.08 or 8% (standard error). The p-hats would be between both 80%-8% and 80%+8%.\n",
    "```\n",
    "### Example 2\n",
    "Three of the choices are true of the Central Limit Theorem. Which is not?\n",
    "- the larger the sample size, the taller and more narrow our distribution\n",
    "- the central limit theorem works for both small and large population sizes\n",
    "- the mean of our random sample means directs us to the population mean\n",
    "- (wrong) the greater the size of our samples, the greater the standard deviation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confidence Intervals\n",
    "At this point, you should hopefully feel comfortable with the concepts of sample size and the central limit theorem. `The central limit theorem tells us that if we take enough simple random samples, we can get an excellent approximation of our population means`. In other words, rather than measure everything in the population, we can take some random samples. Those random samples will provide us with the measurements that will be nearly normal in our distribution, and will direct us to the population mean. \n",
    "\n",
    "And you also, hopefully, remember that `the larger the sample size of those random samples, the smaller the standard deviation of our distributions`, so the more certain we are about our resulting population mean. Lots of samples make us feel confident about our population numbers.\n",
    "\n",
    "In this section, in which we will cover `confidence intervals`, we're going to go in the opposite direction. `What happens when we have only one sample?` If we have only one sample, how confident are we that this single sample mean is near our actual population mean? \n",
    "\n",
    "In this section, you'll often see results that look like this. We are 95% confident that the average adult in the United States drinks between two and three liters of beverages per day. As you can see, one random sample will allow us to calculate our range and attach to it a level of confidence. Think about how incredibly powerful this is, the efficient use of resources, the overall savings, and the ability to be 95% confident, or perhaps even more confident than that. \n",
    "\n",
    "But before we move on, let's take a moment to discuss what a 95% confidence level means. It means that if, instead of taking a poll only once, we took a similar poll 20 times. 19 times, the results of the poll, in other words, the resulting ranges of those 19 polls, they would capture the population mean. But of course, one of the 20 times, the reported range would not include our population mean. Remember that the next time a pre-election poll predicts the wrong candidate to win. So, let's get started with that exact example. Let's see how they create confidence intervals for those pre-election polls.\n",
    "\n",
    "### What exactly is a confidence interval?\n",
    "Let's create a 95% confidence interval for an election poll where the voters have two choices: Candidate A and Candidate B. As you may have guessed, we'll be working with proportions. Before we start creating a 95% confidence interval for this scenario, let's recap a few things. \n",
    "\n",
    "- First, if we took a lot of voter samples, the distribution would be approximately normal. \n",
    "- Second, the larger the voter sample size, the smaller the variation, and thus, the smaller the standard deviation of the resulting distribution. \n",
    "- Third, a 95% interval is one where we are 95% certain that our interval which will be centered at the sample's proportion will contain the actual population proportion. \n",
    "\n",
    "Now what we're going to do is take a single sample. This single random sample might include 50 eligible voters, but the resulting sample proportion of eligible voters that favor Candidate A is a single number we can call `p-hat`. This single sample proportion is a single dot on this distribution. \n",
    "\n",
    "<img src=\"images/confidence_intervals.png\" alt=\"\" style=\"width: 600px;\"/>\n",
    "\n",
    "Now the question is, is it a dot that is close to the population's true proportion or is it a dot that is very far away from the true proportion. I also want you to remember we don't actually know the true population proportion. So while our single sample is here, we don't know if the true population proportion is here or here or here. So, what are we actually doing? Well, let's imagine that this is the true population proportion distribution. We're going to take a sample and build an interval around that sample. And we're going to hope that the true population proportion falls within that interval. Now, what we really want to create is an interval, an interval of a certain length we will call `y`. This interval will have a lower limit and an upper limit. And this interval will be centered on our sample proportion, `p-hat`. This interval would need to be big enough where if we took 20 samples, 19 of the 20 intervals would contain the true population proportion. In other words, 95% of my samples would have an interval within range of `p`. \n",
    "\n",
    "So let's recap. When we gather a sample with a certain sample proportion `p-hat` and when we create an interval around that p-hat, we are 95% certain that the real population proportion is somewhere between the lower and upper limit of that interval.\n",
    "\n",
    "### 95% confidence intervals for population proportions\n",
    "So there's an upcoming election for mayor of a large city between two candidates. Let's simply call the candidates Candidate A and Candidate B. You work for Candidate A. Candidate A's campaign team wants to know where Candidate A stands so they ask you to conduct a poll. You gather a random sample of 100 voters and ask if they will be voting for Candidate A or Candidate B. 55% of the 100 voters polled said they planned on voting for Candidate A. Anything over 50% in the real election would result in a win for your candidate. So far, based on the results of the poll, things look promising for your candidate but remember, this was just one sample with a sample size of 100. \n",
    "\n",
    "<img src=\"images/confidence_intervals2.png\" alt=\"\" style=\"width: 600px;\"/>\n",
    "\n",
    "Now, look, I understand that my small pre-election poll likely didn't provide the actual percentage of votes Candidate A will get on the actual day of the election but maybe we're close. So let's create a 95% confidence interval. In other words, let's use our sample result to create an interval that very likely includes the actual percentage of votes Candidate A will get on election day. \n",
    "\n",
    "Let's take a look at a normal distribution curve. If we want a 95% confidence level, that would mean we'd want to capture 95% of the area under the curve between two points equidistant from the sample proportion which means 2.5% of the area under the curve on the right side of the curve would not be included and 2.5% of the area under the curve on the left side of the curve would not be included. So how do we find these two points which establish our interval? We'll have to take a look at `z-scores`. \n",
    "\n",
    "<img src=\"images/confidence_intervals3.png\" alt=\"\" style=\"width: 600px;\"/>\n",
    "\n",
    "`Z-scores tell us how many standard deviations away from the mean we would need to be to capture a certain percentage of the total distribution`. So we pull up a z-score table. \n",
    "\n",
    "<img src=\"images/confidence_intervals4.png\" alt=\"\" style=\"width: 600px;\"/>\n",
    "\n",
    "We find 0.975. This means 97.5% of the data points are to the left of this point and thus, 2.5% of the data points would fall to the right of this point. As you can see, our z-score is 1.96. This means if we go 1.96 standard deviations in the positive direction and 1.96 standard deviations in the negative direction, 95% of the area under our distribution will fall between these two limits. \n",
    "\n",
    "<img src=\"images/confidence_intervals5.png\" alt=\"\" style=\"width: 600px;\"/>\n",
    "\n",
    "So let's see where we are so far. `Our sample proportion is 0.55`. `This will be the center of our interval`. Therefore, the upper limit will be 0.55 plus 1.96 times our standard deviation and our lower limit will be 0.55 minus 1.96 times our standard deviation. So of course now, we need to find our standard deviation. \n",
    "\n",
    "In the absence of the population proportion and the population's standard deviation, we can use the formula for the standard error. It's basically the formula for the standard deviation but we use the sample proportion as our p hat. Since we use the sample proportion, p hat, instead of the population proportion, p, we can't call it the standard error. When you use the sample proportion, it's called `the sampling error`. So we put p hat into our formula and of course, in our particular example, we polled 100 voters so n is equal to 100. As you can see, our standard deviation or sampling error in this case is 0.05. \n",
    "\n",
    "<img src=\"images/confidence_intervals6.png\" alt=\"\" style=\"width: 300px;\"/>\n",
    "\n",
    "So when we plug that standard deviation into our formula, we get an interval that has a lower limit of 0.452 and an upper limit of 0.648. \n",
    "\n",
    "\n",
    "\n",
    "Uh oh, our interval goes all the way down to 0.452 which means that our margin of error tells us that losing is still possible. Then again, a large proportion of our interval is over 50%. Still, your candidate is probably a bit nervous but how about if we took a bigger sample? How about if the campaign is willing to fund a poll of one thousand voters? The numbers on this poll are a bit lower for your candidate. This poll tells us 54% of the voters are for Candidate A. Let's calculate our sampling error with our new sample proportion and sample size of one thousand. Our sampling error is now 0.16. So let's calculate our interval limits. Look at that. Our new interval stretches from 0.509 to 0.571. If the election were to have a result identical to anything within our 95% confidence interval, Candidate A would win. Remember, according to this sample, there is now a 95% chance that on election day, Candidate A will receive between 50.9% and 57.1% of the vote. There's only a 5% chance that the election day results will fall outside of that interval. And don't forget, it's possible that those 5% might include results that are even better than 57.1% of the vote for Candidate A. No matter how you slice it, that should make Candidate A's team feel pretty good, right? Yeah, there's always that one person on the team that asks, can we get a 96% interval or what about 98%? So for those people, next, we'll create confidence intervals that are greater than 95%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
