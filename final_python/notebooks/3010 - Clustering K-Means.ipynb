{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "From: https://github.com/ksatola\n",
    "Version: 0.0.1\n",
    "\n",
    "TODOs\n",
    "1. \n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Means Clustering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How does it work?\n",
    "Let’s say we’d like to divide the following points into clusters.\n",
    "\n",
    "<img src=\"images/k-means1.png\" alt=\"\" style=\"width: 400px;\"/>\n",
    "\n",
    "First, we must choose how many clusters we’d like to have. The `K` in ‘K-means’ stands for the number of clusters we’re trying to identify. In fact, that’s where this method gets its name from. We can start by choosing two clusters.\n",
    "\n",
    "The second step is to specify the cluster seeds. A `seed` is basically a starting cluster `centroid`. It is chosen at random or is specified by the data scientist based on prior knowledge about the data.\n",
    "\n",
    "One of the clusters will be the green cluster, and the other one – the orange cluster. And these are the seeds.\n",
    "\n",
    "<img src=\"images/k-means2.png\" alt=\"\" style=\"width: 400px;\"/>\n",
    "\n",
    "The next step is to assign each point on the graph to a seed. Which is done based on `proximity`.\n",
    "\n",
    "For instance, this point is closer to the green seed than to the orange one. Therefore, it will belong to the green cluster.\n",
    "\n",
    "<img src=\"images/k-means3.png\" alt=\"\" style=\"width: 400px;\"/>\n",
    "\n",
    "This point, on the other hand, is closer to the orange seed, therefore, it will be a part of the orange cluster.\n",
    "\n",
    "<img src=\"images/k-means4.png\" alt=\"\" style=\"width: 400px;\"/>\n",
    "\n",
    "In this way, we can assign all points on the graph to a cluster, based on their Euclidean squared distance from the seeds.\n",
    "\n",
    "The final step is to calculate the centroid or the geometrical center of the green points and the orange points. The green seed will move closer to the green points to become their centroid and the orange will do the same for the orange points.\n",
    "\n",
    "<img src=\"images/k-means5.png\" alt=\"\" style=\"width: 400px;\"/>\n",
    "\n",
    "From here, we can repeat the last two steps. We can do that 10, 15 or 1000 times until we’ve reached a clustering solution where we can no longer adjust any of the clusters.\n",
    "\n",
    "<img src=\"images/k-means6.png\" alt=\"\" style=\"width: 400px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion\n",
    "\n",
    "One disadvantage arises from the fact that `in K-means we have to specify the number of clusters before starting`. In fact, this is an issue that a lot of the clustering algorithms share. In the case of K-means if we choose K too small, the cluster centroid will not lie inside the clusters. \n",
    "\n",
    "<img src=\"images/k-means7.png\" alt=\"\" style=\"width: 400px;\"/>\n",
    "\n",
    "In cases where K is too large, some of the clusters may be split into two.\n",
    "\n",
    "Another important issue is that `K-means enforces clusters with a spherical shape or blobs`. \n",
    "\n",
    "<img src=\"images/k-means8.png\" alt=\"\" style=\"width: 400px;\"/>\n",
    "\n",
    "The reason is that we are trying to minimize the distance from the centroids in a straight line. So, if we have clusters, which are more elongated, K-means will have difficulty separating them.\n",
    "\n",
    "<img src=\"images/k-means9.png\" alt=\"\" style=\"width: 400px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation\n",
    "See 3000 Clustering algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# read the train and test dataset\n",
    "train_data = pd.read_csv('train-data.csv')\n",
    "test_data = pd.read_csv('test-data.csv')\n",
    "\n",
    "# shape of the dataset\n",
    "print('Shape of training data :', train_data.shape)\n",
    "print('Shape of testing data :', test_data.shape)\n",
    "\n",
    "# Now, we need to divide the training data into differernt clusters\n",
    "# and predict in which cluster a particular data point belongs.  \n",
    "\n",
    "# create the object of the K-Means model\n",
    "model = KMeans(n_clusters=5)  \n",
    "\n",
    "# fit the model with the training data\n",
    "model.fit(train_data)\n",
    "\n",
    "# Number of Clusters\n",
    "print('\\nDefault number of Clusters : ', model.n_clusters)\n",
    "\n",
    "# predict the clusters on the train dataset\n",
    "#predict_train = model.predict(train_data)\n",
    "#print('\\nCLusters on train data', predict_train) \n",
    "\n",
    "# predict the target on the test dataset\n",
    "predict_test = model.predict(test_data)\n",
    "print('Clusters on test data', predict_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
