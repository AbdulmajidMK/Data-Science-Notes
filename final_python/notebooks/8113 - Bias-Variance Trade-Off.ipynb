{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "From: https://github.com/ksatola\n",
    "Version: 0.0.1\n",
    "\n",
    "TODOs\n",
    "1. \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bias-Variance Trade-Off\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "- [Bias and Variance](#intro)\n",
    "- [Bias-Variance Trade-Off](#trade)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='into'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "- **Bias**: is the simplifying assumptions made by a model to make the target function easier to learn.\n",
    "- **Variance**: is the amount that the estimate of the target function will change if different training data was used.\n",
    "\n",
    "There could be 4 for bias/variance in a model:\n",
    "\n",
    "<img src=\"images/bias_variance_01.png\" style=\"width: 500px;\"/>\n",
    "\n",
    "In a very accurate model the error of our model will be low, meaning a low bias and low variance as shown in the first figure. As `variance increases`, the spread of our data point increases which result in less accurate prediction. As `Bias increases` the error between our predicted value and the observed values increases. A high bias assumes a strong assumption or strong restrictions on the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='trade'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bias-Variance Trade-Off\n",
    "\n",
    "<img src=\"images/bias_variance_02.png\" style=\"width: 600px;\"/>\n",
    "\n",
    "- **Underfitting** model performs poorly on training data. This happens because the model is unable to capture the relationship between the input example and the target variable. \n",
    "    - **Fix:** To overcome underfitting or high `bias`, we can basically add new parameters to our model so that the model complexity increases, and thus reducing high bias.\n",
    "- **Overfitting** As we add more and more parameters to our model, its complexity increases, which results in increasing `variance` and decreasing bias.\n",
    "    - **Fix:** There are some to overcome overfitting:\n",
    "        - Reduce the model complexity\n",
    "        - Use regularisation\n",
    "        - Use cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
