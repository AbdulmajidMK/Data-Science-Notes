{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "From: https://github.com/ksatola\n",
    "Version: 0.0.1\n",
    "\n",
    "TODOs\n",
    "1. \n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Learning Systems\n",
    "Learning systems are rarely perfect. So, one of our key criteria is measuring how well they do. How correct are the predictions? Since nothing comes for free, we also care about the cost of making the predictions. What computational resources did we invest to get those predictions? We’ll look at evaluating both of these aspects of learning system performance.\n",
    "\n",
    "## Correctness\n",
    "Our key criteria for evaluating learning systems is that they give us correct predictive answers. If we didn’t particularly care about correct answers, we could simply flip a coin, spin a roulette wheel, or use a random-number generator on a computer to get our output predictions. We want our learning system—that we are investing time and effort in building and running—to do better than random guessing. So, \n",
    "- (1) we need to quantify how well the learner is doing and \n",
    "- (2) we want to compare that level of success—or sadly, failure—with other systems. Comparing with other systems can even include comparisons with random guessers.\n",
    "\n",
    "One last issue in assessing correctness: two wrongs don’t necessarily make a right. If we are predicting rainfall and, in one case, we underpredict by 2 inches while in another case we overpredict by 2 inches, these don’t always cancel out. We cannot say, “On average, we were perfect!” Well, in fact, that’s strictly true and it might be good enough in some instances. Usually, however, we do care, and very deeply in other cases, that we were wrong in both predictions.\n",
    "\n",
    "## Resource Consumption\n",
    "There are two primary resources that we will measure: `time` and `memory` (or `storage space`). How long does a computation take? What is the maximum memory it needs? It is often the case that these can be traded off one for the other. Different learning systems make different tradeoffs between what they `remember` about the data and how long they spend `processing` the data.\n",
    "\n",
    "`At each level of increased complexity of a computational system, we pay for the privilege of using that more complex system.` We need more software support. We need more specialized human capital. We need more complicated off-the-shelf libraries. We lose the ability to rapidly prototype ideas. For each of these costs, we need to justify the expense.\n",
    "\n",
    "Further, for many systems, there are small portions of code that are a performance bottleneck. It is often possible to maintain the simplicity of the overall system and only have a small kernel that draws on more sophisticated machinery to go fast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
