{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "From: https://github.com/ksatola\n",
    "Version: 0.0.1\n",
    "\n",
    "TODOs\n",
    "1. 3.1.1.2. in https://scikit-learn.org/stable/modules/cross_validation.html\n",
    "2. https://scikit-learn.org/stable/modules/grid_search.html#grid-search\n",
    "3. https://github.com/STAC-IITMandi/Exoplanet-Detection/blob/master/live-953-2037-jair.pdf\n",
    "4. https://github.com/vaasha/Machine-leaning-in-examples/blob/master/sklearn/cross-validation/Cross%20Validation.ipynb\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-Validation (CV)\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "- [Cross Validation Techniques](#tech)\n",
    "- [Cross-validation on Imbalanced Data](#imb)\n",
    "- [XXX](#report)\n",
    "\n",
    "## Introduction\n",
    "\n",
    "**[Cross validation (CV)](https://en.wikipedia.org/wiki/Cross-validation_(statistics))**, sometimes called `rotation estimation` or `out-of-sample testing` is an essential tool in statistical learning to estimate the performance of your algorithm (how the results of a statistical analysis will generalize to an independent dataset). Despite its great power it also exposes some fundamental risk when done wrong which may terribly bias your performance estimate.\n",
    "\n",
    "During cross-validation, we are typically trying to understand how well our model can generalize, and how well it can predict our outcome of interest on unseen samples.\n",
    "\n",
    "**Cross validation** involves splitting the training dataset of observations into k non overlapping groups (or folds) of approximately equal size. One fold is treated as a validation set, and the machine learning algorithm is trained on the remaining k-1 folds. The mean squared error - MSE -  (or another metric) is then computed on the validation fold. This procedure is repeated k times; each time, a different group of observations is treated as a validation set.\n",
    "\n",
    "<img src=\"images/cross_validation_kfold.png\" alt=\"\" style=\"width: 600px;\"/>\n",
    "\n",
    "This process results in k estimates of the MSE quantity, namely MSE1, MSE2, ...MSEk. The cross validation estimate for the MSE is then computed by simply averaging these values:\n",
    "\n",
    "<img src=\"images/cross_validation_mse.png\" alt=\"\" style=\"width: 400px;\"/> \n",
    "\n",
    "This value is an estimate, say MSE_hat, of the real MSE and our goal is to make this estimate as accurate as possible. MSE is just one for the possible metrics you can estimate using cross validation. **The evaluation metrics should always report on generalization performance.** For more, see [sklearn implementation of CV](https://scikit-learn.org/stable/modules/cross_validation.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Connect with underlying Python code\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.insert(0, '../src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import (\n",
    "    get_dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, ShuffleSplit, RepeatedKFold\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='tech'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation Techniques\n",
    "see TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-fold\n",
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repeated K-Fold\n",
    "[RepeatedKFold](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RepeatedKFold.html#sklearn.model_selection.RepeatedKFold) repeats K-Fold n times. It can be used when one requires to run KFold n times, producing different splits in each repetition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 3] [0 1]\n",
      "[0 1] [2 3]\n",
      "[0 2] [1 3]\n",
      "[1 3] [0 2]\n"
     ]
    }
   ],
   "source": [
    "X = np.array([[1, 2], [3, 4], [1, 2], [3, 4]])\n",
    "random_state = 12883823\n",
    "cv = RepeatedKFold(n_splits=2, n_repeats=2, random_state=random_state)\n",
    "for train, test in cv.split(X):\n",
    "    print(\"%s %s\" % (train, test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leave One Out (LOO)\n",
    "[LeaveOneOut (or LOO)](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.LeaveOneOut.html#sklearn.model_selection.LeaveOneOut) is a simple cross-validation. Each learning set is created by taking all the samples except one, the test set being the sample left out. Thus, for  samples, we have  different training sets and  different tests set. This cross-validation procedure does not waste much data as only one sample is removed from the training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3] [0]\n",
      "[0 2 3] [1]\n",
      "[0 1 3] [2]\n",
      "[0 1 2] [3]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import LeaveOneOut\n",
    "\n",
    "X = [1, 2, 3, 4]\n",
    "loo = LeaveOneOut()\n",
    "for train, test in loo.split(X):\n",
    "    print(\"%s %s\" % (train, test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leave P Out (LPO)\n",
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random permutations cross-validation a.k.a. Shuffle & Split\n",
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stratified k-fold\n",
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='imb'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validation on Imbalanced Data\n",
    "\n",
    "Letâ€™s now have a look at one of the most typical mistakes when using cross validation. When cross validation is done wrong its result does not reflect reality. In other words, you may think that you just found a perfect machine learning algorithm with incredibly good performance metric, while in reality you simply wrongly applied CV by introduction `knowledge leaking` or `data leaking`.\n",
    "\n",
    "There is a major issue in most clinical research, i.e. how to properly cross-validate when we have imbalanced data. As a matter of fact, in the context of many medical applications, we have datasets where we have two classes for the main outcome; normal samples and relevant samples. For example in a cancer detection application we might have a small percentages of patients with cancer (relevant samples) while the majority of samples might be healthy individuals. Outside of the medical space, this is true (even more) for the case for example of fraud detection, where the rate of relevant samples (i.e. frauds) to normal samples might be even in the order of 1 to 100 000.\n",
    "\n",
    "Typically, classifiers are more sensitive to detecting the majority class and less sensitive to the minority class. Thus, if we don't take care of the issue, the classification output will be biased, in many cases resulting in always predicting the majority class. \n",
    "\n",
    "**What can we do when we have imbalanced data?** Mainly three things:\n",
    "- **Ignore the problem.** Building a classifier using the data as it is, would in most cases give us a prediction model that always returns the majority class. The classifier would be biased.\n",
    "- **Undersample the majority class.** Simply select n samples at random from the majority class, where n is the number of samples for the minority class, and use them during training phase, after excluding the sample to use for validation.\n",
    "- **Oversample the minority class.** The easiest way to oversample is to re-sample the minority class, i.e. to duplicate the entries, or manufacture data which is similar to the data what we have already."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oversampling the Minority Class\n",
    "\n",
    "**Oversampling the minority class can result in overfitting problems if we oversample before cross-validating.** What is wrong with oversampling before cross-validating? Letâ€™s consider the simplest oversampling method ever, as an example that clearly explains this point.\n",
    "\n",
    "The easiest way to oversample is to re-sample the minority class, i.e. to duplicate the entries, or manufacture data which is exactly the same as what we have already. Now, if we do so before cross-validating, i.e. before we enter the leave one participant out cross-validation loop, we will be training the classifier using n-1 entries, leaving 1 out, but including in the n-1 one or more instances that are exactly the same as the one being validated. Thus, defeating the purpose of cross-validation altogether. Let's have a look at this issue graphically:\n",
    "\n",
    "<img src=\"images/cross-validation1.jpg\" alt=\"\" style=\"width: 400px;\"/>\n",
    "\n",
    "From left to right, we start with the original dataset where we have a minority class with two samples. We duplicate those samples, and then we do cross-validation. At this point there will be iterations, such as the one showed, where the training and validation set contain the same sample, resulting in overfitting and misleading results. Here is how this should be done:\n",
    "\n",
    "<img src=\"images/cross-validation2.jpg\" alt=\"\" style=\"width: 400px;\"/>\n",
    "\n",
    "First, we start cross-validating. This means that at each iteration we first exclude the sample to use as validation set, and then oversample the remaining of the minority class (in orange). In this toy example we had only two samples, so we created three instances of the same. `The difference from before, is that clearly now we are not using the same data for training and validation.` Therefore we will obtain more representative results. The same holds even if we use other cross-validation and oversampling methods, such as k-fold cross-validation or SMOTE.\n",
    "\n",
    "This was a simple example, and better methods can be used to oversample. One of the most common being the `SMOTE` technique, i.e. a method that instead of simply duplicating entries creates entries that are interpolations of the minority class, as well as undersamples the majority class. Normally when we duplicate data points the classifiers get very convinced about a specific data point with small boundaries around it, as the only point where the minority class is valid, instead of generalizing from it. However, `SMOTE` effectively forces the decision region of the minority class to become more general, partially solving the generalization problem. There are some pretty neat visualizations in the original paper, so I would advice to have a look [here](https://github.com/STAC-IITMandi/Exoplanet-Detection/blob/master/live-953-2037-jair.pdf). \n",
    "\n",
    "However, something to keep in mind is that while oversampling using SMOTE does improve the decision boundaries, it has nothing to do with cross-validation. If we use the same data for training and validation, results will be dramatically better than what they would be with out of sample data. The same problem that we highlighted above with a simpler example, is still present in more robust scenarios. \n",
    "\n",
    "Letâ€™s see what results we can get when oversampling before cross-validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Datasets\n",
    "We will use two datasets as an example (one synthethic, one real) to demonstrate the difference of doing oversampling before or during cross-validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dataset 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preg</th>\n",
       "      <th>plas</th>\n",
       "      <th>pres</th>\n",
       "      <th>skin</th>\n",
       "      <th>test</th>\n",
       "      <th>mass</th>\n",
       "      <th>pedi</th>\n",
       "      <th>age</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   preg  plas  pres  skin  test  mass   pedi  age  class\n",
       "0     6   148    72    35     0  33.6  0.627   50      1\n",
       "1     1    85    66    29     0  26.6  0.351   31      0\n",
       "2     8   183    64     0     0  23.3  0.672   32      1\n",
       "3     1    89    66    23    94  28.1  0.167   21      0\n",
       "4     0   137    40    35   168  43.1  2.288   33      1"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# target = 'class'\n",
    "df = get_dataset('pima-indians-diabetes')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    500\n",
       "1    268\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"class\"].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'Class Balance for 768 Instances'}, ylabel='support'>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from yellowbrick.classifier import ClassBalance\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "cb_viz = ClassBalance(labels=[\"0\", \"1\"])\n",
    "cb_viz.fit(df[\"class\"].values.reshape(-1, 1).flatten())\n",
    "cb_viz.poof()\n",
    "#fig.savefig(\"images/class_balance.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "preg     0.0\n",
       "plas     0.0\n",
       "pres     0.0\n",
       "skin     0.0\n",
       "test     0.0\n",
       "mass     0.0\n",
       "pedi     0.0\n",
       "age      0.0\n",
       "class    0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show percent of missing values per column\n",
    "df.isnull().mean() * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    500\n",
       "1    268\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y1 = df[\"class\"]\n",
    "X1 = df.drop(columns='class')\n",
    "y1.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dataset 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 10) (1000,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    897\n",
       "1    103\n",
       "dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "\n",
    "# Define dataset with 1,000 examples and 10 input features, \n",
    "# five of which are important and five of which are redundant\n",
    "# and impalanced binary class (9:1 ratio) as target\n",
    "X2, y2 = make_classification(n_samples=1000, \n",
    "                           n_features=10, \n",
    "                           n_informative=5, \n",
    "                           n_redundant=5, \n",
    "                           random_state=1, \n",
    "                           weights=[.9])\n",
    "# summarize the dataset\n",
    "print(X2.shape, y2.shape)\n",
    "pd.Series(y2).value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bad cross-validation when oversampling\n",
    "Here is the code, we first oversample then we go into the cross-validation loops. :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split for dataset 1\n",
    "X = X1\n",
    "y = y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split for dataset 2\n",
    "X = X2\n",
    "y = pd.Series(y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this method or the method below\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "oversample = SMOTE(random_state=42)\n",
    "X, y = oversample.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this method or the method above\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "oversample = RandomOverSampler(random_state=42)\n",
    "X, y = oversample.fit_sample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    897\n",
       "0    897\n",
       "dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1255, 10) (539, 10) (1255,) (539,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.3, \n",
    "                                                    random_state=42, \n",
    "                                                    stratify=y)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    ('DummyClassifier', DummyClassifier(random_state=random_state, strategy=\"uniform\")),\n",
    "    ('LogisticRegression', LogisticRegression(solver='liblinear', random_state=42)),\n",
    "    ('DecisionTreeClassifier', DecisionTreeClassifier()),\n",
    "    ('KNeighborsClassifier', KNeighborsClassifier()),\n",
    "    ('GaussianNB', GaussianNB()),\n",
    "    ('SVC', SVC()),\n",
    "    ('RandomForestClassifier', RandomForestClassifier()),\n",
    "    ('xgboost.XGBClassifier', xgboost.XGBClassifier()),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DummyClassifier         F1-score: 0.376 STD: 0.05 \n",
      "LogisticRegression      F1-score: 0.634 STD: 0.04 \n",
      "DecisionTreeClassifier  F1-score: 0.541 STD: 0.07 \n",
      "KNeighborsClassifier    F1-score: 0.559 STD: 0.05 \n",
      "GaussianNB              F1-score: 0.627 STD: 0.05 \n",
      "SVC                     F1-score: 0.576 STD: 0.04 \n",
      "RandomForestClassifier  F1-score: 0.624 STD: 0.07 \n",
      "xgboost.XGBClassifier   F1-score: 0.566 STD: 0.08 \n"
     ]
    }
   ],
   "source": [
    "# Cross-validation\n",
    "\n",
    "for model in models:\n",
    "    \n",
    "    cls = model[1]\n",
    "    #cv = KFold(n_splits=5, random_state=42, shuffle=True)\n",
    "    cv = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\n",
    "    #cv = RepeatedKFold(n_splits=5, n_repeats=10, random_state=42)\n",
    "    #cv = ShuffleSplit(n_splits=5, random_state=42)\n",
    "    #scores = cross_val_score(cls, X_train, y_train, scoring=\"roc_auc\", cv=cv)\n",
    "    scores = cross_val_score(cls, X_train, y_train, scoring=\"f1\", cv=cv)\n",
    "\n",
    "    print(f\"{model[0]:22}  F1-score: \"\n",
    "          f\"{scores.mean():.3f} STD: {scores.std():.2f} \")\n",
    "    \n",
    "# Other scoring params: \n",
    "# https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "DATASET 1 (SMOTE)\n",
    "---------\n",
    "DummyClassifier         F1-score: 0.471 STD: 0.06 \n",
    "LogisticRegression      F1-score: 0.730 STD: 0.04 \n",
    "DecisionTreeClassifier  F1-score: 0.697 STD: 0.05 \n",
    "KNeighborsClassifier    F1-score: 0.725 STD: 0.03 \n",
    "GaussianNB              F1-score: 0.719 STD: 0.02 \n",
    "SVC                     F1-score: 0.687 STD: 0.03 \n",
    "RandomForestClassifier  F1-score: 0.797 STD: 0.02 \n",
    "xgboost.XGBClassifier   F1-score: 0.756 STD: 0.03\n",
    "        \n",
    "DATASET 2 (SMOTE)\n",
    "---------\n",
    "DummyClassifier         F1-score: 0.530 STD: 0.05 \n",
    "LogisticRegression      F1-score: 0.752 STD: 0.03 \n",
    "DecisionTreeClassifier  F1-score: 0.942 STD: 0.02 \n",
    "KNeighborsClassifier    F1-score: 0.944 STD: 0.01 \n",
    "GaussianNB              F1-score: 0.737 STD: 0.03 \n",
    "SVC                     F1-score: 0.940 STD: 0.01 \n",
    "RandomForestClassifier  F1-score: 0.976 STD: 0.01 \n",
    "xgboost.XGBClassifier   F1-score: 0.977 STD: 0.01\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results are pretty good now. Especially for the dataset 2 (which is extremely imbalanced), we obtained F1-score close to 1 without any feature engineering, simply using what was provided in the dataset, and without any parameter tuning for the classifier. Once again, apart from the differences in the two oversampling methods (replication of the minority class or SMOTE), `the issue here is not even which method to use, but when to use it`. Using oversampling before cross-validation we have now obtained very good F1-score, i.e. we `overfitted`. \n",
    "\n",
    "#### Proper cross-validation when oversampling\n",
    "The way to proper cross validate when oversampling data is rather simple, **we should oversample inside the loop**. It makes no sense to create instances based on our current minority class and then exclude an instance for validation, pretending we didnâ€™t generate it using data that is still in the training set. This time we oversample inside the cross-validation loop, after the validation sample has already been removed from the training data, so that we create synthetic data by interpolating only recordings that will not be used for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split for dataset 1\n",
    "X = X1\n",
    "y = y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split for dataset 2\n",
    "X = pd.DataFrame(X2)\n",
    "y = pd.Series(y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(700, 10) (300, 10) (700,) (300,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.3, \n",
    "                                                    random_state=42, \n",
    "                                                    stratify=y)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DummyClassifier         F1-score: 0.152 STD: 0.03 \n",
      "LogisticRegression      F1-score: 0.379 STD: 0.07 \n",
      "DecisionTreeClassifier  F1-score: 0.574 STD: 0.08 \n",
      "KNeighborsClassifier    F1-score: 0.634 STD: 0.04 \n",
      "GaussianNB              F1-score: 0.368 STD: 0.08 \n",
      "SVC                     F1-score: 0.681 STD: 0.07 \n",
      "RandomForestClassifier  F1-score: 0.656 STD: 0.12 \n",
      "xgboost.XGBClassifier   F1-score: 0.709 STD: 0.11 \n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "for model in models:\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\n",
    "    scores = []\n",
    "    fold_count = 0\n",
    "\n",
    "    for train, val in cv.split(X_train, y_train):\n",
    "        #print(f\"Processing fold {fold_count}\")\n",
    "\n",
    "        # Select df rows based on list index\n",
    "        X_train_fold = X_train.iloc[train]\n",
    "        X_val_fold = X_train.iloc[val]\n",
    "\n",
    "        y_train_fold = y_train.iloc[train]\n",
    "        y_val_fold = y_train.iloc[val]\n",
    "\n",
    "        # Oversample technique 1\n",
    "        oversample = SMOTE(random_state=42)\n",
    "        X_train_fold, y_train_fold = oversample.fit_resample(X_train_fold, y_train_fold)\n",
    "        #print(y_train_fold.value_counts(dropna=False))\n",
    "\n",
    "        # Oversample technique 2\n",
    "        #oversample = RandomOverSampler(random_state=42)\n",
    "        #X_train_fold, y_train_fold = oversample.fit_sample(X_train_fold, y_train_fold)\n",
    "\n",
    "        # Train\n",
    "        cls = model[1]\n",
    "        cls.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "        # Predict & score\n",
    "        pred = cls.predict(X_val_fold)\n",
    "        scores.append(f1_score(y_val_fold, pred))\n",
    "\n",
    "        fold_count += 1\n",
    "        \n",
    "    scores = pd.Series(scores)\n",
    "\n",
    "    print(f\"{model[0]:22}  F1-score: \"\n",
    "          f\"{scores.mean():.3f} STD: {scores.std():.2f} \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "DATASET 1 (SMOTE)\n",
    "---------\n",
    "DummyClassifier         F1-score: 0.376 STD: 0.06 \n",
    "LogisticRegression      F1-score: 0.670 STD: 0.04 \n",
    "DecisionTreeClassifier  F1-score: 0.580 STD: 0.06 \n",
    "KNeighborsClassifier    F1-score: 0.600 STD: 0.05 \n",
    "GaussianNB              F1-score: 0.654 STD: 0.05 \n",
    "SVC                     F1-score: 0.633 STD: 0.03 \n",
    "RandomForestClassifier  F1-score: 0.647 STD: 0.06 \n",
    "xgboost.XGBClassifier   F1-score: 0.626 STD: 0.04 \n",
    "        \n",
    "DATASET 2 (SMOTE)\n",
    "---------\n",
    "DummyClassifier         F1-score: 0.152 STD: 0.03 \n",
    "LogisticRegression      F1-score: 0.379 STD: 0.07 \n",
    "DecisionTreeClassifier  F1-score: 0.574 STD: 0.08 \n",
    "KNeighborsClassifier    F1-score: 0.634 STD: 0.04 \n",
    "GaussianNB              F1-score: 0.368 STD: 0.08 \n",
    "SVC                     F1-score: 0.681 STD: 0.07 \n",
    "RandomForestClassifier  F1-score: 0.656 STD: 0.12 \n",
    "xgboost.XGBClassifier   F1-score: 0.709 STD: 0.11  \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The same (good) method with oversampling inside CV using sklear `pipeline`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['accuracy',\n",
       " 'adjusted_mutual_info_score',\n",
       " 'adjusted_rand_score',\n",
       " 'average_precision',\n",
       " 'balanced_accuracy',\n",
       " 'completeness_score',\n",
       " 'explained_variance',\n",
       " 'f1',\n",
       " 'f1_macro',\n",
       " 'f1_micro',\n",
       " 'f1_samples',\n",
       " 'f1_weighted',\n",
       " 'fowlkes_mallows_score',\n",
       " 'homogeneity_score',\n",
       " 'jaccard',\n",
       " 'jaccard_macro',\n",
       " 'jaccard_micro',\n",
       " 'jaccard_samples',\n",
       " 'jaccard_weighted',\n",
       " 'max_error',\n",
       " 'mutual_info_score',\n",
       " 'neg_brier_score',\n",
       " 'neg_log_loss',\n",
       " 'neg_mean_absolute_error',\n",
       " 'neg_mean_gamma_deviance',\n",
       " 'neg_mean_poisson_deviance',\n",
       " 'neg_mean_squared_error',\n",
       " 'neg_mean_squared_log_error',\n",
       " 'neg_median_absolute_error',\n",
       " 'neg_root_mean_squared_error',\n",
       " 'normalized_mutual_info_score',\n",
       " 'precision',\n",
       " 'precision_macro',\n",
       " 'precision_micro',\n",
       " 'precision_samples',\n",
       " 'precision_weighted',\n",
       " 'r2',\n",
       " 'recall',\n",
       " 'recall_macro',\n",
       " 'recall_micro',\n",
       " 'recall_samples',\n",
       " 'recall_weighted',\n",
       " 'roc_auc',\n",
       " 'roc_auc_ovo',\n",
       " 'roc_auc_ovo_weighted',\n",
       " 'roc_auc_ovr',\n",
       " 'roc_auc_ovr_weighted',\n",
       " 'v_measure_score']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import SCORERS\n",
    "sorted(SCORERS.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define classification scoring for cross_validate method\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    confusion_matrix\n",
    ")\n",
    "\n",
    "# https://scikit-learn.org/stable/modules/model_evaluation.html#multimetric-scoring\n",
    "\n",
    "def tn(y_test, y_pred): return confusion_matrix(y_test, y_pred)[0, 0]\n",
    "def fp(y_test, y_pred): return confusion_matrix(y_test, y_pred)[0, 1]\n",
    "def fn(y_test, y_pred): return confusion_matrix(y_test, y_pred)[1, 0]\n",
    "def tp(y_test, y_pred): return confusion_matrix(y_test, y_pred)[1, 1]\n",
    "def PPV(y_test, y_pred): return tp(y_test, y_pred) / (tp(y_test, y_pred) + fp(y_test, y_pred))\n",
    "def TPR(y_test, y_pred): return tp(y_test, y_pred) / (tp(y_test, y_pred) + fn(y_test, y_pred))\n",
    "def TNR(y_test, y_pred): return tn(y_test, y_pred) / (tn(y_test, y_pred) + fp(y_test, y_pred))\n",
    "def NPV(y_test, y_pred): return tn(y_test, y_pred) / (tn(y_test, y_pred) + fn(y_test, y_pred))\n",
    "def BA(y_test, y_pred): return (TPR(y_test, y_pred) + TNR(y_test, y_pred)) / 2\n",
    "def F1(y_test, y_pred): return 2 * PPV(y_test, y_pred) * TPR(y_test, y_pred) / (PPV(y_test, y_pred) + TPR(y_test, y_pred))\n",
    "def F2(y_test, y_pred):\n",
    "    beta_sqared = 2**2\n",
    "    return (1 + beta_sqared) * PPV(y_test, y_pred) * TPR(y_test, y_pred) / ((beta_sqared * PPV(y_test, y_pred)) + TPR(y_test, y_pred))\n",
    "\n",
    "#scoring = [\"recall\", \"precision\", \"f1\", \"accuracy\", \"confusion_matrix\"]\n",
    "\n",
    "scoring = {\n",
    "    'tp': make_scorer(tp),\n",
    "    'tn': make_scorer(tn),\n",
    "    'fp': make_scorer(fp), # type I error\n",
    "    'fn': make_scorer(fn), # type II error\n",
    "    'accuracy': make_scorer(accuracy_score), # Accuracy\n",
    "    'PPV' : make_scorer(PPV), # Precision, Positive Predictive Value\n",
    "    'TPR' : make_scorer(TPR), # Recall, Hit rate, Sensitivity, True Positive Rate\n",
    "    'TNR' : make_scorer(TNR), # Selectivity, Specificity, True Negative Rate\n",
    "    'NPV' : make_scorer(NPV), # Negative Predictive Value\n",
    "    'BA' : make_scorer(BA), # Balanced Accuracy\n",
    "    'F1' : make_scorer(F1), # F1 Score\n",
    "    'F2' : make_scorer(PPV), # F2 Score\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DummyClassifier         Mean CV F1-score: 0.152 STD: 0.03 \n",
      "LogisticRegression      Mean CV F1-score: 0.379 STD: 0.07 \n",
      "DecisionTreeClassifier  Mean CV F1-score: 0.549 STD: 0.04 \n",
      "KNeighborsClassifier    Mean CV F1-score: 0.634 STD: 0.04 \n",
      "GaussianNB              Mean CV F1-score: 0.368 STD: 0.07 \n",
      "SVC                     Mean CV F1-score: 0.681 STD: 0.06 \n",
      "RandomForestClassifier  Mean CV F1-score: 0.668 STD: 0.12 \n",
      "xgboost.XGBClassifier   Mean CV F1-score: 0.709 STD: 0.10 \n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from imblearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "oversample = SMOTE(random_state=42)\n",
    "\n",
    "for model in models:\n",
    "\n",
    "    results = []\n",
    "\n",
    "    kf = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\n",
    "    if oversample:\n",
    "        pipeline = make_pipeline(oversample, model[1])\n",
    "    else:\n",
    "        pipeline = make_pipeline(model[1])\n",
    "\n",
    "    cv_results = cross_validate(pipeline, X_train, y_train, scoring=scoring, cv=kf)\n",
    "    results.append(cv_results)\n",
    "\n",
    "    #print(cv_results[])\n",
    "\n",
    "    mod = pipeline.fit(X_train, y_train)\n",
    "    y_pred = mod.predict(X_test)\n",
    "\n",
    "    # In cv_results scores, 'test-' refers to the validation fold, not to the hold out test dataset\n",
    "    print(f\"{model[0]:22}  Mean CV F1-score: \" \n",
    "          f\"{cv_results['test_F1'].mean():.3f} STD: {cv_results['test_F1'].std():.2f} \")\n",
    "\n",
    "    # This F1 is for predition on the hold out test dataset\n",
    "    #f1_test_score = f1_score(y_test, y_pred)\n",
    "    #print(f'F1-score on test: {f1_test_score}')\n",
    "\n",
    "\n",
    "# Confusion matrix\n",
    "#print(tp(y_test, y_pred), fp(y_test, y_pred))\n",
    "#print(fn(y_test, y_pred), tn(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, more data didn't solve any problem, regardless of doing \"smart\" oversampling using SMOTE. What did bring very high accuracy, was simply overfitting. `In the second approach, we not only get lower F1-scores but also higher standard deviations.`\n",
    "\n",
    "To summarize, **when cross-validating with oversampling**, do the following to make sure your results are generalizable:\n",
    "- Inside the cross-validation loop, get a sample out and do not use it for anything related to features selection, oversampling or model building.\n",
    "- Oversample your minority class, without the sample you already excluded.\n",
    "- Use the excluded sample for validation, and the oversampled minority class and the majority class, to create the model.\n",
    "- Repeat n times, where n is your number of samples (if doing leave one participant out cross-validation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
