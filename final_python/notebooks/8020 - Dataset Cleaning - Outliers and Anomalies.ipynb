{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "From: https://github.com/ksatola\n",
    "Version: 0.0.1\n",
    "\n",
    "TODOs\n",
    "1.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect with underlying Python code\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.insert(0, '../src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import (\n",
    "    get_dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outliers\n",
    "When modeling, it is important to clean the data sample to ensure that the observations best represent the problem. Sometimes a dataset can contain extreme values that are outside the range of what is expected and unlike the other data. These are called `outliers` and often machine learning modeling and model skill in general can be improved by understanding and even removing these outlier values.\n",
    "\n",
    "An `outlier` is an observation that is unlike the other observations. It is rare, or distinct, or does not fit in some way. We will generally define outliers as samples that are exceptionally far from the mainstream of the data. \n",
    "\n",
    "Outliers can have many causes, such as:\n",
    "- Measurement or input error,\n",
    "- Data corruption,\n",
    "- True outlier observation.\n",
    "\n",
    "**There is no precise way to define and identify outliers in general because of the specifics of each dataset**. Instead, you, or a domain expert, must interpret the raw observations and decide whether a value is an outlier or not. Nevertheless, we can use statistical methods to identify observations that appear to be rare or unlikely given the available data.\n",
    "\n",
    "Identifying outliers and bad data in your dataset is probably one of the most difficult parts of data cleanup, and it takes time to get right. Even if you have a deep understanding of statistics and how outliers might affect your data, itâ€™s always a topic to explore cautiously. \n",
    "\n",
    "A good tip is to consider plotting the identified outlier values, perhaps in the context of non-outlier values to see if there are any systematic relationship or pattern to the outliers. If there is, perhaps they are not outliers and can be explained, or perhaps the outliers themselves can be identified more systematically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean=50.049 stdv=4.994\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAARiklEQVR4nO3df4xlZX3H8fdHpGjQiMh0s2U3XapUo6YsOkUJxiBEBTQuJpZCWkRLs/4BiSamFWxS6Q9STKqUP1qSVdBFrUBRy0aJFZHEmFRwFlcQkLjqEnaz7I4KijXFAt/+cc/CdZnZmZ2ZO/fMs+9XcnPPec65M1+eWT7z3Oc+50yqCklSW54z7gIkSUvPcJekBhnuktQgw12SGmS4S1KDnjvuAgCOOeaYWrdu3bjLkKQVZevWrT+tqomZjvUi3NetW8fU1NS4y5CkFSXJg7Mdc1pGkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1CDDXZIa1IsrVKU+WHfJV57e3nHF28ZYibR4jtwlqUGGuyQ1yHCXpAY5567mOZeuQ5HhrkPWcOjP9zx/OWilcFpGkhpkuEtSgwx3SWqQ4S5JDfIDVR1S5vshqrTSOXKXpAbNOXJP8jzgm8AR3fk3VdVHkhwHXA+8BNgKnF9Vv0lyBHAd8FrgZ8CfVtWOEdUvLSuXRWqlmM/I/XHgtKo6AVgPnJHk9cBHgSur6mXAI8CF3fkXAo907Vd250mSltGc4V4Dv+p2D+8eBZwG3NS1bwbO7rY3dPt0x09PkqUqWJI0t3nNuSc5LMk2YC9wK/Aj4NGqeqI7ZSdwbLd9LPAQQHf8FwymbiRJy2Re4V5VT1bVemANcBLwisV+4yQbk0wlmZqenl7sl5MkDTmo1TJV9ShwO3AycFSSfR/IrgF2ddu7gLUA3fEXMfhgdf+vtamqJqtqcmJiYmHVS5JmNJ/VMhPA/1XVo0meD7yZwYektwPvYrBi5gLg5u4lW7r9/+6Of6OqagS1SyPjenitdPO5iGk1sDnJYQxG+jdW1ZeT3Adcn+Qfge8C13TnXwN8Jsl24OfAuSOoW5J0AHOGe1XdDZw4Q/uPGcy/79/+v8CfLEl1kqQF8QpVSWqQ4S5JDfLGYWqSH4jqUOfIXZIa5MhdWmLeXEx94MhdkhrkyF295QhYWjhH7pLUIMNdkhrktIxWtL5M3bj0Un3jyF2SGuTIXc1w9Cw9w3DXimOIS3NzWkaSGuTIXVog30Gozxy5S1KDDHdJapDhLkkNMtwlqUF+oCqNUF+uoNWhx5G7JDXIcJekBhnuktSgOcM9ydoktye5L8m9Sd7ftV+WZFeSbd3jrKHXXJpke5IHkrx1lP8BkqRnm88Hqk8AH6yqu5K8ENia5Nbu2JVV9c/DJyd5JXAu8Crg94CvJ/nDqnpyKQuXJM1uzpF7Ve2uqru67ceA+4FjD/CSDcD1VfV4Vf0E2A6ctBTFSpLm56CWQiZZB5wI3AGcAlyc5N3AFIPR/SMMgv/bQy/byYF/GUhP834t0tKY9weqSV4AfAH4QFX9ErgaeCmwHtgNfOxgvnGSjUmmkkxNT08fzEslSXOYV7gnOZxBsH+uqr4IUFV7qurJqnoK+ATPTL3sAtYOvXxN1/ZbqmpTVU1W1eTExMRi/hskSfuZz2qZANcA91fVx4faVw+d9k7g+932FuDcJEckOQ44Hrhz6UqWJM1lPnPupwDnA/ck2da1fRg4L8l6oIAdwPsAqureJDcC9zFYaXORK2UkaXnNGe5V9S0gMxy65QCvuRy4fBF1Sc3xPjNaTl6hKkkNMtwlqUGGuyQ1yHCXpAb5xzo0dl6VKi09R+6S1CDDXZIa5LSMVgSnbqSD48hdkhpkuEtSg5yWkcbAWxFo1By5S1KDDHdJapDhLkkNMtwlqUGGuyQ1yNUyGgsvSpJGy5G7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJatCcSyGTrAWuA1YBBWyqqquSHA3cAKwDdgDnVNUjSQJcBZwF/Bp4T1XdNZrypZXPm4hpFOazzv0J4INVdVeSFwJbk9wKvAe4raquSHIJcAnwIeBM4Pju8Trg6u5Z0hwMei2VOadlqmr3vpF3VT0G3A8cC2wANnenbQbO7rY3ANfVwLeBo5KsXurCJUmzO6g59yTrgBOBO4BVVbW7O/Qwg2kbGAT/Q0Mv29m17f+1NiaZSjI1PT19sHVLkg5g3uGe5AXAF4APVNUvh49VVTGYj5+3qtpUVZNVNTkxMXEwL5UkzWFe4Z7kcAbB/rmq+mLXvGffdEv3vLdr3wWsHXr5mq5NkrRM5gz3bvXLNcD9VfXxoUNbgAu67QuAm4fa352B1wO/GJq+kSQtg/msljkFOB+4J8m2ru3DwBXAjUkuBB4EzumO3cJgGeR2Bksh37uUBUuS5jZnuFfVt4DMcvj0Gc4v4KJF1iVJWgSvUJWkBhnuktQgw12SGuSf2dOS8xJ6afwcuUtSgwx3SWqQ4S5JDTLcJalBfqAq9ZQfTGsxHLlLUoMcuUsrjCN6zYfhrpEyiKTxcFpGkhpkuEtSg5yW0bIZnqKRNFqGu7QC+ItRB8tpGUlqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGjRnuCe5NsneJN8farssya4k27rHWUPHLk2yPckDSd46qsIlSbObz8j908AZM7RfWVXru8ctAEleCZwLvKp7zb8lOWypipUkzc+c4V5V3wR+Ps+vtwG4vqoer6qfANuBkxZRnyRpARYz535xkru7aZsXd23HAg8NnbOza3uWJBuTTCWZmp6eXkQZkqT9LfTeMlcD/wBU9/wx4C8O5gtU1SZgE8Dk5GQtsA71hPc+kfplQSP3qtpTVU9W1VPAJ3hm6mUXsHbo1DVdmyRpGS0o3JOsHtp9J7BvJc0W4NwkRyQ5DjgeuHNxJUqSDtac0zJJPg+cChyTZCfwEeDUJOsZTMvsAN4HUFX3JrkRuA94Arioqp4cSeWSpFnNGe5Vdd4Mzdcc4PzLgcsXU5QkaXG8QlWSGmS4S1KDDHdJapB/Q1VawYavL9hxxdvGWIn6xnDXQfFiJWllcFpGkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1CAvYpIa4dWqGubIXZIa5MhdT3PkJ7XDkbskNchwl6QGOS2jOXknSGnlceQuSQ0y3CWpQYa7JDXIcJekBs35gWqSa4G3A3ur6tVd29HADcA6YAdwTlU9kiTAVcBZwK+B91TVXaMpXaPkh6grm9csaD4j908DZ+zXdglwW1UdD9zW7QOcCRzfPTYCVy9NmZKW2rpLvvL0Q+2ZM9yr6pvAz/dr3gBs7rY3A2cPtV9XA98GjkqyeolqlSTN00Ln3FdV1e5u+2FgVbd9LPDQ0Hk7u7ZnSbIxyVSSqenp6QWWIUmayaI/UK2qAmoBr9tUVZNVNTkxMbHYMiRJQxYa7nv2Tbd0z3u79l3A2qHz1nRtkqRltNDbD2wBLgCu6J5vHmq/OMn1wOuAXwxN30gaA1fOHJrmsxTy88CpwDFJdgIfYRDqNya5EHgQOKc7/RYGyyC3M1gK+d4R1CxJmsOc4V5V581y6PQZzi3gosUWJWk0XPZ46PAKVUlqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJatBC7y0jqVH7X8Xq/WhWJkfuktQgR+6SvOdMgxy5S1KDDHdJapDhLkkNcs79EOdcq9QmR+6S1CBH7pIOyL/BujI5cpekBjlyb5SjLenQZrgfArycXDr0OC0jSQ0y3CWpQYualkmyA3gMeBJ4oqomkxwN3ACsA3YA51TVI4srU0vJte1S+5Zi5P6mqlpfVZPd/iXAbVV1PHBbty9JWkajmJbZAGzutjcDZ4/ge0iSDmCx4V7A15JsTbKxa1tVVbu77YeBVTO9MMnGJFNJpqanpxdZhiRp2GKXQr6hqnYl+V3g1iQ/GD5YVZWkZnphVW0CNgFMTk7OeI6klcHrKvpnUeFeVbu6571JvgScBOxJsrqqdidZDexdgjol9YAhvnIsONyTHAk8p6oe67bfAvw9sAW4ALiie755KQrV3FwFo+Xkv7d+W8zIfRXwpST7vs6/V9VXk3wHuDHJhcCDwDmLL1OSdDAWHO5V9WPghBnafwacvpiiJEmL471lVjjfGkuaibcfkKQGOXJfgRytS5qL4b5CGOiSDobhLmlJuRa+H5xzl6QGGe6S1CDDXZIaZLhLUoMMd0lqkKtlJI2MK2fGx3DvMde2S1oop2UkqUGGuyQ1yGmZnnEqRq1y/n15OXKXpAY5cu8BR+s61DiKHz3DXdJYGfSjYbiPgP9YpYXx/52lY7iPmFMuksbBcF8ihrikPjHcJfXSbAOm4ekap3Fm51JISWpQqmo0Xzg5A7gKOAz4ZFVdMdu5k5OTNTU1NZI6RsmpGKmfZhvFtzbST7K1qiZnOjaSaZkkhwH/CrwZ2Al8J8mWqrpvFN9vMWb7Ybf2j0DSoWUkI/ckJwOXVdVbu/1LAarqn2Y6fzEj94WEsCNuSUvpYAeGSzV4PNDIfVTh/i7gjKr6y27/fOB1VXXx0DkbgY3d7suBB4BjgJ8ueUFLo8+1gfUtRp9rg37X1+faoP36fr+qJmY6MLbVMlW1Cdg03JZkarbfQuPW59rA+hajz7VBv+vrc21waNc3qtUyu4C1Q/trujZJ0jIYVbh/Bzg+yXFJfgc4F9gyou8lSdrPSKZlquqJJBcD/8VgKeS1VXXvPF66ae5TxqbPtYH1LUafa4N+19fn2uAQrm9k69wlSePjFaqS1CDDXZIaNJZwT/K8JHcm+V6Se5P8Xdd+XJI7kmxPckP3YWyf6vt0kp8k2dY91o+jvq6Ww5J8N8mXu/1e9N0B6utT3+1Ick9Xx1TXdnSSW5P8sHt+cY9quyzJrqG+O2sctXW1HJXkpiQ/SHJ/kpN71Hcz1daLvkvy8qEatiX5ZZIPjLLvxjVyfxw4rapOANYDZyR5PfBR4MqqehnwCHBhz+oD+KuqWt89to2pPoD3A/cP7fel7/bZvz7oT98BvKmrY98a40uA26rqeOC2bn9c9q8NBj/bfX13y9gqG9wv6qtV9QrgBAY/47703Uy1QQ/6rqoe2FcD8Frg18CXGGHfjSXca+BX3e7h3aOA04CbuvbNwNnLX90B6+uFJGuAtwGf7PZDT/quq+e36lshNjDoNxhz//VVkhcBbwSuAaiq31TVo/Sg7w5QWx+dDvyoqh5khH03tjn37m37NmAvcCvwI+DRqnqiO2UncOyYyntWfVV1R3fo8iR3J7kyyRFjKu9fgL8Gnur2X0KP+o5n17dPH/oOBr+ov5Zka3cbDIBVVbW7234YWDWe0masDeDiru+uHde0B3AcMA18qpty+2SSI+lH381WG/Sj74adC3y+2x5Z340t3Kvqye4tyhrgJOAV46plJvvXl+TVwKUM6vxj4GjgQ8tdV5K3A3urautyf+/5OEB9Y++7IW+oqtcAZwIXJXnj8MEarA8e1zu1mWq7GngpgynC3cDHxlTbc4HXAFdX1YnA/7DfNMIY+2622vrSdwB0n4W9A/iP/Y8tdd+NfbVM99bpduBk4Kgk+y6s6sUtC4bqO6OqdndTNo8Dn2LwS2m5nQK8I8kO4HoG0zFX0Z++e1Z9ST7bk74DoKp2dc97Gcx7ngTsSbIaoHve25faqmpPN9h4CvgE4+u7ncDOoXexNzEI1D703Yy19ajv9jkTuKuq9nT7I+u7ca2WmUhyVLf9fAb3fb+fQYi+qzvtAuDmHtX3g6EfQhjMjX1/uWurqkurak1VrWPw9u4bVfVn9KTvZqnvz/vQd933PzLJC/dtA2/patnCoN9gTP03W237+q7zTsbUd1X1MPBQkpd3TacD99GDvputtr703ZDzeGZKBkbZd1W17A/gj4DvAncz6Oy/7dr/ALgT2M7gbcsRPavvG8A9XdtngReMo76hOk8FvtynvjtAfb3ou66fvtc97gX+pmt/CYPVCj8Evg4c3aPaPtP13d0MwmD1GH+m64Gprpb/BF7ch747QG196rsjgZ8BLxpqG1nfefsBSWrQ2OfcJUlLz3CXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDfp/VZmVUHffJvQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from numpy.random import seed\n",
    "from numpy.random import randn\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "\n",
    "# Seed the random number generator\n",
    "seed(1)\n",
    "# Generate univariate observations\n",
    "data = 5 * randn(10000) + 50\n",
    "# Summarize\n",
    "print(f'mean={mean(data):.3f} stdv={std(data):.3f}')\n",
    "# Plot the data distribution\n",
    "plt.hist(x=data, bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard Deviation Method (For Normally Distributed Data)\n",
    "**If we know that the distribution of values in the sample is Gaussian or Gaussian-like, we can use the standard deviation of the sample as a cut-off for identifying outliers**. The `Gaussian distribution` has the property that the standard deviation from the mean can be used to reliably summarize the percentage of values in the sample. So, if the mean is 50 and the standard deviation is 5, as in the test dataset above, then all data in the sample between 45 and 55 will account for about 68% of the data sample. We can cover more of the data sample if we expand the range as follows:\n",
    "- 1 Standard Deviation from the Mean: 68%\n",
    "- 2 Standard Deviations from the Mean: 95%\n",
    "- 3 Standard Deviations from the Mean: 99.7%\n",
    "\n",
    "A value that falls outside of 3 standard deviations is part of the distribution, but it is an `unlikely or rare event` at approximately 1 in 370 samples.\n",
    "\n",
    "**Three standard deviations from the mean is a common cut-off in practice for identifying outliers in a Gaussian or Gaussian-like distribution**. For smaller samples of data, perhaps a value of 2 standard deviations (95%) can be used, and for larger samples, perhaps a value of 4 standard deviations (99.9%) can be used.\n",
    "\n",
    "Given `mu` and `sigma`, a simple way to identify outliers is to compute a `z-score` for every xi, which is defined as the number of standard deviations away xi is from the mean. Data values that have a `z-score` sigma greater than a threshold, for example, of three, are declared to be `outliers`.\n",
    "\n",
    "Sometimes, the data is standardized first (e.g. to a `Z-score` with zero mean and unit variance) so that the outlier detection can be performed using standard `Z-score` cut-off values. This is a convenience and is not required in general, and we will perform the calculations in the original scale of the data here to make things clear.\n",
    "\n",
    "We can calculate the mean and standard deviation of a given sample, then calculate the cut-off for identifying outliers as more than 3 standard deviations from the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate summary statistics\n",
    "data_mean, data_std = mean(data), std(data)\n",
    "\n",
    "# Identify outliers\n",
    "cut_off = data_std * 3\n",
    "lower = data_mean - cut_off\n",
    "upper = data_mean + cut_off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50.04886328349552"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.993929218440242"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.981787655320726"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cut_off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35.06707562817479"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65.03065093881625"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[31.717799503726024,\n",
       " 33.525707966507426,\n",
       " 33.6969245211173,\n",
       " 33.73482882511691,\n",
       " 33.90433947188079,\n",
       " 34.0469182658796,\n",
       " 34.23321274904475,\n",
       " 34.679293219474495,\n",
       " 34.72183379792847,\n",
       " 34.73117809786848,\n",
       " 34.91984007395351,\n",
       " 65.06377284118616,\n",
       " 65.15428556186015,\n",
       " 65.55945915508362,\n",
       " 65.59239795391275,\n",
       " 65.66014864070253,\n",
       " 65.67523670043954,\n",
       " 65.74492012609815,\n",
       " 66.19171598376188,\n",
       " 66.49270261640393,\n",
       " 66.60539378085183,\n",
       " 66.99057828251213,\n",
       " 67.02151137874486,\n",
       " 67.1633171589778,\n",
       " 67.80436660352774,\n",
       " 68.06638503541573,\n",
       " 68.70124451852294,\n",
       " 69.79301352018982,\n",
       " 70.1342452227369]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identify outliers\n",
    "outliers = [x for x in data if x < lower or x > upper]\n",
    "outliers.sort() # this returns None, and sorts the list in place\n",
    "outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove outliers\n",
    "outliers_removed = [x for x in data if x > lower and x < upper]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identified outliers: 29\n",
      "Non-outlier observations: 9971\n"
     ]
    }
   ],
   "source": [
    "print(f'Identified outliers: {len(outliers)}')\n",
    "print(f'Non-outlier observations: {len(outliers_removed)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interquartile Range Method (For Non-Gaussian Distributions of Data)\n",
    "Not all data is normal or normal enough to treat it as being drawn from a Gaussian distribution. A good statistic for summarizing a non-Gaussian distribution sample of data is the `Interquartile Range`, or `IQR` for short. The `IQR` is calculated as the **difference between the 75th and the 25th percentiles of the data** and defines the box in a box and `whisker plot`.\n",
    "\n",
    "Remember that `percentiles` can be calculated by sorting the observations and selecting values at specific indices. The `50th percentile` is the middle value, or the average of the two middle values for an even number of examples. If we had 10,000 samples, then the 50th percentile would be the average of the 5000th and 5001st values. We refer to the percentiles as quartiles (`quart` meaning 4) because the data is divided into four groups via the 25th, 50th and 75th values. The `IQR` defines the middle 50% of the data, or the body of the data.\n",
    "\n",
    "**The `IQR` can be used to identify outliers by defining limits on the sample values that are a factor k of the IQR below the 25th percentile or above the 75th percentile. The common value for the factor k is the value 1.5. A factor k of 3 or more can be used to identify values that are extreme outliers or far outs when described in the context of `box and whisker plots`**.\n",
    "\n",
    "On a `box and whisker plot`, these limits are drawn as fences on the whiskers (or the lines) that are drawn from the box. Values that fall outside of these values are drawn as dots.\n",
    "\n",
    "We can calculate the percentiles of a dataset using the `percentile()` NumPy function that takes the dataset and specification of the desired percentile. The `IQR` can then be calculated as the difference between the 75th and 25th percentiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "from numpy.random import randn\n",
    "from numpy import percentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46.685375790489445 53.3590441773518\n"
     ]
    }
   ],
   "source": [
    "# Calculate interquartile range\n",
    "q25, q75 = percentile(data, 25), percentile(data, 75)\n",
    "print(q25, q75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46.685375790489445 53.3590441773518\n"
     ]
    }
   ],
   "source": [
    "# or\n",
    "q25, q75 = percentile(data, [25, 75])\n",
    "print(q25, q75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.673668386862353"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iqr = q75 - q25\n",
    "iqr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentiles: 25th=46.685, 75th=53.359, IQR=6.674\n"
     ]
    }
   ],
   "source": [
    "print(f'Percentiles: 25th={q25:.3f}, 75th={q75:.3f}, IQR={iqr:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.01050258029353 36.67487321019591 63.369546757645324\n"
     ]
    }
   ],
   "source": [
    "# Calculate the outlier cutoff\n",
    "cut_off = iqr * 1.5\n",
    "lower, upper = q25 - cut_off, q75 + cut_off\n",
    "print(cut_off, lower, upper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify outliers\n",
    "outliers = [x for x in data if x < lower or x > upper]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove outliers\n",
    "outliers_removed = [x for x in data if x > lower and x < upper]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identified outliers: 81\n",
      "Non-outlier observations: 9919\n"
     ]
    }
   ],
   "source": [
    "print(f'Identified outliers: {len(outliers)}')\n",
    "print(f'Non-outlier observations: {len(outliers_removed)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visual Way of Identifying Outliers\n",
    "It is always a good idea to check data for outliers visually. For detailed description and the meaning of the plot see: https://seaborn.pydata.org/generated/seaborn.boxplot.html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWEAAAD4CAYAAAA94VfoAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAQVklEQVR4nO3dbUzV9f/H8dfhQkTKNlCgGJt5tchcbv8bNm8UYI4rXeRFm3PTZYutmhikpYkLG5K5MtNbVqvJ5n7LlWJL1KlQVurSyovfxNEZc0NXsh28SMEDB7//G+6cgXCSA+fwPj99Pm7BOed7Pm8+8H1y+ILlchzHEQDARIz1AADwICPCAGCICAOAISIMAIaIMAAYigv1gFOnTkmSEhISwj1L2Hi9XuYbpGieTWK+oYjm2aToni8cs3m9Xk2bNq3P7SFH2D9IVlbWkAaKpMbGRuYbpGieTWK+oYjm2aToni8cszU2NvZ7O5cjAMAQEQYAQ0QYAAwRYQAwRIQBwBARBgBDRBgADBFhADBEhAHAEBEGAENEGAAMEWEAMESEAcAQEQYAQ0QYAAwRYQAwRIQBwBARBgBDRBgADIX8/5gD7rZ161a53e6Ir9PW1qbOzk6lp6dHfC1JmjhxopYtWzYsa+HBRYQxZG63W6f+26juUckRXSe23SNJutTuiug6d9Zqi/gagESEESbdo5LV8URhRNdIPF8nSRFfp+daQKRxTRgADBFhADBEhAHAEBEGAENEGAAMEWEAMESEAcAQEQYAQ0QYAAwRYQAwRIQBwBARBgBDRBgADBFhADBEhAHAEBEGAENEGAAMEWEAMESEAcAQEQYAQ0QYAAwRYQAwRIQBwBARBgBDRBgADBFhADBEhAHAEBEGAENEGAAMEWEAMESEAcAQEQYAQ0QYAAwRYQAwRIQBwBARBgBDRBgADBFhADBEhAHAEBEGAENEGAAMEWFJBw4c0IEDB6zHAO4LnE+hibMeIBrU1dVJkvLy8ownAf73cT6FhlfCAGCICAOAISIMAIaIMAAYIsIAYIgIA4AhIgwAhogwABgiwgBgiAgDgCEiDACGiDAAGCLCAGCICAOAISIMAIaIMAAYIsIAYIgIA4AhIgwAhogwABgiwgBgiAgDgCEiDACGiDAAGCLCAGCICAOAISIMAIaIMAAYIsIAYIgIA4AhIgwAhogwABgiwgBgiAgDgCEiDACGiDAAGCLCAGCICAOAoWGLsMfjUWlpqTwez6CO++2331RQUKCSkhK53W69/vrreu211wLPd/LkSeXk5Gjp0qVqaWlRaWmpTp48qaKiIjU0NCg/P18FBQXasmWLsrOzNW/ePOXl5WnmzJk6ffq0Tp8+rYaGhkh86MADpaurS+fPn1d2drays7O1aNEi5efna9GiRYHbXnrpJWVnZ2vp0qWB87m6ujpwTrvdbhUUFCgvL08lJSXyeDy9GuJ2u1VUVCS32y1JcrvdKiws1KuvvtqrMf5j3G53n/4MpEn+x/ibEmq/BmLYIrx9+3adPXtWNTU1gzruvffeU0dHh5qamlRVVaVz586psbEx8HyVlZVyHEfNzc366quvdPbsWVVWVurmzZtav369bt26pY6ODu3atUvSnc31er3q7u4OrLV+/frwfcDAA+ry5cvyer2B9y9duqRbt27p0qVLgdtaW1slSc3NzYHzuaWlJXBOV1VVqaOjQ16vV01NTaqpqenVkKqqKt28eVNVVVWSpKqqKrW3t+vPP//s1Rj/MVVVVX36M5Am+R/jb0qo/RqIYYmwx+PR/v375TiO9u/fP+DvJj2Pu3HjRuD2CxcuBN7et2+f6uvre93/119/9TrG5/MNaD2fz8erYWAIPB6P2traQjqm5/ksSXv37u1zW11dnfbt2yfHcVRXVxe4/8KFC2poaOj1+Lq6usArZ38/Lly40Ks/A2lSz8f4mxJKvwYqLqzPFsT27dt1+/ZtSVJ3d7dqampUVlYW0nHBdHV1qbq6OixzStK6detUW1sbtufrT3t7u0aNGhXRNQZrMLO53W65uoflS2nYuLo65Ha7tXz58pCOu98+t6G6ePGiHMcZ0nP096Kpq6tLLpcr8HZPd/8E29XVpZqaGjmO06cf/v70vC9Yk/rrTyj9GqhheSV86NChwMb6fD4dPHgw5OOCcRxnwK90AUTWlStXIvbcweLe3/l/8ODBfvvh789AmvRvx4fTsLx8ef7551VXVyefz6e4uDjNmjUr5OOCcblcio2NDVuI4+Li9Omnn4bluYJpbGxUVlZWRNcYrMHMtnz5cv3WfDlCE9lw4hM1cXxayF8L99vnNlSbNm3Sd999F5Hndrlc/YY4Li6uz/k/a9aswKWLnvf5+9PzvmBN6q8/ofRroIbllfCSJUsUE3NnqdjYWC1evDjk44KJj4/Xu+++O+QZ/dasWRO25wIeNEuWLAlcNhisuLi+rw3j4+MDt8fHx/e67+5zNj4+XosXL+63H/7+DKRJ/3Z8OA1LhFNSUpSfny+Xy6X8/HylpKSEfNxDDz0UuH3cuHGBtwsKCpSbm9vr/kcffbTXMf19UvsTFxennJycAT0WQF8pKSlKTk4O6Zie57MkFRUV9bmtsLBQBQUFcrlcKiwsDNw/btw45eTk9Hp8YWGhUlJSevVj3LhxvfozkCb1fIy/KaH0a6CG7U/UlixZoqlTp4b8XcR/3Lp165SYmKjJkyeroqJCTz75pLKysgLPV1lZKZfLpfHjx+vll1/W1KlTVVlZqaSkJK1Zs0YjR45UYmKi5s6dK+nOBickJCg2NjawFq+CgaFLS0tTQkJC4P2MjAyNHDlSGRkZgdtSU1MlSePHjw+cz5mZmYFzuqKiQomJiUpISNDkyZMDr179DamoqFBSUpIqKiokSRUVFRo1apQmTZrUqzH+YyoqKvr0ZyBN8j/G35RwvwqWJJcT4q8yGxsbJSlqr3tJoV/78v8GPNLXgv3ut+uG/mvCHU8URmiqOxLP10lSxNfxr/V/XBMelMGeT/f73gV7Dv7ZMgAYIsIAYIgIA4AhIgwAhogwABgiwgBgiAgDgCEiDACGiDAAGCLCAGCICAOAISIMAIaIMAAYIsIAYIgIA4AhIgwAhogwABgiwgBgiAgDgCEiDACGiDAAGCLCAGCICAOAISIMAIaIMAAYIsIAYIgIA4AhIgwAhogwABgiwgBgiAgDgCEiDACGiDAAGCLCAGCICAOAISIMAIaIMAAYIsIAYCjOeoBoUFhYaD0CcN/gfAoNEZaUl5dnPQJw3+B8Cg2XIwDAEBEGAENEGAAMEWEAMESEAcAQEQYAQ0QYAAwRYQAwRIQBwBARBgBDRBgADBFhADBEhAHAEBEGAENEGAAMEWEAMESEAcAQEQYAQ0QYAAwRYQAwRIQBwBARBgBDRBgADBFhADBEhAHAEBEGAENEGAAMEWEAMESEAcAQEQYAQ0QYAAwRYQAwRIQBwBARBgBDRBgADBFhADBEhAHAEBEGAENEGAAMEWEAMBRnPQDuD7HtbUo8XxfhNTySFPF17qzVJikt4usARBhDNnHixGFZp60tXp2dnUpPH444pg3bx4UHGxHGkC1btmzY1mpsbFRWVtawrQdEGteEAcAQEQYAQ0QYAAwRYQAwRIQBwBARBgBDRBgADBFhADBEhAHAEBEGAENEGAAMEWEAMESEAcAQEQYAQ0QYAAwRYQAwRIQBwBARBgBDRBgADBFhADDkchzHCeWAU6dOKSEhIVLzAMB9yev1atq0aX1uDznCAIDw4XIEABgiwgBgiAgDgCEiDACGiDAAGCLCAGAo7l4P8Hq9WrRokTo7O9Xd3a28vDyVlpaqpaVF5eXlunr1qqZMmaKNGzdqxIgRwzHzPWdbtWqVfv31Vz388MOSpA0bNigrK2tYZ+upu7tb8+bNU1pamrZt2xYVexdstmjau9zcXCUlJSkmJkaxsbHatWuXrl69qrKyMl26dEkZGRnavHmzHnnkkaiZb+vWrdq5c6eSk5MlSeXl5XruuedM5rt+/boqKirU1NQkl8ul6upqPf7441Gxf/3N9vPPP0fF3jU3N6usrCzwfktLi0pLS1VcXByZvXPu4fbt286NGzccx3Gczs5OZ/78+c4ff/zhlJaWOt9//73jOI6zdu1aZ8eOHfd6qrALNts777zj7Nu3b9jnCebLL790ysvLnZKSEsdxnKjYu2CzRdPe5eTkOB6Pp9dtH374obNt2zbHcRxn27ZtzsaNGy1Gcxyn//m2bNnifPHFF0YT9fb22287O3fudBzHcbxer3Pt2rWo2b/+ZoumvfPz+XzOjBkznIsXL0Zs7+55OcLlcikpKUmS5PP55PP55HK5dPz4ceXl5UmSXnzxRR0+fHjo3xFCFGy2aPL333/rhx9+0Pz58yVJjuNExd71N9v/gsOHD6u4uFiSVFxcrEOHDtkOFKX++ecfnThxIvC5HTFihEaPHh0V+xdstmh07NgxZWZmKiMjI2J7N6Brwt3d3XrhhRc0Y8YMzZgxQ5mZmRo9erTi4u5czUhPT9fly5fDMlCo7p7t6aefliR98sknmjNnjqqrq9XZ2WkymyRVV1dr5cqViom5s9VXrlyJmr27eza/aNk7SXrllVc0d+5cff3115Ikj8ej1NRUSdLYsWPl8Xgsx+sznyTt2LFDc+bM0erVq3Xt2jWTuS5evKjk5GStXr1axcXFWrNmjdrb26Ni/4LNJkXH3vW0d+9ezZ49W1LkvvYGFOHY2Fjt2bNHP/74o86cOaPm5uawLB4Od8/W1NSk8vJy7d+/X99++62uXbumzz77zGS2hoYGJScn66mnnjJZ/98Emy1a9k6S/vOf/2j37t36/PPPtWPHDp04caLX/S6Xy/Qnn/7mW7hwoQ4ePKg9e/YoNTVVGzZsMJnN5/Pp3LlzWrhwoWpra5WYmNjnc2m1f8Fmi5a98+vs7FR9fb3y8/P73BfOvQvpryNGjx6t6dOn69SpU7p+/bp8Pp+kOz/WpqWlhWWgwfLP9tNPPyk1NVUul0sjRozQ3LlzdfbsWZOZfv/9d9XX1ys3N1fl5eU6fvy41q9fHxV7199sK1asiJq9kxTYl5SUFM2aNUtnzpxRSkqKWltbJUmtra2BX+JEy3xjxoxRbGysYmJitGDBArP9S09PV3p6euAnw/z8fJ07dy4q9i/YbNGyd35HjhzRlClTNGbMGEmK2N7dM8JtbW26fv26JOnWrVs6evSoJkyYoOnTp+vAgQOSpN27dys3NzcsA4Wiv9nGjx8f2CjHcXTo0CFNmjRp2GeTpLfeektHjhxRfX29Nm3apGeeeUYff/xxVOxdf7N99NFHUbN37e3tunHjRuDtX375RZMmTVJubq5qa2slSbW1tZo5c2ZUzeffP0mm+zd27Filp6cHfmo9duyYJkyYEBX7F2y2aNk7v71796qoqCjwfqT27p5/otba2qpVq1apu7tbjuMoPz9fOTk5mjhxosrKyrR582ZlZWVpwYIFYRkoFMFmW7x4sa5cuSLHcfTEE09o3bp1wz7bv1m5cqX53gWzYsWKqNg7j8ejN954Q9Kd6/6zZ8/Ws88+q6lTp+rNN9/UN998o8cee0ybN2+OqvlWrlyp8+fPS5IyMjL0/vvvm8wnSWvXrtWKFSvU1dWlzMxMffDBB7p9+3ZU7F9/s1VVVUXN3rW3t+vo0aO9ZigpKYnI3vGfsgQAQ/yLOQAwRIQBwBARBgBDRBgADBFhADBEhAHAEBEGAEP/DxWp8qycXwOAAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set_style(\"whitegrid\") \n",
    "sns.boxplot(x = data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automatic Outlier / Anomaly Detection\n",
    "In machine learning, an approach to tackling the problem of outlier detection is `one-class classification`. One-Class Classification, or `OCC` for short, involves fitting a model on the \"normal\" data and predicting whether new data is normal or an `outlier/anomaly`. **A one-class classifier is fit on a training dataset that only has examples from the normal class**. Once prepared, the model is used to classify new examples as either normal or not-normal, i.e. `outliers` or `anomalies`.\n",
    "\n",
    "A simple approach to identifying outliers is to locate those examples that are far from the other examples in the feature space. This can work well for feature spaces with low dimensionality (few features), although it can become less reliable as the number of features is increased, referred to as the `curse of dimensionality`.\n",
    "\n",
    "The `local outlier factor`, or `LOF` for short, is a technique that attempts to harness the idea of nearest neighbors for `outlier detection`. Each example is assigned a scoring of how isolated or how likely it is to be outliers based on the size of its local neighborhood. Those examples with the largest score are more likely to be outliers. The scikit-learn library provides an implementation of this approach in the [LocalOutlierFactor](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.LocalOutlierFactor.html) class.\n",
    "\n",
    "We can demonstrate the LocalOutlierFactor method on a predictive modelling dataset. The Boston housing regression problem that has 13 inputs and one numerical target and requires learning the relationship between suburb characteristics and house prices.\n",
    "\n",
    "First, we can load the dataset as a NumPy array, separate it into input and output variables and then split it into train and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crim</th>\n",
       "      <th>zn</th>\n",
       "      <th>indus</th>\n",
       "      <th>chas</th>\n",
       "      <th>nox</th>\n",
       "      <th>rm</th>\n",
       "      <th>age</th>\n",
       "      <th>dis</th>\n",
       "      <th>rad</th>\n",
       "      <th>tax</th>\n",
       "      <th>ptratio</th>\n",
       "      <th>b</th>\n",
       "      <th>lstat</th>\n",
       "      <th>medv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      crim    zn  indus  chas    nox     rm   age     dis  rad  tax  ptratio  \\\n",
       "0  0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296     15.3   \n",
       "1  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242     17.8   \n",
       "2  0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242     17.8   \n",
       "3  0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222     18.7   \n",
       "4  0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222     18.7   \n",
       "\n",
       "        b  lstat  medv  \n",
       "0  396.90   4.98  24.0  \n",
       "1  396.90   9.14  21.6  \n",
       "2  392.83   4.03  34.7  \n",
       "3  394.63   2.94  33.4  \n",
       "4  396.90   5.33  36.2  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# target = 'medv'\n",
    "df = get_dataset('boston_housing')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.3200e-03, 1.8000e+01, 2.3100e+00, 0.0000e+00, 5.3800e-01,\n",
       "        6.5750e+00, 6.5200e+01, 4.0900e+00, 1.0000e+00, 2.9600e+02,\n",
       "        1.5300e+01, 3.9690e+02, 4.9800e+00, 2.4000e+01],\n",
       "       [2.7310e-02, 0.0000e+00, 7.0700e+00, 0.0000e+00, 4.6900e-01,\n",
       "        6.4210e+00, 7.8900e+01, 4.9671e+00, 2.0000e+00, 2.4200e+02,\n",
       "        1.7800e+01, 3.9690e+02, 9.1400e+00, 2.1600e+01],\n",
       "       [2.7290e-02, 0.0000e+00, 7.0700e+00, 0.0000e+00, 4.6900e-01,\n",
       "        7.1850e+00, 6.1100e+01, 4.9671e+00, 2.0000e+00, 2.4200e+02,\n",
       "        1.7800e+01, 3.9283e+02, 4.0300e+00, 3.4700e+01],\n",
       "       [3.2370e-02, 0.0000e+00, 2.1800e+00, 0.0000e+00, 4.5800e-01,\n",
       "        6.9980e+00, 4.5800e+01, 6.0622e+00, 3.0000e+00, 2.2200e+02,\n",
       "        1.8700e+01, 3.9463e+02, 2.9400e+00, 3.3400e+01],\n",
       "       [6.9050e-02, 0.0000e+00, 2.1800e+00, 0.0000e+00, 4.5800e-01,\n",
       "        7.1470e+00, 5.4200e+01, 6.0622e+00, 3.0000e+00, 2.2200e+02,\n",
       "        1.8700e+01, 3.9690e+02, 5.3300e+00, 3.6200e+01]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve the array\n",
    "data = df.values\n",
    "data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 13) (506,)\n",
      "(339, 13) (167, 13) (339,) (167,)\n"
     ]
    }
   ],
   "source": [
    "# Split into inpiut and output elements\n",
    "X, y = data[:, :-1], data[:, -1]\n",
    "\n",
    "# Summarize the shape of the dataset\n",
    "print(X.shape, y.shape)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "\n",
    "# Summarize the shape of the train and test sets\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is a regression predictive modeling problem, meaning that we will be predicting a numeric value. All input variables are also numeric. In this case, we will fit a linear regression algorithm and evaluate model performance by training the model on the test dataset and making a prediction on the test data and evaluate the predictions using the mean absolute error (MAE). Normally, before using the linear regression for modelling, in order to trust the results, we should check its assumptions first (this step is ommited for brevity)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 3.417\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Fit the model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "yhat = model.predict(X_test)\n",
    "\n",
    "# Evaluate predictions\n",
    "mae = mean_absolute_error(y_test, yhat)\n",
    "print(f'MAE: {mae:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The expectation is that the outliers are causing the linear regression model to learn a bias or skewed understanding of the problem, and that removing these outliers from the training set will allow a more effective model to be learned.\n",
    "\n",
    "We can achieve this by defining the `LocalOutlierFactor` model and using it to make a prediction on the training dataset, marking each row in the training dataset as normal (`1`) or an outlier (`-1`). We will use the default hyper-parameters for the outlier detection model, although it is a good idea to tune the configuration to the specifics of your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(305, 13) (305,)\n",
      "MAE: 3.356\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model on training dataset with outliers removed\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Identify outliers in the training dataset\n",
    "lof = LocalOutlierFactor()\n",
    "yhat = lof.fit_predict(X_train)\n",
    "\n",
    "# Select all rows that are not outliers\n",
    "mask = yhat != -1\n",
    "X_train, y_train = X_train[mask, :], y_train[mask]\n",
    "\n",
    "# Summarize the shape of the updated training dataset\n",
    "print(X_train.shape, y_train.shape)\n",
    "\n",
    "# Fit the model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "yhat = model.predict(X_test)\n",
    "\n",
    "# Evaluate predictions\n",
    "mae = mean_absolute_error(y_test, yhat)\n",
    "print(f'MAE: {mae:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, we can see that the number of examples in the training dataset has been reduced from 339 to 305, meaning 34 rows containing outliers were identified and deleted. We can also see a reduction in MAE from about 3.417 by a model fit on the entire training dataset, to about 3.356 on a model fit on the dataset with outliers removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
