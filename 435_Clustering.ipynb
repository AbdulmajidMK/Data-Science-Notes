{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In `supervised learning`, algorithms start with a set of labeled data and use that as the basis for making predictions about new, unlabeled data. **Clustering**, however, is an example of `unsupervised learning`, in which we work with completely unlabeled data (or in which our data has labels but we ignore them).\n",
    "\n",
    "Whenever you look at some source of data, `it’s likely that the data will somehow form clusters`. There is generally no “correct” clustering and the `clusters won’t label themselves`. You’ll have to do that by looking at the data underlying each one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-means\n",
    "One of the simplest clustering methods is **k-means**, in which the number of clusters `k` is chosen in advance, after which the goal is to partition the inputs into sets `S1, ..., Sk` in a way that minimizes the total sum of squared distances from each point to the mean of its assigned cluster.\n",
    "\n",
    "There are a lot of ways to assign `n` points to `k` clusters, which means that finding an optimal clustering is a very hard problem. We’ll settle for an iterative algorithm that usually finds a good clustering:\n",
    "\n",
    "1. Start with a set of k-means, which are points in d-dimensional space.\n",
    "2. Assign each point to the mean to which it is closest.\n",
    "3. If no point’s assignment has changed, stop and keep the clusters.\n",
    "4. If some point’s assignment has changed, recompute the means and return to step 2.\n",
    "\n",
    "To start with, we will create a helper function that measures how many coordinates two vectors differ in. We will us this to track our training progress:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scratch.linear_algebra import Vector\n",
    "\n",
    "def num_differences(v1: Vector, v2: Vector) -> int:\n",
    "    assert len(v1) == len(v2)\n",
    "    return len([x1 for x1, x2 in zip(v1, v2) if x1 != x2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert num_differences([1,2,3], [2,1,3]) == 2\n",
    "assert num_differences([1,2], [1,2]) == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need a function, that given some vectors and their assignments to clusters, computes the means of the clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from scratch.linear_algebra import vector_mean\n",
    "\n",
    "assert vector_mean([[1, 2], [3, 4], [5, 6]]) == [3, 4]\n",
    "\n",
    "def cluster_means(k: int,\n",
    "                 inputs: List[Vector],\n",
    "                 assignments: List[int]) -> List[Vector]:\n",
    "    \n",
    "    # clusters[i] contains the inputs whose assignment is i\n",
    "    clusters = [[] for i in range(k)]\n",
    "    \n",
    "    for input, assignment in zip(inputs, assignments):\n",
    "        clusters[assignment].append(input)\n",
    "        \n",
    "    # if a cluster is empty, just use a random point\n",
    "    return [vector_mean(cluster) if cluster else random.choice(inputs)\n",
    "           for cluster in clusters]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import random\n",
    "import tqdm\n",
    "from scratch.linear_algebra import squared_distance\n",
    "\n",
    "class KMeans:\n",
    "    \n",
    "    def __init__(self, k: int) -> None:\n",
    "        self.k = k # number of clusters\n",
    "        self.means = None\n",
    "        \n",
    "    def classify(self, input: Vector) -> int:\n",
    "        \"\"\"\n",
    "        Return the index of the cluster closest to the input\n",
    "        \"\"\"\n",
    "        return min(range(self.k),\n",
    "                  key=lambda i: squared_distance(input, self.means[i]))\n",
    "    \n",
    "    def train(self, inputs: List[Vector]) -> None:\n",
    "        \n",
    "        # start with random assignmnets\n",
    "        assginments = [random.randrange(self.k) for _ in inputs]\n",
    "        \n",
    "        with tqdm.tqdm(itertools.count()) as t:\n",
    "            for _ in t:\n",
    "                \n",
    "                # compute means and find new assignmnets\n",
    "                self.means = cluster_means(self.k, inputs, assignmnets)\n",
    "                new_assignments = [self.classify(input) for input in input]\n",
    "                \n",
    "                # check how many assignmnets changed and if we're done\n",
    "                num_changed = num_differences(assignmnets, new_assignments)\n",
    "                if num_changed == 0:\n",
    "                    return\n",
    "                \n",
    "                # otherwise keep the new assignments, and compute new means\n",
    "                assignments = new_assignments\n",
    "                self.means = cluster_means(self.k, inputs, assignments)\n",
    "                t.set_description(f\"changed: {num_changed} / {len(inputs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
